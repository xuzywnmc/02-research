Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Zhang2013,
abstract = {Recently, sparse representation (SR) and joint sparse representation (JSR) have attracted a lot of interest in image fusion. The SR models signals by sparse linear combinations of prototype signal atoms that make a dictionary. The JSR indicates that different signals from the various sensors of the same scene form an ensemble. These signals have a common sparse component and each individual signal owns an innovation sparse component. The JSR offers lower computational complexity compared with SR. First, for JSR-based image fusion, we give a new fusion rule. Then, motivated by the method of optimal directions (MOD), for JSR, we propose a novel dictionary learning method (MODJSR) whose dictionary updating procedure is derived by employing the JSR structure one time with singular value decomposition (SVD). MODJSR has lower complexity than the K-SVD algorithm which is often used in previous JSR-based fusion algorithms. To capture the image details more efficiently, we proposed the generalized JSR in which the signals ensemble depends on two dictionaries. MODJSR is extended to MODGJSR in this case. MODJSR/MODGJSR can simultaneously carry out dictionary learning, denoising, and fusion of noisy source images. Some experiments are given to demonstrate the validity of the MODJSR/MODGJSR for image fusion. {\textcopyright} 2013 Society of Photo-Optical Instrumentation Engineers (SPIE).},
author = {Zhang, Qiheng and Fu, Yuli and Li, Haifeng and Zou, Jian},
doi = {10.1117/1.oe.52.5.057006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Dictionary learning method for joint.pdf:pdf},
issn = {0091-3286},
journal = {Optical Engineering},
number = {5},
pages = {057006},
title = {{Dictionary learning method for joint sparse representation-based image fusion}},
volume = {52},
year = {2013}
}
@article{Asha2019,
abstract = {Recently, medical image fusion has emerged as an impressive technique in
merging the medical images of different modalities. Certainly, the fused
image assists the physician in disease diagnosis for effective treatment
planning. The fusion process combines multi-modal images to incur a
single image with excellent quality, retaining the information of
original images. This paper proposes a multi-modal medical image fusion
through a weighted blending of high-frequency subbands of nonsubsampled
shearlet transform (NSST) domain via chaotic grey wolf optimization
algorithm. As an initial step, the NSST is applied on source images to
decompose into the multi-scale and multi-directional components. The
low-frequency bands are fused based on a simple max rule to sustain the
energy of an individual. The texture details of input images are
preserved by an adaptively weighted combination of high-frequency images
using a recent chaotic grey wolf optimization algorithm to minimize the
distance between the fused image and source images. The entire process
emphasizes on retaining the energy of the low-frequency band and the
transferring of texture features from source images to the fused image.
Finally, the fused image is formed using inverse NSST of merged low and
high-frequency bands. The experiments are carried out on eight different
disease datasets obtained from Brain Atlas, which consists of MR-T1 and
MR-T2, MR and SPECT, MR and PET, and MR and CT. The effectiveness of the
proposed method is validated using more than 100 pairs of images based
on the subjective and objective quality assessment. The experimental
results confirm that the proposed method performs better in contrast
with the current state-of-the-art image fusion techniques in terms of
entropy, VIFF, and FMI. Hence, the proposed method will be helpful for
disease diagnosis, medical treatment planning, and surgical procedure.},
author = {Asha, C. S. and Lal, Shyam and Gurupur, Varadraj Prabhu and Saxena, P. U.Prakash},
doi = {10.1109/ACCESS.2019.2908076},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/05-2-Multi-Modal Bands Using Chaotic Grey Wolf .pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {MRI,NSST,PET,SPECT,chaotic function,grey Wolf optimization,image fusion},
pages = {40782--40796},
publisher = {IEEE},
title = {{Multi-Modal Medical Image Fusion with Adaptive Weighted Combination of NSST Bands Using Chaotic Grey Wolf Optimization}},
volume = {7},
year = {2019}
}
@article{Liu2017,
abstract = {{\textcopyright} 2017 International Society of Information Fusion (ISIF). Medical image fusion technique plays an an increasingly critical role in many clinical applications by deriving the complementary information from medical images with different modalities. In this paper, a medical image fusion method based on convolutional neural networks (CNNs) is proposed. In our method, a siamese convolutional network is adopted to generate a weight map which integrates the pixel activity information from two source images. The fusion process is conducted in a multi-scale manner via image pyramids to be more consistent with human visual perception. In addition, a local similarity based strategy is applied to adaptively adjust the fusion mode for the decomposed coefficients. Experimental results demonstrate that the proposed method can achieve promising results in terms of both visual quality and objective assessment.},
author = {Liu, Yu and Chen, Xun and Cheng, Juan and Peng, Hu},
doi = {10.23919/ICIF.2017.8009769},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/A Medical Image Fusion .pdf:pdf},
isbn = {9780996452700},
journal = {20th International Conference on Information Fusion, Fusion 2017 - Proceedings},
title = {{A medical image fusion method based on convolutional neural networks}},
year = {2017}
}
@article{Zhang2018,
abstract = {As a result of several successful applications in computer vision and image processing, sparse representation (SR) has attracted significant attention in multi-sensor image fusion. Unlike the traditional multiscale transforms (MSTs) that presume the basis functions, SR learns an over-complete dictionary from a set of training images for image fusion, and it achieves more stable and meaningful representations of the source images. By doing so, the SR-based fusion methods generally outperform the traditional MST image fusion methods in both subjective and objective tests. In addition, they are less susceptible to mis-registration among the source images, thus facilitating the practical applications. This survey paper proposes a systematic review of the SR-based multi-sensor image fusion literature, highlighting the pros and cons of each category of approaches. Specifically, we start by performing a theoretical investigation of the entire system from three key algorithmic aspects, (1) sparse representation models; (2) dictionary learning methods; and (3) activity levels and fusion rules. Subsequently, we show how the existing works address these scientific problems and design the appropriate fusion rules for each application such as multi-focus image fusion and multi-modality (e.g., infrared and visible) image fusion. At last, we carry out some experiments to evaluate the impact of these three algorithmic components on the fusion performance when dealing with different applications. This article is expected to serve as a tutorial and source of reference for researchers preparing to enter the field or who desire to employ the sparse representation theory in other fields.},
author = {Zhang, Qiang and Liu, Yi and Blum, Rick S. and Han, Jungong and Tao, Dacheng},
doi = {10.1016/j.inffus.2017.05.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Sparserepresentationbasedmulti-sensorimagefusion.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Activity level,Dictionary learning,Image fusion,Sparse representation},
pages = {57--75},
publisher = {Elsevier B.V.},
title = {{Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review}},
url = {http://dx.doi.org/10.1016/j.inffus.2017.05.006},
volume = {40},
year = {2018}
}
@article{Li2013,
abstract = {A fast and effective image fusion method is proposed for creating a highly informative fused image through merging multiple images. The proposed method is based on a two-scale decomposition of an image into a base layer containing large scale variations in intensity, and a detail layer capturing small scale details. A novel guided filtering-based weighted average technique is proposed to make full use of spatial consistency for fusion of the base and detail layers. Experimental results demonstrate that the proposed method can obtain state-of-the-art performance for fusion of multispectral, multifocus, multimodal, and multiexposure images.},
author = {Li, Shutao and Kang, Xudong and Hu, Jianwen},
doi = {10.1109/TIP.2013.2244222},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/GF.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Guided filter,image fusion,spatial consistency,two-scale decomposition},
number = {7},
pages = {2864--2875},
title = {{Image fusion with guided filtering}},
volume = {22},
year = {2013}
}
@article{Du2017,
abstract = {A novel method for performing anatomical magnetic resonance imaging-functional (positron emission tomography or single photon emission computed tomography) image fusion is presented. The method merges specific feature information from input image signals of a single or multiple medical imaging modalities into a single fused image, while preserving more information and generating less distortion. The proposed method uses a local Laplacian filtering-based technique realized through a novel multi-scale system architecture. First, the input images are generated in a multi-scale image representation and are processed using local Laplacian filtering. Second, at each scale, the decomposed images are combined to produce fused approximate images using a local energy maximum scheme and produce the fused residual images using an information of interest-based scheme. Finally, a fused image is obtained using a reconstruction process that is analogous to that of conventional Laplacian pyramid transform. Experimental results computed using individual multi-scale analysis-based decomposition schemes or fusion rules clearly demonstrate the superiority of the proposed method through subjective observation as well as objective metrics. Furthermore, the proposed method can obtain better performance, compared with the state-of-the-art fusion methods.},
author = {Du, Jiao and Li, Weisheng and Xiao, Bin},
doi = {10.1109/TIP.2017.2745202},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/LLF{\_}IOI.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Image fusion,interest-based rule,multi-scale decomposition},
number = {12},
pages = {5855--5866},
publisher = {IEEE},
title = {{Anatomical-Functional Image Fusion by Information of Interest in Local Laplacian Filtering Domain}},
volume = {26},
year = {2017}
}
@article{Yin2019a,
author = {Yin, Ming and Liu, Xiaoning and Liu, Yu and Chen, Xun},
doi = {10.1109/TIM.2018.2838778},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/03-10-Medical Image Fusion in NonsubsampledShearlet.pdf:pdf},
issn = {00189456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Activity level measure,image fusion,medical imaging,nonsubsampled shearlet transform (NSST),pulse coupled neural network (PCNN)},
number = {1},
pages = {49--64},
publisher = {IEEE},
title = {{Medical Image Fusion with Parameter-Adaptive Pulse Coupled Neural Network in Nonsubsampled Shearlet Transform Domain}},
volume = {68},
year = {2019}
}
@article{Du2016,
abstract = {Multi-modal medical image fusion is the process of merging multiple images from single or multiple imaging modalities to improve the imaging quality with preserving the specific features. Medical image fusion covers a broad number of hot topic areas, including image processing, computer vision, pattern recognition, machine learning and artificial intelligence. And medical image fusion has been widely used in clinical for physicians to comprehend the lesion by the fusion of different modalities medical images. In this review, methods in the field of medical image fusion are characterized by (1) image decomposition and image reconstruction, (2) image fusion rules, (3) image quality assessments, and (4) experiments on the benchmark dataset. In addition, this review provides a factual listing of scientific challenges faced in the field of multi-modal medical image fusion.},
author = {Du, Jiao and Li, Weisheng and Lu, Ke and Xiao, Bin},
doi = {10.1016/j.neucom.2015.07.160},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/00 An overview of multi-modal medical image fusion.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Image decomposition,Image fusion,Image fusion rules,Image quality assessment,Image reconstruction,Multi-modal},
pages = {3--20},
title = {{An overview of multi-modal medical image fusion}},
volume = {215},
year = {2016}
}
@article{Liu2013,
abstract = {Sparse representation (SR) has been widely used in many image processing applications including image fusion. As the contents vary significantly across different images, a highly redundant dictionary is always required in the sparse model, which reduces the algorithm stability and efficiency. This paper proposes a multi-focus image fusion method based on SR with adaptive sparse domain selection (SR-ASDS). Under SR-ASDS, numerous high-quality image patches are first classified into several categories according to their gradient information, and each category is applied into training a compact sub-dictionary. At the fusion process, a corresponding sub-dictionary is adaptively selected for a given pair of source image patches. Moreover, we present a general optimization framework for the merging rule design of the SR based image fusion. Numerous experiments on both clear images and the noisy ones demonstrate that the proposed method outperforms the fusion methods which use a single dictionary, in terms of several popular objective evaluation criteria.},
author = {Liu, Yu and Wang, Zengfu},
doi = {10.1109/ICIG.2013.123},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Multi-focus image fusion based .pdf:pdf},
isbn = {9780769550503},
journal = {Proceedings - 2013 7th International Conference on Image and Graphics, ICIG 2013},
pages = {591--596},
publisher = {IEEE},
title = {{Multi-focus image fusion based on sparse representation with adaptive sparse domain selection}},
year = {2013}
}
@article{Aharon2006,
abstract = {In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data},
author = {Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
doi = {10.1109/TSP.2006.881199},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/K-SVD An Algorithm for Designing OvercompleteDictionaries for Sparse Representation.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Atom decomposition,Basis pursuit,Codebook,Dictionary,FOCUSS,Gain-shape VQ,K-SVD,K-means,Matching pursuit,Sparse representation,Training,Vector quantization},
number = {11},
pages = {4311--4322},
title = {{K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation}},
volume = {54},
year = {2006}
}
@article{Liu2015,
abstract = {In this study, a novel adaptive sparse representation (ASR) model is presented for simultaneous image fusion and denoising. As a powerful signal modelling technique, sparse representation (SR) has been successfully employed in many image processing applications such as denoising and fusion. In traditional SR-based applications, a highly redundant dictionary is always needed to satisfy signal reconstruction requirement since the structures vary significantly across different image patches. However, it may result in potential visual artefacts as well as high computational cost. In the proposed ASR model, instead of learning a single redundant dictionary, a set of more compact sub-dictionaries are learned from numerous high-quality image patches which have been pre-classified into several corresponding categories based on their gradient information. At the fusion and denoising processes, one of the sub-dictionaries is adaptively selected for a given set of source image patches. Experimental results on multi-focus and multi-modal image sets demonstrate that the ASR-based fusion method can outperform the conventional SR-based method in terms of both visual quality and objective assessment.},
author = {Liu, Yu and Wang, Zengfu},
doi = {10.1049/iet-ipr.2014.0311},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Simultaneous image fusion .pdf:pdf},
issn = {17519659},
journal = {IET Image Processing},
number = {5},
pages = {347--357},
title = {{Simultaneous image fusion and denoising with adaptive sparse representation}},
volume = {9},
year = {2015}
}
@article{Amsterdam,
author = {Amsterdam, S J},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/A NEW QUALITY METRIC FOR IMAGE FUSION .pdf:pdf},
isbn = {0780377508},
journal = {Image (Rochester, N.Y.)},
pages = {173--176},
title = {{Gemma Piella' and Heni Heijmans}}
}
@article{Aharon2006a,
abstract = {In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data},
author = {Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
doi = {10.1109/TSP.2006.881199},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/K-SVD An Algorithm for Designing OvercompleteDictionaries for Sparse Representation.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Atom decomposition,Basis pursuit,Codebook,Dictionary,FOCUSS,Gain-shape VQ,K-SVD,K-means,Matching pursuit,Sparse representation,Training,Vector quantization},
number = {11},
pages = {4311--4322},
title = {{K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation}},
volume = {54},
year = {2006}
}
@article{Hsu2019,
abstract = {{\textcopyright} 2019, CARS. Rationale and objectives: The ultrasound B-mode-based morphological and texture analysis and Nakagami parametric imaging have been proposed to characterize breast tumors. Since these three feature categories of ultrasonic tissue characterization supply information on different physical characteristics of breast tumors, by combining the above methods is expected to provide more clues for classifying breast tumors. Materials and methods: To verify the validity of the concept, raw data were obtained from 160 clinical cases. Six different types of morphological-feature parameters, four texture features, and the Nakagami parameter of benignancy and malignancy were extracted for evaluation. The Pearson's correlation matrix was used to calculate the correlation between different feature parameters. The fuzzy c-means clustering and stepwise regression techniques were utilized to determine the optimal feature set, respectively. The logistic regression, receiver operating characteristic curve, and support vector machine were used to estimate the diagnostic ability. Results: The best performance was obtained by combining morphological-feature parameter (e.g., standard deviation of the shortest distance), texture feature (e.g., variance), and the Nakagami parameter, with an accuracy of 89.4{\%}, a specificity of 86.3{\%}, a sensitivity of 92.5{\%}, and an area under receiver operating characteristic curve of 0.96. There was no significant difference between using fuzzy c-means clustering, logistic regression, and support vector machine based on the optimal feature set for breast tumors classification. Conclusion: Therefore, we verified that different physical ultrasonic features are functionally complementary and thus improve the performance in diagnosing breast tumors. Moreover, the optimal feature set had the maximum discriminating performance should be irrelative to the power of classifiers.},
author = {Hsu, Soa Min and Kuo, Wen Hung and Kuo, Fang Chuan and Liao, Yin Yin},
doi = {10.1007/s11548-018-01908-8},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Hsu et al. - 2019 - Breast tumor classification using different features of quantitative ultrasound parametric images.pdf:pdf},
issn = {18616429},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {Breast ultrasound,Classification,Morphological features,Nakagami parameter,Texture features},
number = {4},
pages = {623--633},
publisher = {Springer International Publishing},
title = {{Breast tumor classification using different features of quantitative ultrasound parametric images}},
url = {https://doi.org/10.1007/s11548-018-01908-8},
volume = {14},
year = {2019}
}
@article{Zhang2018a,
abstract = {As a result of several successful applications in computer vision and image processing, sparse representation (SR) has attracted significant attention in multi-sensor image fusion. Unlike the traditional multiscale transforms (MSTs) that presume the basis functions, SR learns an over-complete dictionary from a set of training images for image fusion, and it achieves more stable and meaningful representations of the source images. By doing so, the SR-based fusion methods generally outperform the traditional MST image fusion methods in both subjective and objective tests. In addition, they are less susceptible to mis-registration among the source images, thus facilitating the practical applications. This survey paper proposes a systematic review of the SR-based multi-sensor image fusion literature, highlighting the pros and cons of each category of approaches. Specifically, we start by performing a theoretical investigation of the entire system from three key algorithmic aspects, (1) sparse representation models; (2) dictionary learning methods; and (3) activity levels and fusion rules. Subsequently, we show how the existing works address these scientific problems and design the appropriate fusion rules for each application such as multi-focus image fusion and multi-modality (e.g., infrared and visible) image fusion. At last, we carry out some experiments to evaluate the impact of these three algorithmic components on the fusion performance when dealing with different applications. This article is expected to serve as a tutorial and source of reference for researchers preparing to enter the field or who desire to employ the sparse representation theory in other fields.},
author = {Zhang, Qiang and Liu, Yi and Blum, Rick S. and Han, Jungong and Tao, Dacheng},
doi = {10.1016/j.inffus.2017.05.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Sparserepresentationbasedmulti-sensorimagefusion.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Activity level,Dictionary learning,Image fusion,Sparse representation},
pages = {57--75},
publisher = {Elsevier B.V.},
title = {{Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review}},
url = {http://dx.doi.org/10.1016/j.inffus.2017.05.006},
volume = {40},
year = {2018}
}
