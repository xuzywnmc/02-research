Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Yu2011a,
abstract = {In this paper, a novel joint sparse representation-based image fusion method is proposed. Since the sensors observe related phenomena, the source images are expected to possess common and innovation features. We use sparse coefficients as image features. The source image is represented with the common and innovation sparse coefficients by joint sparse representation. The sparse coefficients are consequently weighted by the mean absolute values of the innovation coefficients. Furthermore, since sparse representation has been significantly successful in the development of image denoising algorithms, our method can carry out image denoising and fusion simultaneously, while the images are corrupted by additive noise. Experiment results show that the performance of the proposed method is better than that of other methods in terms of several metrics, as well as in the visual quality. {\textcopyright} 2011 IEEE.},
author = {Yu, Nannan and Qiu, Tianshuang and Bi, Feng and Wang, Aiqi},
doi = {10.1109/JSTSP.2011.2112332},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Image Features Extraction and Fusion Based on Joint Sparse Representation(2).pdf:pdf},
issn = {19324553},
journal = {IEEE Journal on Selected Topics in Signal Processing},
keywords = {Features extraction,K-SVD,image fusion,joint sparse representation},
number = {5},
pages = {1074--1082},
publisher = {IEEE},
title = {{Image features extraction and fusion based on joint sparse representation}},
volume = {5},
year = {2011}
}
@article{Hsu2019,
abstract = {{\textcopyright} 2019, CARS. Rationale and objectives: The ultrasound B-mode-based morphological and texture analysis and Nakagami parametric imaging have been proposed to characterize breast tumors. Since these three feature categories of ultrasonic tissue characterization supply information on different physical characteristics of breast tumors, by combining the above methods is expected to provide more clues for classifying breast tumors. Materials and methods: To verify the validity of the concept, raw data were obtained from 160 clinical cases. Six different types of morphological-feature parameters, four texture features, and the Nakagami parameter of benignancy and malignancy were extracted for evaluation. The Pearson's correlation matrix was used to calculate the correlation between different feature parameters. The fuzzy c-means clustering and stepwise regression techniques were utilized to determine the optimal feature set, respectively. The logistic regression, receiver operating characteristic curve, and support vector machine were used to estimate the diagnostic ability. Results: The best performance was obtained by combining morphological-feature parameter (e.g., standard deviation of the shortest distance), texture feature (e.g., variance), and the Nakagami parameter, with an accuracy of 89.4{\%}, a specificity of 86.3{\%}, a sensitivity of 92.5{\%}, and an area under receiver operating characteristic curve of 0.96. There was no significant difference between using fuzzy c-means clustering, logistic regression, and support vector machine based on the optimal feature set for breast tumors classification. Conclusion: Therefore, we verified that different physical ultrasonic features are functionally complementary and thus improve the performance in diagnosing breast tumors. Moreover, the optimal feature set had the maximum discriminating performance should be irrelative to the power of classifiers.},
author = {Hsu, Soa Min and Kuo, Wen Hung and Kuo, Fang Chuan and Liao, Yin Yin},
doi = {10.1007/s11548-018-01908-8},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Hsu et al. - 2019 - Breast tumor classification using different features of quantitative ultrasound parametric images.pdf:pdf},
issn = {18616429},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {Breast ultrasound,Classification,Morphological features,Nakagami parameter,Texture features},
number = {4},
pages = {623--633},
publisher = {Springer International Publishing},
title = {{Breast tumor classification using different features of quantitative ultrasound parametric images}},
url = {https://doi.org/10.1007/s11548-018-01908-8},
volume = {14},
year = {2019}
}
@article{Aharon2006a,
abstract = {In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data},
author = {Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
doi = {10.1109/TSP.2006.881199},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/K-SVD An Algorithm for Designing OvercompleteDictionaries for Sparse Representation.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Atom decomposition,Basis pursuit,Codebook,Dictionary,FOCUSS,Gain-shape VQ,K-SVD,K-means,Matching pursuit,Sparse representation,Training,Vector quantization},
number = {11},
pages = {4311--4322},
title = {{K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation}},
volume = {54},
year = {2006}
}
@article{Zhang2018a,
abstract = {As a result of several successful applications in computer vision and image processing, sparse representation (SR) has attracted significant attention in multi-sensor image fusion. Unlike the traditional multiscale transforms (MSTs) that presume the basis functions, SR learns an over-complete dictionary from a set of training images for image fusion, and it achieves more stable and meaningful representations of the source images. By doing so, the SR-based fusion methods generally outperform the traditional MST image fusion methods in both subjective and objective tests. In addition, they are less susceptible to mis-registration among the source images, thus facilitating the practical applications. This survey paper proposes a systematic review of the SR-based multi-sensor image fusion literature, highlighting the pros and cons of each category of approaches. Specifically, we start by performing a theoretical investigation of the entire system from three key algorithmic aspects, (1) sparse representation models; (2) dictionary learning methods; and (3) activity levels and fusion rules. Subsequently, we show how the existing works address these scientific problems and design the appropriate fusion rules for each application such as multi-focus image fusion and multi-modality (e.g., infrared and visible) image fusion. At last, we carry out some experiments to evaluate the impact of these three algorithmic components on the fusion performance when dealing with different applications. This article is expected to serve as a tutorial and source of reference for researchers preparing to enter the field or who desire to employ the sparse representation theory in other fields.},
author = {Zhang, Qiang and Liu, Yi and Blum, Rick S. and Han, Jungong and Tao, Dacheng},
doi = {10.1016/j.inffus.2017.05.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Sparserepresentationbasedmulti-sensorimagefusion.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Activity level,Dictionary learning,Image fusion,Sparse representation},
pages = {57--75},
publisher = {Elsevier B.V.},
title = {{Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review}},
url = {http://dx.doi.org/10.1016/j.inffus.2017.05.006},
volume = {40},
year = {2018}
}
@article{Su2018,
abstract = {Recently, multifeature learning in collaborative representation classification (CRC) for hyperspectral images has generated promising performance. In this paper, two novel multifeature learning algorithms that update dictionary directly and indirectly are proposed. In order to offer the complementarity of multifeature, four different types of features - global feature (i.e., Gabor feature), local feature (i.e., local binary pattern), shape feature (i.e., extended multiattribute profiles), and spectral feature - are adopted in this paper. Under the hypothesis that most of the features should share the same coding pattern in CRC, this paper proposes to learn proper dictionaries for each feature until obtaining stable codes in a linear classifier. Furthermore, to avoid the explicit mapping of infinite-dimensional dictionaries in a nonlinear kernelized classifier, an indirect approach to construct the transformation matrix from original dictionaries to learn new dictionaries is developed. Three real hyperspectral images acquired from different sensors are adopted for performance evaluation. The experimental results demonstrate that the proposed methods can provide superior performance compared with those of the state-of-the-art classifiers.},
author = {Su, Hongjun and Zhao, Bo and Du, Qian and Du, Peijun and Xue, Zhaohui},
doi = {10.1109/TGRS.2017.2781805},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08244254.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Collaborative representation classification (CRC),Dictionary learning,Hyperspectral imagery,Multifeature learning},
number = {4},
pages = {2467--2484},
publisher = {IEEE},
title = {{Multifeature dictionary learning for collaborative representation classification of hyperspectral imagery}},
volume = {56},
year = {2018}
}
@article{Lin2018,
abstract = {In this paper, we present a novel method for ship classification in synthetic aperture radar (SAR) images. The proposed method consists of feature extraction and classifier training. Inspired by SAR-HOG feature in automatic target recognition, we first design a novel feature named MSHOG by improving SAR-HOG, adapting it to ship classification, and employing manifold learning to achieve dimensionality reduction. Then, we train the classifier and dictionary jointly in task-driven dictionary learning (TDDL) framework. To further improve the performance of TDDL, we enforce structured incoherent constraints on it and develop an efficient algorithm for solving corresponding optimization problem. Extensive experiments performed on two datasets with TerraSAR-X images demonstrate that the proposed method, MSHOG feature and TDDL with structured incoherent constraints, outperforms other existing methods and achieves state-of-art performance.},
author = {Lin, Huiping and Song, Shengli and Yang, Jian},
doi = {10.3390/rs10020190},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/remotesensing-10-00190-v2(1).pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Histogram of oriented gradients (HOG),Manifold learning,Ship classification,Sparse representation,Structured incoherent constraints,Task-driven dictionary learning},
number = {2},
title = {{Ship classification based on MSHOG feature and task-driven dictionary learning with structured incoherent constraints in SAR images}},
volume = {10},
year = {2018}
}
@article{Wang2018,
abstract = {Recently, sparse representation classification (SRC) and fisher discrimination dictionary learning (FDDL) methods have emerged as important methods for vehicle classification. In this paper, inspired by recent breakthroughs of discrimination dictionary learning approach and multi-task joint covariate selection, we focus on the problem of vehicle classification in real-world applications by formulating it as a multi-task joint sparse representation model based on fisher discrimination dictionary learning to merge the strength of multiple features among multiple sensors. To improve the classification accuracy in complex scenes, we develop a new method, called multi-task joint sparse representation classification based on fisher discrimination dictionary learning, for vehicle classification. In our proposed method, the acoustic and seismic sensor data sets are captured to measure the same physical event simultaneously by multiple heterogeneous sensors and the multi-dimensional frequency spectrum features of sensors data are extracted using Mel frequency cepstral coefficients (MFCC). Moreover, we extend our model to handle sparse environmental noise. We experimentally demonstrate the benefits of joint information fusion based on fisher discrimination dictionary learning from different sensors in vehicle classification tasks.},
author = {Wang, Rui and Shen, Miaomiao and Li, Yanping and Gomes, Samuel},
doi = {10.32604/cmc.2018.02408},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/20181019033311{\_}89365.pdf:pdf},
issn = {15462226},
journal = {Computers, Materials and Continua},
keywords = {Fisher discrimination dictionary learning (FDDL),Multi-sensor fusion,Sensor networks,Sparse representation classification (SRC).,Vehicle classification},
number = {1},
pages = {25--48},
title = {{Multi-task joint sparse representation classification based on fisher discrimination dictionary learning}},
volume = {57},
year = {2018}
}
@article{Liu2015a,
abstract = {In image fusion literature, multi-scale transform (MST) and sparse representation (SR) are two most widely used signal/image representation theories. This paper presents a general image fusion framework by combining MST and SR to simultaneously overcome the inherent defects of both the MST- and SR-based fusion methods. In our fusion framework, the MST is firstly performed on each of the pre-registered source images to obtain their low-pass and high-pass coefficients. Then, the low-pass bands are merged with a SR-based fusion approach while the high-pass bands are fused using the absolute values of coefficients as activity level measurement. The fused image is finally obtained by performing the inverse MST on the merged coefficients. The advantages of the proposed fusion framework over individual MST- or SR-based method are first exhibited in detail from a theoretical point of view, and then experimentally verified with multi-focus, visible-infrared and medical image fusion. In particular, six popular multi-scale transforms, which are Laplacian pyramid (LP), ratio of low-pass pyramid (RP), discrete wavelet transform (DWT), dual-tree complex wavelet transform (DTCWT), curvelet transform (CVT) and nonsubsampled contourlet transform (NSCT), with different decomposition levels ranging from one to four are tested in our experiments. By comparing the fused results subjectively and objectively, we give the best-performed fusion method under the proposed framework for each category of image fusion. The effect of the sliding window's step length is also investigated. Furthermore, experimental results demonstrate that the proposed fusion framework can obtain state-of-the-art performance, especially for the fusion of multimodal images.},
author = {Liu, Yu and Liu, Shuping and Wang, Zengfu},
doi = {10.1016/j.inffus.2014.09.004},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1566253514001043-main.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Image fusion,Multi-scale transform,Sparse representation},
pages = {147--164},
publisher = {Elsevier B.V.},
title = {{A general framework for image fusion based on multi-scale transform and sparse representation}},
url = {http://dx.doi.org/10.1016/j.inffus.2014.09.004},
volume = {24},
year = {2015}
}
@article{Abdi2019,
abstract = {In this paper, a new framework is presented to enhance the reconstruction and discrimination capabilities of existing discriminative dictionary learning methods. In the proposed framework, a non-linear mapping model is introduced to learn a feature space in a way that any standard discriminative dictionary learning algorithms could achieve higher classification accuracies. The proposed feature mapping process targets to boost the standard dictionary learning methods by facilitating their optimization process. The mapping model uses a modified autoencoder network to provide a higher level of reconstruction and discrimination capabilities for the discriminative dictionary learning methods. The proposed dictionary learning enhancement (DLE) framework could be applied to any discriminative dictionary learning methods with the embedded discriminative term in their objective functions. Our experiments on several real-world image datasets demonstrate that the proposed framework could improve the classification accuracies of standard discriminative dictionary learning methods.},
author = {Abdi, Arash and Rahmati, Mohammad and Ebadzadeh, Mohammad M.},
doi = {10.1016/j.neucom.2019.05.004},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231219306125-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Autoencoder,Discriminative dictionary learning,Image classification,Nonlinear mapping,Sparse representation,Supervised dictionary learning},
pages = {135--150},
publisher = {Elsevier B.V.},
title = {{Dictionary learning enhancement framework: Learning a non-linear mapping model to enhance discriminative dictionary learning methods}},
url = {https://doi.org/10.1016/j.neucom.2019.05.004},
volume = {357},
year = {2019}
}
@article{Amsterdam,
author = {Amsterdam, S J},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/A NEW QUALITY METRIC FOR IMAGE FUSION .pdf:pdf},
isbn = {0780377508},
journal = {Image (Rochester, N.Y.)},
pages = {173--176},
title = {{Gemma Piella' and Heni Heijmans}}
}
@article{Chen2019,
abstract = {Polarimetric synthetic aperture radar (PolSAR) image classification plays an important role in remote sensing image processing. In recent years, stacked auto-encoder (SAE) has obtained a series of excellent results in PolSAR image classification. The recently proposed projective dictionary pair learning (DPL) model takes both accuracy and time consumption into consideration, and another recently proposed semicoupled dictionary learning (SCDL) model gives a new way to fit different features. Based on the SAE, DPL, and SCDL models, we propose a novel semicoupled projective DPL method with SAE (SAE-SDPL) for PolSAR image classification. Our method can get the classification result efficiently and correctly and meanwhile giving a new method to fit different features. In this paper, three PolSAR images are used to test the performance of SAE-SDPL. Compared with some state-of-the-art methods, our method obtains excellent results in PolSAR image classification.},
author = {Chen, Yanqiao and Jiao, Licheng and Li, Yangyang and Li, Lingling and Zhang, Dan and Ren, Bo and Marturi, Naresh},
doi = {10.1109/TGRS.2018.2873302},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-A Novel Semicoupled Projective Dictionary Pair Learning Method for PolSAR Image Classification.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Polarimetric synthetic aperture radar (PolSAR),projective dictionary pair learning (DPL),semicoupled dictionary learning (SCDL),semicoupled projective DPL (SDPL),stacked auto-encoder (SAE)},
number = {4},
pages = {2407--2418},
publisher = {IEEE},
title = {{A Novel Semicoupled Projective Dictionary Pair Learning Method for PolSAR Image Classification}},
volume = {57},
year = {2019}
}
@article{Liu2017,
abstract = {{\textcopyright} 2017 International Society of Information Fusion (ISIF). Medical image fusion technique plays an an increasingly critical role in many clinical applications by deriving the complementary information from medical images with different modalities. In this paper, a medical image fusion method based on convolutional neural networks (CNNs) is proposed. In our method, a siamese convolutional network is adopted to generate a weight map which integrates the pixel activity information from two source images. The fusion process is conducted in a multi-scale manner via image pyramids to be more consistent with human visual perception. In addition, a local similarity based strategy is applied to adaptively adjust the fusion mode for the decomposed coefficients. Experimental results demonstrate that the proposed method can achieve promising results in terms of both visual quality and objective assessment.},
author = {Liu, Yu and Chen, Xun and Cheng, Juan and Peng, Hu},
doi = {10.23919/ICIF.2017.8009769},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/A Medical Image Fusion .pdf:pdf},
isbn = {9780996452700},
journal = {20th International Conference on Information Fusion, Fusion 2017 - Proceedings},
title = {{A medical image fusion method based on convolutional neural networks}},
year = {2017}
}
@article{Li2018b,
abstract = {Accurate classification of either patients with Alzheimer's disease (AD) or patients with mild cognitive impairment (MCI), the prodromal stage of AD, from cognitively unimpaired (CU) individuals is important for clinical diagnosis and adequate intervention. The current study focused on distinguishing AD or MCI from CU based on the multi-feature kernel supervised within-Class-similar discriminative dictionary learning algorithm (MKSCDDL), which we introduced in a previous study, demonstrating that MKSCDDL had superior performance in face recognition. Structural magnetic resonance imaging (sMRI), fluorodeoxyglucose (FDG) positron emission tomography (PET), and florbetapir-PET data fromthe Alzheimer's Disease Neuroimaging Initiative (ADNI) databasewere all included for classification of AD vs. CU, MCI vs. CU, as well as AD vs. MCI (113 AD patients, 110 MCI patients, and 117 CU subjects). By adopting MKSCDDL, we achieved a classification accuracy of 98.18{\%} for AD vs. CU, 78.50{\%} for MCI vs. CU, and 74.47{\%} for AD vs. MCI, which in each instance was superior to results obtained using several other state-of-the-art approaches (MKL, JRC, mSRC, and mSCDDL). In addition, testing time results outperformed other high quality methods. Therefore, the results suggested that the MKSCDDL procedure is a promising tool for assisting early diagnosis of diseases using neuroimaging data.},
author = {Li, Qing and Wu, Xia and Xu, Lele and Chen, Kewei and Yao, Li},
doi = {10.3389/fncom.2017.00117},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/fncom-11-00117.pdf:pdf},
issn = {16625188},
journal = {Frontiers in Computational Neuroscience},
keywords = {Alzheimer's disease (AD),Mild cognitive impairment (MCI),Multimodal imaging,Multiple kernel dictionary learning},
number = {January},
pages = {1--14},
title = {{Classification of Alzheimer's disease, mild cognitive impairment, and cognitively unimpaired individuals using multi-feature kernel discriminant dictionary learning}},
volume = {11},
year = {2018}
}
@article{Li2018,
abstract = {This paper proposes a novel method based on deformable dictionary learning for detecting the regions of change between multitemporal image pairs. We build on our previous work, which constructed a pair of dictionaries. The main shortcoming of this method was its dependence on a large amount of training data. In practice, there is often a shortage of ground-truthed training images, which limits the expression capability of the resulting dictionaries. This paper overcomes this challenge by incorporating the concept of deformation, wherein each atom of a dictionary is no longer a simple image patch, but instead is a flexible image deformation function. This enables the creation of more expressive dictionaries, capable of generalizing to a far greater variety of image patterns, while using a far smaller amount of ground-truthed images for supervised dictionary training. Deformation similarity is employed for patch matching to find the best set of atoms in the difference image (DI) dictionary for reconstructing image patches for a new input DI. Each such atom can be deformed to achieve a better match, thus extending generality while reducing the number of atoms needed in the dictionary. Multiple deformed atoms are weighted and combined to best reconstruct the input DI patch. Then, the same set of deformations and weights is projected to the corresponding atoms in the CD dictionary to obtain the output change-detection map. Experiments in six realistic synthetic aperture radar data sets demonstrate the robustness and efficiency of the proposed method in comparison with five other state-of-the-art methods from the literature.},
author = {Li, Lin and Zhao, Yongqiang and Sun, Jinjun and Stolkin, Rustam and Pan, Quan and Chan, Jonathan Cheung Wai and Kong, Seong G. and Liu, Zhunga},
doi = {10.1109/TGRS.2018.2829630},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08360150.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Change detection,deformable patches,remote sensing,sparse representation,synthetic aperture radar (SAR) image},
number = {8},
pages = {4605--4617},
publisher = {IEEE},
title = {{Deformable dictionary learning for SAR image change detection}},
volume = {56},
year = {2018}
}
@article{Govinahallisathyanarayana2018,
abstract = {Photoacoustic microscopy (PAM) capitalizes on the optical absorption of blood hemoglobin to enable label-free high-contrast imaging of the cerebral microvasculature in vivo. Although time-resolved ultrasonic detection equips PAM with depth-sectioning capability, most of the data at depths are often obscured by acoustic reverberant artifacts from superficial cortical layers and thus unusable. In this paper, we present a first-of-a-kind dictionary learning algorithm to remove the reverberant signal while preserving underlying microvascular anatomy. This algorithm was validated in vitro, using dyed beads embedded in an optically transparent polydimethylsiloxane phantom. Subsequently, we demonstrated in the live mouse brain that the algorithm can suppress reverberant artifacts by 21.0 ± 5.4 dB, enabling depth-resolved PAM up to 500 $\mu$m from the brain surface.},
author = {Govinahallisathyanarayana, Sushanth and Ning, Bo and Cao, Rui and Hu, Song and Hossack, John A.},
doi = {10.1038/s41598-017-18860-3},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/s41598-017-18860-3.pdf:pdf},
isbn = {4159801718860},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--12},
publisher = {Springer US},
title = {{Dictionary learning-based reverberation removal enables depth-resolved photoacoustic microscopy of cortical microvasculature in the mouse brain}},
url = {http://dx.doi.org/10.1038/s41598-017-18860-3},
volume = {8},
year = {2018}
}
@article{Yin2011,
abstract = {Image fusion combines multiple images of the same scene into a single image which is suitable for human perception and practical applications. Different images of the same scene can be viewed as an ensemble of intercorrelated images. This paper proposes a novel mul- timodal image fusion scheme based on the joint sparsity model which is derived from the distributed compressed sensing. First, the source images are jointly sparsely represented as common and innovation components using an over-complete dictionary. Second, the common and innovations sparse coefficients are combined as the jointly sparse coeffi- cients of the fused image. Finally, the fused result is reconstructed from the obtained sparse coefficients. Furthermore, the proposed method is compared with some popular image fusion methods, such as multiscale transform-based methods and simultaneous orthogonal matching pursuit- based method. The experimental results demonstrate the effectiveness of the proposed method in terms of visual effect and quantitative fusion evaluation indexes.},
author = {Yin, Haitao},
doi = {10.1117/1.3584840},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/10.1.1.823.1305.pdf:pdf},
issn = {0091-3286},
journal = {Optical Engineering},
number = {6},
pages = {067007},
title = {{Multimodal image fusion with joint sparsity model}},
volume = {50},
year = {2011}
}
@article{Daneshvar2010,
abstract = {Image fusion has become a widely used tool for increasing the interpretation quality of images in medical applications. The acquired data might exhibit either good functional characteristic (such as PET) or high spatial resolution (such as MRI). The MRI image shows the brain tissue anatomy and contains no functional information. The PET image indicates the brain function and has a low spatial resolution. Hence, the image fusion task is carried out to enhance the spatial resolution of the functional images by combining them with a high-resolution anatomic image. A perfect fusion process preserves the original functional characteristics and adds spatial characteristics to the image with no spatial distortion. The intensity-hue-saturation (IHS) algorithm and the retina-inspired model (RIM) fusion technique can preserve more spatial feature and more functional information content, respectively. The presented algorithm integrates the advantages of both IHS and RIM fusion methods to improve the functional and spatial information content. Visual and statistical analyses show that the proposed algorithm significantly improves the fusion quality in terms of: entropy, mutual information, discrepancy, and average gradient; compared to fusion methods including, IHS, Brovey, discrete wavelet transform (DWT), {\`{a}}-trous wavelet and RIM. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Daneshvar, Sabalan and Ghassemian, Hassan},
doi = {10.1016/j.inffus.2009.05.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/MRI and PET image fusion by combining IHS and retina-inspired models.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {IHS (intensity-hue-saturation),Image fusion,MRI (magnetic resonance imaging),PET (positron emission tomography),Retina-inspired model (RIM)},
number = {2},
pages = {114--123},
publisher = {Elsevier B.V.},
title = {{MRI and PET image fusion by combining IHS and retina-inspired models}},
url = {http://dx.doi.org/10.1016/j.inffus.2009.05.003},
volume = {11},
year = {2010}
}
@article{Liu2018,
abstract = {Rare bird has long been considered an important in the field of airport security, biological conservation, environmental monitoring, and so on. With the development and popularization of IOT-based video surveillance, all day and weather unattended bird monitoring becomes possible. However, the current mainstream bird recognition methods are mostly based on deep learning. These will be appropriate for big data applications, but the training sample size for rare bird is usually very short. Therefore, this paper presents a new sparse recognition model via improved part detection and our previous dictionary learning. There are two achievements in our work: (1) after the part localization with selective search, the GIST feature of all bird image parts will be fused as data description; (2) the fused GIST feature needs to be learned through our proposed intraclass dictionary learning with regularized K-singular value decomposition. According to above two innovations, the rare bird sparse recognition will be implemented by solving one l1-norm optimization. In the experiment with Caltech-UCSD Birds-200-2011 dataset, results show the proposed method can have better recognition performance than other SR methods for rare bird task with small sample size.},
author = {Liu, Jixin and Sun, Ning and Li, Xiaofei and Han, Guang and Yang, Haigen and Sun, Quansen},
doi = {10.3970/cmc.2018.02177},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/cmc.2018.155.177.pdf:pdf},
issn = {15462226},
journal = {Computers, Materials and Continua},
keywords = {GIST feature fusion,Part detection,Rare bird,Regularized intraclass dictionary learning,Sparse recognition},
number = {3},
pages = {435--446},
title = {{Rare bird sparse recognition via part-based GIST feature fusion and regularized intraclass dictionary learning}},
volume = {55},
year = {2018}
}
@article{Aharon2006,
abstract = {In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data},
author = {Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
doi = {10.1109/TSP.2006.881199},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/K-SVD An Algorithm for Designing OvercompleteDictionaries for Sparse Representation.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Atom decomposition,Basis pursuit,Codebook,Dictionary,FOCUSS,Gain-shape VQ,K-SVD,K-means,Matching pursuit,Sparse representation,Training,Vector quantization},
number = {11},
pages = {4311--4322},
title = {{K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation}},
volume = {54},
year = {2006}
}
@article{Vaz2018,
abstract = {We present a method for speech enhancement of data collected in extremely noisy environments, such as those obtained during magnetic resonance imaging scans. We propose an algorithm based on dictionary learning to perform this enhancement. We use complex nonnegative matrix factorization with intrasource additivity (CMF-WISA) to learn dictionaries of the noise and speech+noise portions of the data and use these to factor the noisy spectrum into estimated speech and noise components. We augment the CMF-WISA cost function with spectral and temporal regularization terms to improve the noise modeling. Based on both objective and subjective assessments, we find that our algorithm significantly outperforms traditional techniques such as least mean squares filtering, while not requiring prior knowledge or specific assumptions such as periodicity of the noise waveforms that current state-of-the-art algorithms require.},
author = {Vaz, Colin and Ramanarayanan, Vikram and Narayanan, Shrikanth},
doi = {10.1109/TASLP.2018.2800280},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08276592.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
keywords = {Real-time MRI,complex NMF,dictionary learning,noise suppression},
number = {5},
pages = {967--980},
publisher = {IEEE},
title = {{Acoustic denoising using dictionary learning with spectral and temporal regularization}},
volume = {26},
year = {2018}
}
@article{You2018a,
abstract = {In this letter, we propose an efficient grid evolution multiple targets localization framework for off-grid targets. First, we propose a more accurate localization model, enabling grid evolution by considering all the grids as random variables to be inferred. Then, the localization problem is formulated as a joint sparsifying dictionary learning and sparse signal recovery problem. Finally, the joint optimization problem is solved under the general framework of sparse Bayesian learning (SBL). Different to previous SBL based localization algorithms, we adopt the hierarchical Laplace distribution for sparse prior, rather than the Sudent's t distribution. We compare the proposed framework with state-of-the-art off-grid targets localization algorithms as well as Cramer-Rao lower bound. Numerical simulations highlight the improved performance of the proposed framework in terms of localization error, noise robustness, and required number of measurements.},
author = {You, Kangyong and Guo, Wenbin and Liu, Yueliang and Wang, Wenbo and Sun, Zhuo},
doi = {10.1109/LCOMM.2018.2863374},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08425747.pdf:pdf},
issn = {15582558},
journal = {IEEE Communications Letters},
keywords = {Laplace prior,Source target localization,compressive sensing,off-grid model,sparse Bayesian learning},
number = {10},
pages = {2068--2071},
publisher = {IEEE},
title = {{Grid Evolution: Joint Dictionary Learning and Sparse Bayesian Recovery for Multiple Off-Grid Targets Localization}},
volume = {22},
year = {2018}
}
@article{Ayas2018,
abstract = {Remote sensing image pan sharpening has attracted researchers' interest, since spatial resolution of multispectral (MS) image can be enhanced by injecting spatial details of a panchromatic image to MS image. In this paper, a novel sparse representation based pan sharpening method is proposed to overcome the disadvantages of traditional methods such as color distortion and blurring effect. This learning based method utilizes a compact single dictionary generated from texture information of high-resolution MS images in order to provide more effective and robust pan sharpening. Two data sets acquired from IKONOS and Quickbird satellites are used to evaluate the performance and robustness of the proposed algorithm. The proposed method is compared with nine well-known component substitution and multiresolution analysis methods and a state-of-art method using several quality measurement indices with references. The experimental results demonstrate that the proposed algorithm is competitive or superior to other conventional methods in terms of visual and quantitative analysis, as it preserves spectral information and provides high quality spatial details in the final product image.},
author = {Ayas, Selen and Gormus, Esra Tunc and Ekinci, Murat},
doi = {10.1109/JSTARS.2018.2835573},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08370102.pdf:pdf},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Dictionary learning,multispectral (MS) image,pan sharpening,panchromatic (PAN) image,sparse representation},
number = {7},
pages = {2448--2460},
publisher = {IEEE},
title = {{An efficient pan sharpening via texture based dictionary learning and sparse representation}},
volume = {11},
year = {2018}
}
@article{Nieto2019,
author = {Nieto, A},
doi = {10.1016/j.cej.2007.09.011},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Akhavan-2019-A-dictionary-learning-approach-for-.pdf:pdf},
journal = {Chemical Engineering Journal},
pages = {0--35},
title = {{Ac ce d M us cri p}},
volume = {5},
year = {2019}
}
@article{Ozturk2018,
abstract = {Nowadays, thanks to the use of advanced technological tools, stem cell studies which play an important role in regenerative medicine and cancer studies have increased considerably. In this study, selective dictionary learning method is presented for detecting mitotic event phases in stem cells using phase contrast time-lapse microscopy images. In the proposed method, three phases are defined for representation of mitotic events. Creating a dictionary that represents these phases with a single feature space restricts the success. For this reason, three dictionaries with different features are created. Although the multiplication of image alpha values with all generated dictionaries is quite suitable for determining the lowest error value, this process is time consuming. For this reason, a selective dictionary approach based on the automatic selection of the best values with a cooperation between the dictionaries has been proposed. In this way, the high success rate is maintained and the processing time is significantly reduced. The proposed method gives better results than other state-of-art studies in terms of computational efficiency and accuracy in experiments with C2C12 and BAEC datasets.},
author = {{\"{O}}zt{\"{u}}rk, Şaban and Akdemir, Bayram},
doi = {10.1016/j.compeleceng.2018.03.025},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0045790617322383-main.pdf:pdf},
issn = {00457906},
journal = {Computers and Electrical Engineering},
keywords = {Cell division,Dictionary learning,Mitosis phase detection,Selective dictionary},
pages = {25--37},
publisher = {Elsevier Ltd},
title = {{Phase classification of mitotic events using selective dictionary learning for stem cell populations}},
url = {https://doi.org/10.1016/j.compeleceng.2018.03.025},
volume = {67},
year = {2018}
}
@article{Zheng2018,
abstract = {We target the problem of sparse 3D reconstruction of dynamic objects observed by multiple unsynchronized video cameras with unknown temporal overlap. To this end, we develop a framework to recover the unknown structure without sequencing information across video sequences. Our proposed compressed sensing framework poses the estimation of 3D structure as the problem of dictionary learning, where the dictionary is defined as an aggregation of the temporally varying 3D structures. Given the smooth motion of dynamic objects, we observe any element in the dictionary can be well approximated by a sparse linear combination of other elements in the same dictionary (i.e., self-expression). Our formulation optimizes a biconvex cost function that leverages a compressed sensing formulation and enforces both structural dependency coherence across video streams, as well as motion smoothness across estimates from common video sources. We further analyze the reconstructability of our approach under different capture scenarios, and its comparison and relation to existing methods. Experimental results on large amounts of synthetic data as well as real imagery demonstrate the effectiveness of our approach.},
archivePrefix = {arXiv},
arxivId = {1605.06863},
author = {Zheng, Enliang and Ji, Dinghuang and Dunn, Enrique and Frahm, Jan Michael},
doi = {10.1109/TPAMI.2017.2742950},
eprint = {1605.06863},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08014489.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Dictionary learning,dynamic 3D reconstruction,self-expression,unsynchronized videos},
number = {9},
pages = {2223--2237},
publisher = {IEEE},
title = {{Self-Expressive Dictionary Learning for Dynamic 3D Reconstruction}},
volume = {40},
year = {2018}
}
@article{Zhang2018h,
abstract = {As the extensive applications of sparse representation, the methods of dictionary learning have received widespread attentions. In this paper, we propose a multi-separable dictionary learning (MSeDiL) algorithm for sparse representation, which is based on the Lagrange Multiplier and the QR decomposition. Different with the traditional dictionary learning methods, the training samples are clustered firstly. Then the separable dictionaries for each cluster are optimized by the QR decomposition. The efficiency of the reconstruction process is improved in our algorithm because of the under-determinedness of the dictionaries for each cluster. Experimental results show that with the similar PSNR (Peak Signal to Noise Ratio) and SSIM (Structure Similarity Index), the reconstruction speed of our algorithm is much faster than other dictionary learning methods, especially when the size of samples is large.},
author = {Zhang, Fengzhen and Cen, Yigang and Zhao, Ruizhen and Hu, Shaohai and Mladenovic, V.},
doi = {10.1016/j.sigpro.2017.06.023},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168417302335-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Lagrange Multiplier,Multi-separable dictionary learning,Separable dictionary learning,Sparse representation},
pages = {354--363},
publisher = {Elsevier B.V.},
title = {{Multi-separable dictionary learning}},
url = {https://doi.org/10.1016/j.sigpro.2017.06.023},
volume = {143},
year = {2018}
}
@article{Shin2018,
abstract = {Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95{\%} of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications.},
author = {Shin, Younghak and Balasingham, Ilangko},
doi = {10.1016/j.compmedimag.2018.08.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0895611118300922-main.pdf:pdf},
issn = {18790771},
journal = {Computerized Medical Imaging and Graphics},
keywords = {Colonoscopy,Computer-aided detection,Dictionary learning,Polyp classification,Shape and color feature,Sparse coding},
pages = {33--42},
publisher = {Elsevier Ltd},
title = {{Automatic polyp frame screening using patch based combined feature and dictionary learning}},
url = {https://doi.org/10.1016/j.compmedimag.2018.08.001},
volume = {69},
year = {2018}
}
@article{Akhtar2018,
abstract = {We present a principled approach to learn a discriminative dictionary along a linear classifier for hyperspectral classification. Our approach places Gaussian Process priors over the dictionary to account for the relative smoothness of the natural spectra, whereas the classifier parameters are sampled from multivariate Gaussians. We employ two Beta-Bernoulli processes to jointly infer the dictionary and the classifier. These processes are coupled under the same sets of Bernoulli distributions. In our approach, these distributions signify the frequency of the dictionary atom usage in representing class-specific training spectra, which also makes the dictionary discriminative. Due to the coupling between the dictionary and the classifier, the popularity of the atoms for representing different classes gets encoded into the classifier. This helps in predicting the class labels of test spectra that are first represented over the dictionary by solving a simultaneous sparse optimization problem. The labels of the spectra are predicted by feeding the resulting representations to the classifier. Our approach exploits the nonparametric Bayesian framework to automatically infer the dictionary size-the key parameter in discriminative dictionary learning. Moreover, it also has the desirable property of adaptively learning the association between the dictionary atoms and the class labels by itself. We use Gibbs sampling to infer the posterior probability distributions over the dictionary and the classifier under the proposed model, for which, we derive analytical expressions. To establish the effectiveness of our approach, we test it on benchmark hyperspectral images. The classification performance is compared with the state-of-the-art dictionary learning-based classification methods.},
author = {Akhtar, Naveed and Mian, Ajmal},
doi = {10.1109/TNNLS.2017.2742528},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08057599.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Beta-Bernoulli process,Gaussian process,coupled Bayesian dictionary learning,discriminative dictionary learning,hyperspectral classification},
number = {9},
pages = {4038--4050},
publisher = {IEEE},
title = {{Nonparametric Coupled Bayesian Dictionary and Classifier Learning for Hyperspectral Classification}},
volume = {29},
year = {2018}
}
@article{Zhao2017,
abstract = {Example-based image super-resolution aims to establish a learning model for generating the high resolution image from the coupled training pairs, which is an active study area of mobile media in the recent modern communication. In this paper, we proposed a novel example-based method to address the single image super-resolution problem, where the training pairs are selected from a large amount of natural images. The main idea of our method is to reconstruct the high resolution by a two stage-based scheme. In the first stage, one dictionary is learned to represent the coarse high resolution image from its low version, and the other is trained within the same coding as the coarse image to recover texture details. And then, to further enhance the fine edges in image, a similar dictionary learning scenario are done about the synthesis high resolution image and its fine structure in residual component. Extensive experimental results on some benchmark test images show the advantage of our method compare with other excellent ones.},
author = {Zhao, Feng and Si, Weijian and Dou, Zheng},
doi = {10.1007/s11042-017-5493-0},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Zhao2019{\_}Article{\_}ImageSuper-resolutionViaTwoSta.pdf:pdf},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Dictionary learning,Image superresolution,Low pass filter,Sparse representation},
pages = {1--8},
publisher = {Multimedia Tools and Applications},
title = {{Image super-resolution via two stage coupled dictionary learning}},
year = {2017}
}
@article{Zhang1999,
abstract = {The objective of image fusion is to combine information from multiple images of the same scene. The result of image fusion is a single image which is more suitable for hitman and machine perception or further image-processing tasks. In this paper, a generic image fusion framework based on multiscale decomposition is studied. This framework provides freedom to choose different multiscale decomposition methods and different fusion rules. The framework includes all of the existing multiscale-decompositionbased fusion approaches we found in the literature which did not assume a statistical model for the source images. Different image fusion approaches are investigated based on this framework. Some evaluation measures are suggested and applied to compare the performance of these fusion schemes for a digital camera application. The comparisons indicate that our framework includes some new approaches which outperform the existing approaches for the cases we consider. {\textcopyright} 1999 IEEE.},
author = {Zhang, Zhong and Blum, Rick S.},
doi = {10.1109/5.775414},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/00775414.pdf:pdf},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Image fusion,Multiscale decomposition,Multisensor fusion},
number = {8},
pages = {1315--1326},
title = {{A categorization of multiscale-decomposition-based image fusion schemes with a performance study for a digital camera application}},
volume = {87},
year = {1999}
}
@article{Hu2019,
abstract = {In this paper, a Spare Representation (SR) based fusion quality evaluation and analysis method is proposed. This method employs Joint Sparse Representation (JSR) to extract the source image remnants after fusion. These atom-level remnants indicate the fusion quality intuitively, and permit the analysis of fusion effect in learned feature space. Our analysis results indicate that high salient atoms always present poor expressions in fusion results. An improved fusion rule is designed to emphasis high salient atoms accordingly. In experiments, the effectiveness of our method was verified and the characteristics of atom JSR remnants were investigated in detail first. Then the new fusion rule was tested to demonstrate the value of JSR remnant analysis. The objective and subjective comparison results indicate that the proposed analytical evaluation metric can measure fusion quality and analysis atom fusion effect accurately. The new fusion rule provides a valuable alternative for SR fusion algorithm design.},
author = {Hu, Yanxiang and Gao, Qian and Zhang, Bo and Zhang, Juntong},
doi = {10.1016/j.jvcir.2019.04.005},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/On the use of joint sparse representation for image fusion quality evaluation and analysis.pdf:pdf},
issn = {10959076},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Atom remnant analysis,Image fusion,Joint sparse representation,Quality evaluation,Sparse representation},
pages = {225--235},
publisher = {Elsevier Inc.},
title = {{On the use of joint sparse representation for image fusion quality evaluation and analysis}},
url = {https://doi.org/10.1016/j.jvcir.2019.04.005},
volume = {61},
year = {2019}
}
@article{Iqbal2018,
abstract = {Objective: Analysis of functional magnetic resonance imaging (fMRI) data from multiple subjects is at the heart of many medical imaging studies, and approaches based on dictionary learning (DL) are recently noted as promising solutions to the problem. However, the DL-based methods for fMRI analysis proposed to date do not naturally extend to multisubject analysis. In this paper, we propose a DL algorithm for multisubject fMRI data analysis. Methods: The proposed algorithm [named shared and subject-specific dictionary learning (ShSSDL)] is derived based on a temporal concatenation, which is particularly attractive for the analysis of multisubject task-related fMRI datasets. It differs from existing DL algorithms in both its sparse coding and dictionary update stages and has the advantage of learning a dictionary shared by all subjects as well as a set of subject-specific dictionaries. Results: The performance of the proposed DL algorithm is illustrated using simulated and real fMRI datasets. The results show that it can successfully extract shared as well as subject-specific latent components. Conclusion: In addition to offering a new DL approach, when applied on multisubject fMRI data analysis, the proposed algorithm generates a group level as well as a set of subject-specific spatial maps. Significance: The proposed algorithm has the advantage of learning simultaneously multiple dictionaries providing us with a shared as well discriminative source of information about the analyzed fMRI datasets.},
author = {Iqbal, Asif and Seghouane, Abd Krim and Adali, Tulay},
doi = {10.1109/TBME.2018.2806958},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08293818.pdf:pdf},
issn = {15582531},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Dictionary learning,functional magnetic resonance imaging (fMRI),multi-subject analysis,sparse decomposition,temporal concatenation},
number = {11},
pages = {2519--2528},
title = {{Shared and subject-specific dictionary learning (ShSSDL) algorithm for multisubject fMRI data analysis}},
volume = {65},
year = {2018}
}
@article{Zhang2018l,
abstract = {To efficiently recognize on-ground objects in airborne laser scanning (ALS) point clouds, we design a method that jointly learns a discriminative dictionary and a classifier. In the method, the point cloud is segmented into hierarchical point clusters, which are organized by a tree structure. Then, the feature of each point cluster is extracted. The feature of a leaf node is obtained by aggregating the features of all its parent nodes. The feature of the leaf node is called the hierarchical aggregation feature. The hierarchical aggregation features are encoded by sparse coding. We introduce a new label consistency constraint called "discriminative sparse-code error," and combine it with the reconstruction error, the classification error, and L1-norm sparsity constraint to form a unified objective function. The objective function is efficiently solved by using the proposed label consistency feature sign method. We obtain an overcomplete discriminative dictionary and an optimal linear classifier. Experiments performed on different ALS point cloud scenes have shown that the hierarchical aggregation features combined with the learned classifier can significantly enhance the classification results, and also demonstrated the superior performance of our method over other techniques in point cloud classification.},
author = {Zhang, Zhenxin and Zhang, Liqiang and Tan, Yumin and Zhang, Liang and Liu, Fangyu and Zhong, Ruofei},
doi = {10.1109/TGRS.2017.2751061},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08082119.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Airborne laser scanning (ALS) point clouds,Classification,Discriminative dictionary learning,Hierarchical aggregation feature,Point clusters,Sparse coding},
number = {1},
pages = {524--538},
publisher = {IEEE},
title = {{Joint discriminative dictionary and classifier learning for ALS point cloud classification}},
volume = {56},
year = {2018}
}
@article{Liu2018i,
author = {Liu, Yu and Chen, Xun and Wang, Zengfu and Wang, Z Jane and Ward, Rabab K and Wang, Xuesong},
doi = {10.1016/j.inffus.2017.10.007},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1566253517305936-main(3).pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {Convolutional neural network,Convolutional sparse representation,Deep learning,Image fusion,Stacked autoencoder},
number = {September 2017},
pages = {158--173},
publisher = {Elsevier},
title = {{Deep learning for pixel-level image fusion : Recent advances and future prospects}},
url = {https://doi.org/10.1016/j.inffus.2017.10.007},
volume = {42},
year = {2018}
}
@article{Elad2011,
author = {Elad, Michael and Aharon, Michal},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Elad-2006-Image-denoising-via-sparse-and-redu.pdf:pdf},
journal = {IEEE Transactions on Image Processing},
number = {12},
pages = {3736--3745},
title = {{Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries Introduction - Issue Revealing}},
volume = {15},
year = {2011}
}
@article{Chen2018,
abstract = {Sparse representation and discriminative dictionary learning (DDL) algorithm has become a widely-used model in visual recognition systems, and various discrimination terms are introduced into the DDL models to enhance the discriminative ability and the recognition rate. Recently, an algorithm named dictionary pair learning (DPL) was proposed which jointly learned a synthesis dictionary and an analysis dictionary to promote the recognition performance. In this paper, a novel dictionary learning model is proposed which introduces a differentiable support vector discriminative term into the original DPL model. In the dictionary learning stage, the proposed model can jointly train a synthesis dictionary, an analysis dictionary and a support vector discriminative term. In the classification stage, the class label is decided by the joint effect of the reconstruction residual, the projective discrimination term and the support vector function. Experimental results on various image recognition benchmarks such as face recognition, scene categorization and object classification are presented to demonstrate the effectiveness of the proposed method.},
author = {Chen, Boheng and Li, Jie and Ma, Biyun and Wei, Gang},
doi = {10.1016/j.neucom.2017.07.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S092523121731233X-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Dictionary pair learning,Discriminative dictionary learning,Image recognition,Support vector function},
pages = {306--313},
publisher = {Elsevier B.V.},
title = {{Discriminative dictionary pair learning based on differentiable support vector function for visual recognition}},
volume = {272},
year = {2018}
}
@article{Sui2018,
abstract = {In this paper, a novel spatial-temporal locality is proposed and unified via a discriminative dictionary learning framework for visual tracking. By exploring the strong local correlations between temporally obtained target and their spatially distributed nearby background neighbors, a spatial-temporal locality is obtained. The locality is formulated as a subspace model and exploited under a unified structure of discriminative dictionary learning with a subspace structure. Using the learned dictionary, the target and its background can be described and distinguished effectively through their sparse codes. As a result, the target is localized by integrating both the descriptive and the discriminative qualities. Extensive experiments on various challenging video sequences demonstrate the superior performance of proposed algorithm over the other state-of-the-art approaches.},
author = {Sui, Yao and Wang, Guanghui and Zhang, Li and Yang, Ming Hsuan},
doi = {10.1109/TIP.2017.2779275},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08125777.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Dictionary learning,Low-rank learning,Sparse representation,Visual tracking},
number = {3},
pages = {1282--1296},
publisher = {IEEE},
title = {{Exploiting spatial-temporal locality of tracking via structured dictionary learning}},
volume = {27},
year = {2018}
}
@article{Donoho2006,
author = {Donoho, David L},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Donoho-2006-Compressed-sensing.pdf:pdf},
number = {4},
pages = {1289--1306},
title = {{Compressed Sensing}},
volume = {52},
year = {2006}
}
@article{Ding2018b,
abstract = {Wheelset bearings are among the crucial elements of bogie frames used in high-speed trains. Wheelset-bearing fault detection can actively reduce or preclude safety-related accidents and realize condition-based maintenance in high-speed train service. Therefore, it is of great significance to automatically detect wheelset-bearing faults. Sparse representations based on circular-structure dictionary learning (SRCSDL) provide an excellent framework for extracting fault impact trains (FITs) induced by wheelset-bearing faults. However, the performance of SRCSDL on extracting FITs heavily relies on the selection of method-related parameters. A systematic method for selecting such parameters has not been reported in the literature. A novel fault detection method, adaptive SRCSDL (ASRCSDL), is therefore proposed in this paper. The effects of the selection of each SRCSDL parameter on extracting FITs are investigated. It was found that three parameters (the length of single set signals, the number of signal sets, and convergence error) can be fixed according to the characteristics of the SRCSDL algorithm. To adaptively tune the remaining three parameters, main frequency analysis is used to select the number of kernel functions, the number of maximum extreme values is employed to determine the length of the kernel function, and envelope spectra kurtosis-guided self-tuning algorithms are proposed to tune the target sparsity of SRCSDL. The proposed method is then validated using the simulated signals and bench and real-line tests.},
author = {Ding, Jianming and Zhao, Wentao and Miao, Bingrong and Lin, Jianhui},
doi = {10.1016/j.ymssp.2018.04.012},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0888327018302024-main.pdf:pdf},
issn = {10961216},
journal = {Mechanical Systems and Signal Processing},
keywords = {Adaptive sparse representation,Circular-structure dictionary learning,Fault detection,Wheelset bearing},
pages = {399--422},
publisher = {Elsevier Ltd},
title = {{Adaptive sparse representation based on circular-structure dictionary learning and its application in wheelset-bearing fault detection}},
url = {https://doi.org/10.1016/j.ymssp.2018.04.012},
volume = {111},
year = {2018}
}
@article{Chun2018,
abstract = {Convolutional dictionary learning (CDL or sparsifying CDL) has many applications in image processing and computer vision. There has been growing interest in developing efficient algorithms for CDL, mostly relying on the augmented Lagrangian (AL) method or the variant alternating direction method of multipliers (ADMM). When their parameters are properly tuned, AL methods have shown fast convergence in CDL. However, the parameter tuning process is not trivial due to its data dependence and, in practice, the convergence of AL methods depends on the AL parameters for nonconvex CDL problems. To moderate these problems, this paper proposes a new practically feasible and convergent Block Proximal Gradient method using a Majorizer (BPG-M) for CDL. The BPG-M-based CDL is investigated with different block updating schemes and majorization matrix designs, and further accelerated by incorporating some momentum coefficient formulas and restarting techniques. All of the methods investigated incorporate a boundary artifacts removal (or, more generally, sampling) operator in the learning model. Numerical experiments show that, without needing any parameter tuning process, the proposed BPG-M approach converges more stably to desirable solutions of lower objective values than the existing state-of-the-art ADMM algorithm and its memory-efficient variant do. Compared with the ADMM approaches, the BPG-M method using a multi-block updating scheme is particularly useful in single-threaded CDL algorithm handling large data sets, due to its lower memory requirement and no polynomial computational complexity. Image denoising experiments show that, for relatively strong additive white Gaussian noise, the filters learned by BPG-M-based CDL outperform those trained by the ADMM approach.},
archivePrefix = {arXiv},
arxivId = {1707.00389},
author = {Chun, Il Yong and Fessler, Jeffrey A.},
doi = {10.1109/TIP.2017.2761545},
eprint = {1707.00389},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08063433.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Convolutional dictionary learning,block proximal gradient method,convergence guarantee,convolutional sparse coding,majorization matrix design},
number = {4},
pages = {1697--1712},
publisher = {IEEE},
title = {{Convolutional Dictionary Learning: Acceleration and Convergence}},
volume = {27},
year = {2018}
}
@article{Wang2019b,
author = {Wang, Weifang and Dong, Jiwen and Niu, Sijie and Chen, Yuehui},
doi = {10.1109/isbi.2019.8759425},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08759425.pdf:pdf},
isbn = {9781538636404},
journal = {2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)},
number = {61701192},
pages = {1631--1634},
publisher = {IEEE},
title = {{Edge-Guided Semi-Coupled Dictionary Learning Super Resolution for Retina Image}},
year = {2019}
}
@article{Engan2007,
abstract = {The use of overcomplete dictionaries, or frames, for sparse signal representation has been given considerable attention in recent years. The major challenges are good algorithms for sparse approximations, i.e., vector selection algorithms, and good methods for choosing or designing dictionaries/frames. This work is concerned with the latter. We present a family of iterative least squares based dictionary learning algorithms (ILS-DLA), including algorithms for design of signal dependent block based dictionaries and overlapping dictionaries, as generalizations of transforms and filter banks, respectively. In addition different constraints can be included in the ILS-DLA, thus we present different constrained design algorithms. Experiments show that ILS-DLA is capable of reconstructing (most of) the generating dictionary vectors from a sparsely generated data set, with and without noise. The dictionaries are shown to be useful in applications like signal representation and compression where experiments demonstrate that our ILS-DLA dictionaries substantially improve compression results compared to traditional signal expansions such as transforms and filter banks/wavelets. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Engan, Kjersti and Skretting, Karl and Hus{\o}y, John H{\aa}kon},
doi = {10.1016/j.dsp.2006.02.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Engan-2007-Family-of-iterative-ls-based-dictio.pdf:pdf},
issn = {10512004},
journal = {Digital Signal Processing: A Review Journal},
keywords = {Compression,Dictionary design,Dictionary learning,Frame design,Least squares,Matching pursuit,Overcomplete dictionary,Signal representation,Sparse approximation},
number = {1},
pages = {32--49},
title = {{Family of iterative LS-based dictionary learning algorithms, ILS-DLA, for sparse signal representation}},
volume = {17},
year = {2007}
}
@article{Korat2019,
abstract = {The purpose of the current study was to examine the efficacy of e-book reading to ‎promoting word learning among kindergarteners with specific language impairment ‎‎(SLI) compared to those with typical language development (TLD). We also tested ‎the contribution of three types of dictionary support provided in the e-book. All ‎dictionary words were given a pictorial and auditory support while a third of them ‎were given a short definition, a third were defined using the story content, and a third ‎were given a combined definition. Twenty kindergarteners with SLI and 20 with TLD ‎were read the e-book with dictionary support 5 times. Each child was exposed to the ‎three types of dictionary support in each e-book reading. Receptive knowledge, word ‎definitions and use of target words were measured pre and post intervention. A ‎significant improvement in new word learning following the e-book reading was ‎found in the children's receptive knowledge, word definitions and use of target ‎words. Nonetheless, children with TLD progressed in words use more than children ‎with SLI. The two groups progressed to a greater extent in explaining new words ‎following the provision of a dictionary definition and following story context ‎definition. Children with SLI progressed in words' use following the definition of a ‎dictionary. The combined definition was especially efficient for children in the two ‎groups with had a low initial level of using new words. Combined definition was also ‎efficient for explaining new words for TLD children with initially high language level. ‎We conclude that children with SLI like children with TLD can benefit from ebook ‎reading and can learn new words at different levels when the e-book is well designed in ‎assisting children with definitions of difficult words.‎},
author = {Korat, Ofra and Graister, Tzlil and Altman, Carmit},
doi = {10.1016/j.jcomdis.2019.03.004},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Contribution of reading an e-book with a dictionary to word learning Comparison between kindergarteners with and without SLI.pdf:pdf},
issn = {18737994},
journal = {Journal of Communication Disorders},
keywords = {Dictionary support,E-book,SLI,Vocabulary,Young children},
number = {January},
pages = {90--102},
publisher = {Elsevier},
title = {{Contribution of reading an e-book with a dictionary to word learning: Comparison between kindergarteners with and without SLI}},
url = {https://doi.org/10.1016/j.jcomdis.2019.03.004},
volume = {79},
year = {2019}
}
@article{Sun2018,
abstract = {Video-based person reidentification (re-id) is a challenging problem due to much discrepancy between different videos by person pose, illumination, viewpoint change, background clutter, and occlusion within each camera and across different cameras. However, most existing video-based person re-id methods usually focus on dealing with the discrepancy between different cameras and do not fully consider the correlation between different cameras. In this paper, we propose a semicoupled dictionary learning with relaxation label space transformation approach to capture the intrinsic relationship of the same person under different cameras. First, to reduce the discrepancy between different views, we transform the original feature spaces into the common feature space by local Fisher discriminant analysis. Two dictionaries are learned from this common feature space. Second, a relaxation label space is introduced to associate the same person under different views. In this label space, the distance between different persons can be enlarged as much as possible, such that label information has stronger discriminative capability. A single dictionary is learned from the relaxation label space. Finally, in order to further enhance the correlation of the same person between different cameras, we use a pair of transformation matrices which map the coding coefficients learned from the common feature space to the coding coefficients learned from the relaxation label space, respectively. Extensive experimental results on two public iLIDS Video re-IDentification and Person Re-ID 2011 video-based person re-id datasets demonstrate the effectiveness of the proposed method.},
author = {Sun, Lingchuan and Jiang, Zhuqing and Song, Hongchao and Lu, Qishuo and Men, Aidong},
doi = {10.1109/ACCESS.2018.2803789},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08286855.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Person re-identification,label space,local Fisher discriminant analysis,semi-coupled dictionary learning},
pages = {12587--12597},
publisher = {IEEE},
title = {{Semi-Coupled Dictionary Learning with Relaxation Label Space Transformation for Video-Based Person Re-Identification}},
volume = {6},
year = {2018}
}
@article{Sulam2018,
abstract = {The recently proposed multilayer convolutional sparse coding (ML-CSC) model, consisting of a cascade of convolutional sparse layers, provides a new interpretation of convolutional neural networks (CNNs). Under this framework, the forward pass in a CNN is equivalent to a pursuit algorithm aiming to estimate the nested sparse representation vectors from a given input signal. Despite having served as a pivotal connection between CNNs and sparse modeling, a deeper understanding of the ML-CSC is still lacking. In this paper, we propose a sound pursuit algorithm for the ML-CSC model by adopting a projection approach. We provide new and improved bounds on the stability of the solution of such pursuit and we analyze different practical alternatives to implement this in practice. We show that the training of the filters is essential to allow for nontrivial signals in the model, and we derive an online algorithm to learn the dictionaries from real data, effectively resulting in cascaded sparse convolutional layers. Last, but not least, we demonstrate the applicability of the ML-CSC model for several applications in an unsupervised setting, providing competitive results. Our work represents a bridge between matrix factorization, sparse dictionary learning, and sparse autoencoders, and we analyze these connections in detail.},
archivePrefix = {arXiv},
arxivId = {1708.08705},
author = {Sulam, Jeremias and Papyan, Vardan and Romano, Yaniv and Elad, Michael},
doi = {10.1109/TSP.2018.2846226},
eprint = {1708.08705},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08379455.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Convolutional sparse coding,convolutional neural networks,dictionary learning,multilayer pursuit,sparse convolutional filters},
number = {15},
pages = {4090--4104},
publisher = {IEEE},
title = {{Multilayer convolutional sparse modeling: Pursuit and dictionary learning}},
volume = {66},
year = {2018}
}
@article{Han2018,
abstract = {Wind power has developed rapidly over the past decade where study on wind turbine fault diagnosis methods are of great significance. The conventional intelligent diagnosis framework has led to impressive results in many studies over the last decade. Despite its popularity, the diagnosis result is affected severely by the feature selection and the performance of the classifiers. To address this issue, a novel method to diagnose wind turbine faults via dictionary learning and sparse representation-based classification (SRC) is proposed in this paper. Dictionary learning algorithm is capable of converting the atoms in the dictionary into the inherent structure of raw signals regardless of any prior knowledge, indicating that it is a self-adaptive feature extraction approach, which avoids the challenge of feature selection in traditional methods. Next, recognition and diagnosis can be solved by the simple SRC without additional classifier, exploiting the sparse nature that the key entries in sparse representation vector are assigned to the corresponding fault category for a test sample. The validity and superiority of the proposed method are validated by the experimental analysis. Moreover, we find that, in terms of robustness under variable conditions and anti-noise ability, the performance of the proposed method always significantly outperforms the traditional diagnosis methods, leading to a promising application prospect.},
author = {Han, Te and Jiang, Dongxiang and Sun, Yankui and Wang, Nanfei and Yang, Yizhou},
doi = {10.1016/j.measurement.2018.01.036},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0263224118300496-main.pdf:pdf},
issn = {02632241},
journal = {Measurement: Journal of the International Measurement Confederation},
keywords = {Dictionary learning,Intelligent fault diagnosis,K-SVD,Rotating machinery,Sparse representation-based classification},
number = {January},
pages = {181--193},
publisher = {Elsevier},
title = {{Intelligent fault diagnosis method for rotating machinery via dictionary learning and sparse representation-based classification}},
url = {https://doi.org/10.1016/j.measurement.2018.01.036},
volume = {118},
year = {2018}
}
@article{Li2019a,
abstract = {Person re-identification (PRID) is integral to many smart surveillance systems. However, owing to the visual ambiguities arising from the variability in viewing angles and illumination, and the presence of occlusions, PRID continues to present many challenges, especially when only a single image per view is available for each person. To overcome this problem, we propose a top distance regularized projection and dictionary learning (DL) model for PRID. The model incorporates both projection and DL to form a unified optimization framework to enhance the effectiveness of both these types of learning. Thus, the dictionary and projection matrix are jointly learned within this framework. In particular, the learned projection maps the coding coefficient into a discriminative space and minimizes the distance between the same persons across non-overlapping views such that the dictionary and projection can be discriminated. Moreover, we exploit listwise distances to capture all pairwise similarities. Based on this design, we derive a top distance regularization term to refine the solution space of the DL model such that the discriminative ability of the learned projection matrix and dictionary are further improved. Experiments on different challenging datasets demonstrate the effectiveness of our method and its superiority over a few current state-of-the-art approaches.},
author = {Li, Huafeng and Xu, Jiajia and Zhu, Jinting and Tao, Dapeng and Yu, Zhengtao},
doi = {10.1016/j.ins.2019.06.046},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0020025519305845-main.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Dictionary learning,Listwise distance,Person re-identification,Projection learning,Top distance},
pages = {472--491},
publisher = {Elsevier Inc.},
title = {{Top distance regularized projection and dictionary learning for person re-identification}},
volume = {502},
year = {2019}
}
@article{Song2019a,
abstract = {Processing and applications of hyperspectral images (HSI) are limited by the noise component. This paper establishes an HSI denoising algorithm by applying dictionary learning and sparse coding theory, which is extended into the spectral domain. First, the HSI noise model under additive noise assumption was studied. Considering the spectral information of HSI data, a novel dictionary learning method based on an online method is proposed to train the spectral dictionary for denoising. With the spatial–contextual information in the noisy HSI exploited as a priori knowledge, the total variation regularizer is introduced to perform the sparse coding. Finally, sparse reconstruction is implemented to produce the denoised HSI. The performance of the proposed approach is better than the existing algorithms. The experiments illustrate that the denoising result obtained by the proposed algorithm is at least 1 dB better than that of the comparison algorithms. The intrinsic details of both spatial and spectral structures can be preserved after significant denoising.},
author = {Song, Xiaorui and Wu, Lingda and Hao, Hongxing and Xu, Wanpeng},
doi = {10.3390/electronics8010086},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/electronics-08-00086-v2.pdf:pdf},
isbn = {8601066364},
issn = {20799292},
journal = {Electronics (Switzerland)},
keywords = {Hyperspectral image,Image denoising,Image processing,Sparse coding,Spectral dictionary},
number = {1},
title = {{Hyperspectral image denoising based on spectral dictionary learning and sparse coding}},
volume = {8},
year = {2019}
}
@article{Zhou2018b,
abstract = {The discriminative ability of dictionary learning algorithms plays a crucial role in various computer vision applications, particularly in visual object tracking. In this paper, a novel visual tracking algorithm based on an online discriminative dictionary learning technique is proposed. The proposed method incorporates target and background information into dictionary learning in order to separate the target-of-interest from a cluttered background effectively. The dictionary thus learnt, can ensure that each class-specific sub-dictionary has a good representation of the samples associated with its own class and a poor representation of the other classes. In contrast to other dictionary learning mechanisms, the proposed method also introduces an error term that aims to capture outliers (e.g., noise and occlusion) and minimize its effect on tracking. Furthermore, by optimizing a constrained objective function, the learnt dictionary is rendered robust and discriminative, thereby resulting in an accurate tracking framework that can efficiently separate the target from the background. Finally, an effective and simple observation likelihood function based on the reconstruction errors from both positive and negative templates is designed to achieve better tracking performance. Experimental results on a publicly available benchmark dataset demonstrate that the proposed tracking algorithm performs better than several baseline trackers.},
author = {Zhou, Tao and Liu, Fanghui and Bhaskar, Harish and Yang, Jie and Zhang, Huanlong and Cai, Ping},
doi = {10.1016/j.neucom.2017.10.019},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231217316703-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Class-specific sub-dictionary,Discriminative dictionary learning,Likelihood function,Visual tracking},
pages = {1801--1812},
publisher = {Elsevier B.V.},
title = {{Online discriminative dictionary learning for robust object tracking}},
url = {https://doi.org/10.1016/j.neucom.2017.10.019},
volume = {275},
year = {2018}
}
@article{Liu2019e,
abstract = {Robust object tracking has widespread applications in human motion analysis systems, but it is challenging due to various factors, such as occlusion, illumination variation, and complex backgrounds. In this paper, we present a novel tracking method on the basis of a constrained online dictionary learning algorithm. Some existing tracking methods cannot consider background effects and thus have weak discriminative ability. Moreover, some dictionary learning-based tracking methods directly collect target templates and background templates as positive and negative dictionaries, respectively. The main issue is that the dictionaries cannot effectively represent the target and background and handle appearance changes. Thus, a constrained online dictionary learning algorithm is proposed to obtain a discriminative dictionary, which can ensure that the proposed tracker has good discriminative ability in distinguishing targets from complex backgrounds. Experimental results show that the proposed algorithm performs favorably against other state-of-the-art methods in terms of accuracy and robustness.},
author = {Liu, Na and Huo, Hong and Fang, Tao},
doi = {10.1007/s11042-017-5538-4},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Liu2019{\_}Article{\_}RobustObjectTrackingViaConstra.pdf:pdf},
isbn = {1104201755},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Appearance changes,Dictionary learning,Human motion analysis,Object tracking},
number = {3},
pages = {3689--3703},
publisher = {Multimedia Tools and Applications},
title = {{Robust object tracking via constrained online dictionary learning}},
volume = {78},
year = {2019}
}
@article{Schnass2018,
abstract = {In this work we show that iterative thresholding and K means (ITKM) algorithms can recover a generating dictionary with K atoms from noisy S sparse signals up to an error $\epsilon$˜ as long as the initialisation is within a convergence radius, that is up to a log⁡K factor inversely proportional to the dynamic range of the signals, and the sample size is proportional to Klog⁡K$\epsilon$˜ −2 . The results are valid for arbitrary target errors if the sparsity level is of the order of the square root of the signal dimension d and for target errors down to K −ℓ if S scales as S≤d/(ℓlog⁡K).},
author = {Schnass, Karin},
doi = {10.1016/j.acha.2016.08.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1063520316300458-main.pdf:pdf},
issn = {1096603X},
journal = {Applied and Computational Harmonic Analysis},
keywords = {Alternating optimisation,Convergence radius,Dictionary learning,K-means,Sample complexity,Sparse coding,Sparse component analysis,Thresholding},
number = {1},
pages = {22--58},
publisher = {Elsevier Inc.},
title = {{Convergence radius and sample complexity of ITKM algorithms for dictionary learning}},
url = {http://dx.doi.org/10.1016/j.acha.2016.08.002},
volume = {45},
year = {2018}
}
@article{Li2019,
abstract = {This paper presents a "structured" learning approach for the identification of continuous partial differential equation (PDE) models with both constant and spatial-varying coefficients. The identification problem of parametric PDEs can be formulated as an ℓ 1 /ℓ 2 -mixed optimization problem by explicitly using block structures. Block-sparsity is used to ensure parsimonious representations of parametric spatiotemporal dynamics. An iterative reweighted ℓ 1 /ℓ 2 algorithm is proposed to solve the ℓ 1 /ℓ 2 -mixed optimization problem. In particular, the estimated values of varying coefficients are further used as data to identify functional forms of the coefficients. In addition, a new type of structured random dictionary matrix is constructed for the identification of constant-coefficient PDEs by introducing randomness into a bounded system of Legendre orthogonal polynomials. By exploring the restricted isometry properties of the structured random dictionary matrices, we derive a recovery condition that relates the number of samples to the sparsity and the probability of failure in the Lasso scheme. Numerical examples, such as the Schr{\"{o}}dinger equation, the Fisher-Kolmogorov-Petrovsky-Piskunov equation, the Burger equation, and the Fisher equation, suggest that the proposed algorithm is fairly effective, especially when using a limited amount of measurements.},
author = {Li, Xiuting and Li, Liang and Yue, Zuogong and Tang, Xiaoquan and Voss, Henning U. and Kurths, J{\"{u}}rgen and Yuan, Ye},
doi = {10.1063/1.5054708},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Sparse learning of partial differential equations with structured dictionary matrix.pdf:pdf},
issn = {10541500},
journal = {Chaos},
number = {4},
title = {{Sparse learning of partial differential equations with structured dictionary matrix}},
volume = {29},
year = {2019}
}
@article{Zhang2018e,
abstract = {Recognizing human actions across different views is challenging, since observations of the same action often vary greatly with viewpoints. To solve this problem, most existing methods explore the cross-view feature transfer relationship at video level only, ignoring the sequential composition of action segments therein. In this paper, we propose a novel hierarchical transfer framework, which is based on an action temporal-structure model that contains sequential relationship between action segments at multiple timescales. Thus, it can capture the view invariance of the sequential relationship of segment-level transfer. Additionally, we observe that the original feature distributions under different views differ greatly, leading to view-dependent representations irrelevant to the intrinsic structure of actions. Thus, at each level of the proposed framework, we transform the original feature spaces of different views to a view-shared low-dimensional feature space, and jointly learn a dictionary in this space for these views. This view-shared dictionary captures the common structure of action data across the views and can represent the action segments in a way robust to view changes. Moreover, the proposed method can be kernelized easily, and operate in both unsupervised and supervised cross-view scenarios. Extensive experimental results on the IXMAS and WVU datasets demonstrate superiority of the proposed method over state-of-the-art methods.},
author = {Zhang, Chengkun and Zheng, Huicheng and Lai, Jianhuang},
doi = {10.1109/ACCESS.2018.2815611},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08315006.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Cross-view,action recognition,dictionary learning,feature space transformation,hierarchical transfer learning},
pages = {16855--16868},
publisher = {IEEE},
title = {{Cross-View Action Recognition Based on Hierarchical View-Shared Dictionary Learning}},
volume = {6},
year = {2018}
}
@article{Zhu2013,
abstract = {Data provided by most optical Earth observation satellites such as IKONOS, QuickBird, and GeoEye are composed of a panchromatic channel of high spatial resolution (HR) and several multispectral channels at a lower spatial resolution (LR). The fusion of an HR panchromatic and the corresponding LR spectral channels is called "pan-sharpening." It aims at obtaining an HR multispectral image. In this paper, we propose a new pan-sharpening method named Sparse Fusion of Images (SparseFI, pronounced as "sparsify"). SparseFI is based on the compressive sensing theory and explores the sparse representation of HR/LR multispectral image patches in the dictionary pairs cotrained from the panchromatic image and its downsampled LR version. Compared with conventional methods, it "learns" from, i.e., adapts itself to, the data and has generally better performance than existing methods. Due to the fact that the SparseFI method does not assume any spectral composition model of the panchromatic image and due to the super-resolution capability and robustness of sparse signal reconstruction algorithms, it gives higher spatial resolution and, in most cases, less spectral distortion compared with the conventional methods. {\textcopyright} 2012 IEEE.},
author = {Zhu, Xiao Xiang and Bamler, Richard},
doi = {10.1109/TGRS.2012.2213604},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Zhu-2013-A-sparse-image-fusion-algorithm-wit.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Data fusion,Dictionary training,Pan-sharpening,SL1MMER,Sparse coefficients estimation,Sparse fusion of images (SparseFI)},
number = {5},
pages = {2827--2836},
publisher = {IEEE},
title = {{A sparse image fusion algorithm with application to pan-sharpening}},
volume = {51},
year = {2013}
}
@article{Qi2018,
abstract = {Dictionary learning aims to find a dictionary where signals in some ensemble have sparse representations, and has been successfully applied for classification. However, traditional dictionary learning methods for classification assume there is no outlier in the training data, which may not be the case in practical applications. In this paper, we propose a new discriminative dictionary learning framework for classification, which simultaneously learns a discriminative dictionary and detects outliers in the data. The dictionary learning framework is formulated into an optimization problem with designed regularizers to promote both the discrimination and outlier-detection capability. We demonstrate the superior performance of the proposed approach in comparison with state-of-the-art alternatives by conducting extensive experiments on various image classification tasks.},
author = {Qi, Jiaming and Chen, Wei},
doi = {10.1016/j.sigpro.2018.06.005},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168418302020-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Classification,Dictionary learning,Sparse representation},
pages = {255--264},
publisher = {Elsevier B.V.},
title = {{Learning a discriminative dictionary for classification with outliers}},
url = {https://doi.org/10.1016/j.sigpro.2018.06.005},
volume = {152},
year = {2018}
}
@article{Liao2019,
abstract = {Dictionary learning plays an important role in sparse representation based face recognition. Many dictionary learning algorithms have been successfully applied to face recognition. However, for corrupted data because of noise or face variations (e.g. occlusion and large pose variation), their performances decline due to the disparity between domains. In this paper, we propose a face recognition algorithm based on dictionary learning and subspace learning (DLSL). In DLSL, a new subspace learning algorithm (SL) is proposed by using sparse constraint, low-rank technology and our label relaxation model to reduce the disparity between domains. Meanwhile, we propose a high-performance dictionary learning algorithm (HPDL) by constructing the embedding term, non-local self-similarity term, and time complexity drop term. In the obtained subspace, we use HPDL to classify these mapped test samples. DLSL is compared with other 28 algorithms on FRGC, LFW, CVL, Yale B and AR face databases. Experimental results show that DLSL achieves better performance than those 28 algorithms, including many state-of-the-art algorithms, such as recurrent regression neural network (RRNN), multimodal deep face recognition (MDFR) and projective low-rank representation (PLR).},
author = {Liao, Mengmeng and Gu, Xiaodong},
doi = {10.1016/j.dsp.2019.04.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Facerecognitionbasedondictionarylearningandsubspacelearning.pdf:pdf},
issn = {10512004},
journal = {Digital Signal Processing: A Review Journal},
keywords = {Dictionary learning,Face recognition,Label relaxation model,Subspace learning},
pages = {110--124},
publisher = {Elsevier Inc.},
title = {{Face recognition based on dictionary learning and subspace learning}},
url = {https://doi.org/10.1016/j.dsp.2019.04.006},
volume = {90},
year = {2019}
}
@article{Zou2018,
abstract = {This paper develops a Bayesian dictionary learning method for hyperspectral image super resolution in the presence of mixed Poisson–Gaussian noise. A likelihood function is first designed to deal with the mixed Poisson–Gaussian noise. A fusion optimization model is then introduced, including the data-fidelity term capturing the statistics of mixed Poisson–Gaussian noise, and a beta process analysis-based sparse representation regularization term. In order to implement the proposed method, we use alternating direction method of multipliers (ADMM) for simultaneous Bayesian nonparametric dictionary learning and image estimation. Compared with conventional dictionary learning methods, the introduced dictionary learning method is based on a popular beta process factor analysis (BPFA) for an adaptive learning performance. Simulation results illustrate that the proposed method has a better performance than several well-known methods in terms of quality indices and reconstruction visual effects.},
author = {Zou, Changzhong and Xia, Youshen},
doi = {10.1016/j.image.2017.09.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S092359651730156X-main.pdf:pdf},
issn = {09235965},
journal = {Signal Processing: Image Communication},
keywords = {Alternating direction method of multipliers,Bayesian dictionary learning,Hyperspectral image,Mixed Poisson–Gaussian noise,Multispectral image},
number = {September 2017},
pages = {29--41},
publisher = {Elsevier Ltd},
title = {{Bayesian dictionary learning for hyperspectral image super resolution in mixed Poisson–Gaussian noise}},
url = {http://dx.doi.org/10.1016/j.image.2017.09.003},
volume = {60},
year = {2018}
}
@article{Wang2014,
abstract = {In this paper, a novel model-based pan-sharpening method via sparse representation and local autoregressive (AR) model is proposed. To recover the high-resolution multispectral (HRMS) image from the observed images, we impose sparsity prior on the unknown HRMS image in the restoration model. The quality of the recovered HRMS image depends on the employed sparse domain. Hence, a new sparse representation model for the HRMS image is constructed, in which we suppose that the low-frequency and high-frequency components of the HRMS image can be sparsely represented by a spectral dictionary and a spatial-detail dictionary respectively. The spectral dictionary and spatial-detail dictionary are learned from the source images: low-spatial-resolution multispectral (LRMS) image and high-spatial-resolution panchromatic (HRP) image adaptively. Additionally, local autoregressive (AR) model is employed to improve the spatial structure of the HRMS image patch. Firstly, a set of AR model parameters are learned from the PAN image patches. Then, the local spatial structure of a given HRMS image patch is regularized by an AR model with the learned parameters. By solving the l1 -norm optimization problem, the HRMS image can be well reconstructed. Experiments are carried out on very high-resolution QuickBird and GeoEye-1 images. In the simulated and real experiments, our proposed method demonstrates its good performance in terms of visual analysis and quantitative evaluation. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
author = {Wang, Wenqing and Jiao, Licheng and Yang, Shuyuan},
doi = {10.1016/j.inffus.2013.11.004},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Wang-2014-Fusion-of-multispectral-and-panchro.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Fusion,Local autoregressive model (AR),Multispectral (MS),Panchromatic (PAN),Sparse representation},
number = {1},
pages = {73--87},
publisher = {Elsevier B.V.},
title = {{Fusion of multispectral and panchromatic images via sparse representation and local autoregressive model}},
url = {http://dx.doi.org/10.1016/j.inffus.2013.11.004},
volume = {20},
year = {2014}
}
@article{Liu2018e,
abstract = {Convolutional sparse representations are a form of sparse representation with a structured, translation-invariant dictionary. Most convolutional dictionary learning algorithms to date operate in batch mode, requiring simultaneous access to all training images during the learning process, which results in very high memory usage and severely limits the training data size that can be used. Very recently, however, a number of authors have considered the design of online convolutional dictionary learning algorithms that offer far better scaling of memory and computational cost with training set size than batch methods. This paper extends our prior work, improving a number of aspects of our previous algorithm; proposing an entirely new one, with better performance, that supports the inclusion of a spatial mask for learning from incomplete data; and providing a rigorous theoretical analysis of these methods.},
archivePrefix = {arXiv},
arxivId = {1709.00106},
author = {Liu, Jialin and Garcia-Cardona, Cristina and Wohlberg, Brendt and Yin, Wotao},
doi = {10.1137/17M1145689},
eprint = {1709.00106},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/17m1145689.pdf:pdf},
issn = {19364954},
journal = {SIAM Journal on Imaging Sciences},
keywords = {Convolutional dictionary learning,Convolutional sparse coding,Online dictionary learning,Recursive least squares,Stochastic gradient descent},
number = {2},
pages = {1589--1628},
title = {{First- and second-order methods for online convolutional dictionary learning}},
volume = {11},
year = {2018}
}
@article{Gao2017,
author = {Gao, Zhisheng and Zhang, Chengfang},
doi = {10.1016/j.ijleo.2016.09.126},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Gao-2016-Texture-clear-multi-modal-image-fus.pdf:pdf},
issn = {0030-4026},
journal = {Optik - International Journal for Light and Electron Optics},
keywords = {joint sparsity model,multi-modal image fusion},
pages = {255--265},
publisher = {Elsevier GmbH.},
title = {{Optik Texture clear multi-modal image fusion with joint sparsity model}},
url = {http://dx.doi.org/10.1016/j.ijleo.2016.09.126},
volume = {130},
year = {2017}
}
@article{Asha2019,
abstract = {Recently, medical image fusion has emerged as an impressive technique in
merging the medical images of different modalities. Certainly, the fused
image assists the physician in disease diagnosis for effective treatment
planning. The fusion process combines multi-modal images to incur a
single image with excellent quality, retaining the information of
original images. This paper proposes a multi-modal medical image fusion
through a weighted blending of high-frequency subbands of nonsubsampled
shearlet transform (NSST) domain via chaotic grey wolf optimization
algorithm. As an initial step, the NSST is applied on source images to
decompose into the multi-scale and multi-directional components. The
low-frequency bands are fused based on a simple max rule to sustain the
energy of an individual. The texture details of input images are
preserved by an adaptively weighted combination of high-frequency images
using a recent chaotic grey wolf optimization algorithm to minimize the
distance between the fused image and source images. The entire process
emphasizes on retaining the energy of the low-frequency band and the
transferring of texture features from source images to the fused image.
Finally, the fused image is formed using inverse NSST of merged low and
high-frequency bands. The experiments are carried out on eight different
disease datasets obtained from Brain Atlas, which consists of MR-T1 and
MR-T2, MR and SPECT, MR and PET, and MR and CT. The effectiveness of the
proposed method is validated using more than 100 pairs of images based
on the subjective and objective quality assessment. The experimental
results confirm that the proposed method performs better in contrast
with the current state-of-the-art image fusion techniques in terms of
entropy, VIFF, and FMI. Hence, the proposed method will be helpful for
disease diagnosis, medical treatment planning, and surgical procedure.},
author = {Asha, C. S. and Lal, Shyam and Gurupur, Varadraj Prabhu and Saxena, P. U.Prakash},
doi = {10.1109/ACCESS.2019.2908076},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/05-2-Multi-Modal Bands Using Chaotic Grey Wolf .pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {MRI,NSST,PET,SPECT,chaotic function,grey Wolf optimization,image fusion},
pages = {40782--40796},
publisher = {IEEE},
title = {{Multi-Modal Medical Image Fusion with Adaptive Weighted Combination of NSST Bands Using Chaotic Grey Wolf Optimization}},
volume = {7},
year = {2019}
}
@article{Hu2018,
abstract = {In this paper, we propose a new nonlinear dictionary learning (NDL) method and apply it to image classification. While a variety of dictionary learning algorithms have been proposed in recent years, most of them learn only a linear dictionary for feature learning and encoding, which cannot exploit the nonlinear relationship of image samples for feature extraction. Even though kernel-based dictionary learning methods can address this limitation, they still suffer from the scalability problem. Unlike existing dictionary learning methods, our NDL employs a feed-forward neural network to seek hierarchical feature projection matrices and dictionary simultaneously, so that the nonlinear structure of samples can be well exploited for feature learning and encoding. To better exploit the discriminative information, we extend the NDL into supervised NDL (SNDL) by learning a class-specific dictionary with the labels of training samples. Experimental results on four image datasets show the effectiveness of the proposed methods.},
author = {Hu, Junlin and Tan, Yap Peng},
doi = {10.1016/j.patcog.2017.02.009},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S003132031730050X-main.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Image classification,Neural network,Nonlinear dictionary learning,Sparse coding},
pages = {282--291},
publisher = {Elsevier Ltd},
title = {{Nonlinear dictionary learning with application to image classification}},
url = {https://doi.org/10.1016/j.patcog.2017.02.009},
volume = {75},
year = {2018}
}
@article{Zhang2019,
abstract = {To improve the quality of the super-resolution (SR) reconstructed medical images, an improved adaptive multi-dictionary learning method is proposed, which uses the combined information of medical image itself and the natural images database. In training dictionary section, it uses the upper layer images of pyramid which are generated by the self-similarity of low resolution images. In reconstruction section, the top layer image of pyramid is taken as the initial reconstruction image, and medical image's SR reconstruction is achieved by regularization term which is the non-local structure self-similarity of the image. This method can make full use of the same scale and different scale similar information of medical images. Simulation experiments are carried out on natural images and medical images, and the experimental results show the proposed method is effective for improving the effect of medical image SR reconstruction.},
author = {Zhang, Fang and Wu, Yue and Xiao, Zhitao and Geng, Lei and Wu, Jun and Wen, Jia and Wang, Wen and Liu, Ping},
doi = {10.1080/24699322.2018.1560092},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Super resolution reconstruction for medical image based on adaptive multi dictionary learning and structural self similarity.pdf:pdf},
issn = {24699322},
journal = {Computer Assisted Surgery},
keywords = {Super-resolution reconstruction,improved adaptive multi-dictionary learning,medical image,non-local structural similarity},
title = {{Super resolution reconstruction for medical image based on adaptive multi-dictionary learning and structural self-similarity}},
volume = {9322},
year = {2019}
}
@article{Lin2019,
abstract = {Ship detection with polarimetric synthetic aperture radar (PolSAR) has received increasing attention for its wide usage in maritime applications. However, extracting discriminative features to implement ship detection is still a challenging problem. In this paper, we propose a novel ship detection method for PolSAR images via task-driven discriminative dictionary learning (TDDDL). An assumption that ship and clutter information are sparsely coded under two separate dictionaries is made. Contextual information is considered by imposing superpixel-level joint sparsity constraints. In order to amplify the discrimination of the ship and clutter, we impose incoherence constraints between the two sub-dictionaries in the objective of feature coding. The discriminative dictionary is trained jointly with a linear classifier in task-driven dictionary learning (TDDL) framework. Based on the learnt dictionary and classifier, we extract discriminative features by sparse coding, and obtain robust detection results through binary classification. Different from previous methods, our ship detection cue is obtained through active learning strategies rather than artificially designed rules, and thus, is more adaptive, effective and robust. Experiments performed on synthetic images and two RADARSAT-2 images demonstrate that our method outperforms other comparative methods. In addition, the proposed method yields better shape-preserving ability and lower computation cost.},
author = {Lin, Huiping and Chen, Hang and Wang, Hongmiao and Yin, Junjun and Yang, Jian},
doi = {10.3390/rs11070769},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-Ship Detection for PolSAR Images via Task-Driven Discriminative Dictionary Learning.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Contextual information,Incoherence constraints,Polarimetric synthetic aperture radar (PolSAR),Ship detection,Task-driven discriminative dictionary learning (TD},
number = {7},
title = {{Ship detection for PolSAR images via task-driven discriminative dictionary learning}},
volume = {11},
year = {2019}
}
@article{Mahdizadehaghdam2019,
abstract = {Deep dictionary learning seeks multiple dictionaries at different image scales to capture complementary coherent characteristics. We propose a method for learning a hierarchy of synthesis dictionaries with an image classification goal. The dictionaries and classification parameters are trained by a classification objective, and the sparse features are extracted by reducing a reconstruction loss in each layer. The reconstruction objectives in some sense regularize the classification problem and inject source signal information in the extracted features. The performance of the proposed hierarchical method increases by adding more layers, which consequently makes this model easier to tune and adapt. The proposed algorithm furthermore, shows remarkably lower fooling rate in presence of adversarial perturbation. The validation of the proposed approach is based on its classification performance using four benchmark datasets and is compared to a CNN of similar size.},
archivePrefix = {arXiv},
arxivId = {1803.04022},
author = {Mahdizadehaghdam, Shahin and Panahi, Ashkan and Krim, Hamid and Dai, Liyi},
doi = {10.1109/tip.2019.2914376},
eprint = {1803.04022},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08708973.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
number = {10},
pages = {4790--4802},
title = {{Deep Dictionary Learning: A PARametric NETwork Approach}},
volume = {28},
year = {2019}
}
@article{Zhao2019,
abstract = {Extracting impulsive information under strong background noise and harmonic interference is a challenging problem for bearing fault diagnosis. Multi-scale transforms have achieved great success in extracting impulsive feature information, however, how to choose a suitable transform is a difficult problem, especially in the case of strong noise interference. Therefore, dictionary learning methods have attracted more and more attention in recent years. A weighted multi-scale dictionary learning model (WMSDL) is proposed in this paper which integrates the multi-scale transform and fault information into a unified dictionary learning model and it successfully overcomes four disadvantages of traditional dictionary learning algorithms including lacking the multi-scale property; restricting training samples to local patches; being sensitive to strong harmonic interference; suffering from high computational complexity. Moreover, algorithmic derivation, computational complexity and parameter selection are discussed. Finally, The effectiveness of the proposed method is verified by both the numerical simulations and experiments. Comparisons with other state-of-the-art methods further demonstrate the superiority of the proposed method.},
author = {Zhao, Zhibin and Qiao, Baijie and Wang, Shibin and Shen, Zhixian and Chen, Xuefeng},
doi = {10.1016/j.jsv.2019.01.042},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-A weighted multi-scale dictionary learning model and itsapplications on bearing fault diagnosis.pdf:pdf},
issn = {10958568},
journal = {Journal of Sound and Vibration},
keywords = {Fault diagnosis,Planetary bearing,Sparse representation,Strong interference,Weighted multi-scale dictionary learning},
pages = {429--452},
publisher = {Elsevier Ltd},
title = {{A weighted multi-scale dictionary learning model and its applications on bearing fault diagnosis}},
url = {https://doi.org/10.1016/j.jsv.2019.01.042},
volume = {446},
year = {2019}
}
@article{Sarkar2018,
abstract = {In image classification, obtaining adequate data to learn a robust classifier has often proven to be difficult in several scenarios. Classification of histological tissue images for health care analysis is a notable application in this context due to the necessity of surgery, biopsy or autopsy. To adequately exploit limited training data in classification, we propose a saliency guided dictionary learning method and subsequently an image similarity technique for histo-pathological image classification. Salient object detection from images aids in the identification of discriminative image features. We leverage the saliency values for the local image regions to learn a dictionary and respective sparse codes for an image, such that the more salient features are reconstructed with smaller error. The dictionary learned from an image gives a compact representation of the image itself and is capable of representing images with similar content, with comparable sparse codes. We employ this idea to design a similarity measure between a pair of images, where local image features of one image, are encoded with the dictionary learned from the other and vice versa. To effectively utilize the learned dictionary, we take into account the contribution of each dictionary atom in the sparse codes to generate a global image representation for image comparison. The efficacy of the proposed method was evaluated using three tissue data sets that consist of mammalian kidney, lung and spleen tissue, breast cancer, and colon cancer tissue images. From the experiments, we observe that our methods outperform the state of the art with an increase of 14.2{\%} in the average classification accuracy over all data sets.},
author = {Sarkar, Rituparna and Acton, Scott T.},
doi = {10.1109/TIP.2017.2763829},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08070340.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Dictionary learning,Image similarity,Saliency,Sparse representation,Tissue image classification},
number = {2},
pages = {749--763},
publisher = {IEEE},
title = {{SDL: Saliency-Based Dictionary Learning Framework for Image Similarity}},
volume = {27},
year = {2018}
}
@article{Song2019,
abstract = {Traditional collaborative representation based classification (CRC) method usually faces the challenge of data uncertainty hence results in poor performance, especially in the presence of appearance variations in pose, expression and illumination. To overcome this issue, this paper presents a CRC-based face classification method by jointly using block weighted LBP and analysis dictionary learning. To this end, we first design a block weighted LBP histogram algorithm to form a set of local histogram-based feature vectors instead of using raw images. By this means we are able to effectively decrease data redundancy and uncertainty derived from image noises and appearance variations. Second, we adopt an analysis dictionary learning model as the projection transform to construct an analysis subspace, in which a new sample is characterized with the improved sparsity of its reconstruction coefficient vector. The crucial role of the analysis dictionary learning method in CRC is revealed by its capacity of the collaborative representation in an analytic coefficient space. Extensive experimental results conducted on a set of well-known face databases demonstrate the merits of the proposed method.},
author = {Song, Xiaoning and Chen, Youming and Feng, Zhen Hua and Hu, Guosheng and Zhang, Tao and Wu, Xiao Jun},
doi = {10.1016/j.patcog.2018.11.008},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-CollaborativerepresentationbasedfaceclassificationexploitingblockweightedLBPandanalysisdictionarylearning.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Analysis dictionary learning,Block weighted LBP,Collaborative representation based classification,Face classification},
pages = {127--138},
publisher = {Elsevier Ltd},
title = {{Collaborative representation based face classification exploiting block weighted LBP and analysis dictionary learning}},
url = {https://doi.org/10.1016/j.patcog.2018.11.008},
volume = {88},
year = {2019}
}
@article{Du2017,
abstract = {A novel method for performing anatomical magnetic resonance imaging-functional (positron emission tomography or single photon emission computed tomography) image fusion is presented. The method merges specific feature information from input image signals of a single or multiple medical imaging modalities into a single fused image, while preserving more information and generating less distortion. The proposed method uses a local Laplacian filtering-based technique realized through a novel multi-scale system architecture. First, the input images are generated in a multi-scale image representation and are processed using local Laplacian filtering. Second, at each scale, the decomposed images are combined to produce fused approximate images using a local energy maximum scheme and produce the fused residual images using an information of interest-based scheme. Finally, a fused image is obtained using a reconstruction process that is analogous to that of conventional Laplacian pyramid transform. Experimental results computed using individual multi-scale analysis-based decomposition schemes or fusion rules clearly demonstrate the superiority of the proposed method through subjective observation as well as objective metrics. Furthermore, the proposed method can obtain better performance, compared with the state-of-the-art fusion methods.},
author = {Du, Jiao and Li, Weisheng and Xiao, Bin},
doi = {10.1109/TIP.2017.2745202},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/LLF{\_}IOI.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Image fusion,interest-based rule,multi-scale decomposition},
number = {12},
pages = {5855--5866},
publisher = {IEEE},
title = {{Anatomical-Functional Image Fusion by Information of Interest in Local Laplacian Filtering Domain}},
volume = {26},
year = {2017}
}
@article{Ma2019,
abstract = {Image fusion can be regarded as how to integrate complementary information in images with different focal region together. However, except for complementary information, there is also redundant information in source images. To obtain a better fused image, an efficient image fusion method based on sparse representation and optimal solution was proposed in this paper. Firstly, we obtained adaptive dictionaries based on source images themselves by K-means singular value decomposition. Then, we combined a fixed dictionary with adaptive dictionaries to obtain the joint dictionary. By sparse coding source images with the final joint dictionary, complementary and redundant components could be apart. Next, the optimum theory was employed to fuse complementary components and an optimal solution could be obtained by orthogonal matching pursuit. A fused image was constructed by sparse representation at last. Experimental results showed the proposed method had better visual effects and objective valuable index values.},
author = {Ma, Xiaole and Hu, Shaohai and Liu, Shuaiqi and Fang, Jing and Xu, Shuwen},
doi = {10.1016/j.image.2019.06.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Multi-focus image fusion based on joint sparse representation and optimumtheory.pdf:pdf},
issn = {09235965},
journal = {Signal Processing: Image Communication},
keywords = {Joint sparse representation,Multi-focus image fusion,Optimum theory,Orthogonal matching pursuit},
number = {May},
pages = {125--134},
publisher = {Elsevier Ltd},
title = {{Multi-focus image fusion based on joint sparse representation and optimum theory}},
url = {https://doi.org/10.1016/j.image.2019.06.002},
volume = {78},
year = {2019}
}
@article{Shu2018,
abstract = {Age progression is defined as aesthetically re-rendering the aging face at any future age for an individual face. In this work, we aim to automatically render aging faces in a personalized way. Basically, for each age group, we learn an aging dictionary to reveal its aging characteristics (e.g., wrinkles), where the dictionary bases corresponding to the same index yet from two neighboring aging dictionaries form a particular aging pattern cross these two age groups, and a linear combination of all these patterns expresses a particular personalized aging process. Moreover, two factors are taken into consideration in the dictionary learning process. First, beyond the aging dictionaries, each person may have extra personalized facial characteristics, e.g., mole, which are invariant in the aging process. Second, it is challenging or even impossible to collect faces of all age groups for a particular person, yet much easier and more practical to get face pairs from neighboring age groups. To this end, we propose a novel Bi-level Dictionary Learning based Personalized Age Progression (BDL-PAP) method. Here, bi-level dictionary learning is formulated to learn the aging dictionaries based on face pairs from neighboring age groups. Extensive experiments well demonstrate the advantages of the proposed BDL-PAP over other state-of-the-arts in term of personalized age progression, as well as the performance gain for cross-age face verification by synthesizing aging faces.},
archivePrefix = {arXiv},
arxivId = {1706.01039},
author = {Shu, Xiangbo and Tang, Jinhui and Li, Zechao and Lai, Hanjiang and Zhang, Liyan and Yan, Shuicheng},
doi = {10.1109/TPAMI.2017.2705122},
eprint = {1706.01039},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/07930470.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Age progression,aging dictionary,dictionary learning,face synthesis},
number = {4},
pages = {905--917},
publisher = {IEEE},
title = {{Personalized Age Progression with Bi-Level Aging Dictionary Learning}},
volume = {40},
year = {2018}
}
@article{Chen2001,
author = {Chen, Scott Shaobing and Donoho, David L and Saunders, Michael A},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/10.1.1.86.5247.pdf:pdf},
keywords = {1 norm optimization,cosine pack-,denoising,ets,interior-point methods for linear,matching pursuit,multiscale,overcomplete signal representation,programming,time-frequency analysis,time-scale anal-,total variation denoising,wavelet packets,wavelets,ysis},
number = {1},
pages = {129--159},
title = {{Pursuit ∗}},
volume = {43},
year = {2001}
}
@article{Yang2008,
abstract = {As a novel multiscale geometric analysis tool, contourlet has shown many advantages over the conventional image representation methods. In this paper, a new fusion algorithm for multimodal medical images based on contourlet transform is proposed. All fusion operations are performed in contourlet domain. A novel contourlet contrast measurement is developed, which is proved to be more suitable for human vision system. Other fusion rules like local energy, weighted average and selection are combined with "region" idea for coefficient selection in the lowpass and highpass subbands, which can preserve more details in source images and further improve the quality of fused image. The final fusion image is obtained by directly applying inverse contourlet transform to the fused lowpass and highpass subbands. Extensive fusion experiments have been made on three groups of multimodality CT/MR dataset, both visual and quantitative analysis show that comparing with conventional image fusion algorithms, the proposed approach can provide a more satisfactory fusion outcome. {\textcopyright} 2008.},
author = {Yang, L. and Guo, B. L. and Ni, W.},
doi = {10.1016/j.neucom.2008.02.025},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Yang-2008-Multimodality-medical-image-fusion-.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Contourlet transform,Image fusion,Medical image,Multimodality},
number = {1-3},
pages = {203--211},
title = {{Multimodality medical image fusion based on multiscale geometric analysis of contourlet transform}},
volume = {72},
year = {2008}
}
@article{Wu2018,
abstract = {We propose to apply a novel incoherent dictionary learning (IDL) algorithm for regularizing the least-squares inversion in seismic imaging. The IDL is proposed to overcome the drawback of traditional dictionary learning algorithm in losing partial texture information. Firstly, the noisy image is divided into overlapped image patches, and some random patches are extracted for dictionary learning. Then, we apply the IDL technology to minimize the coherency between atoms during dictionary learning. Finally, the sparse representation problem is solved by a sparse coding algorithm, and image is restored by those sparse coefficients. By reducing the correlation among atoms, it is possible to preserve most of the small-scale features in the image while removing much of the long-wavelength noise. The application of the IDL method to regularization of seismic images from least-squares reverse time migration shows successful performance.},
author = {Wu, Juan and Bai, Min},
doi = {10.1016/j.cageo.2018.01.010},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0098300417309275-main.pdf:pdf},
issn = {00983004},
journal = {Computers and Geosciences},
keywords = {Computational seismology,LSRTM,Regularization,Reverse time migration,Seismic imaging,Simultaneous source},
number = {January},
pages = {11--21},
publisher = {Elsevier Ltd},
title = {{Incoherent dictionary learning for reducing crosstalk noise in least-squares reverse time migration}},
url = {https://doi.org/10.1016/j.cageo.2018.01.010},
volume = {114},
year = {2018}
}
@article{Wang2014b,
abstract = {For the quality of the fused outcome is determined by the amount of the information captured from the source images, thus, a multi-modal medical image fusion method is developed in the shift-invariant shearlet transform (SIST) domain. The two-state Hidden Markov Tree (HMT) model is extended into the SIST domain to describe the dependent relationships of the SIST coefficients of the cross-scale and inter-subbands. Base on the model, we explain why the conventional Average-Maximum fusion scheme is not the best rule for medical image fusion, and therefore a new scheme is developed, where the probability density function and standard deviation of the SIST coefficients are employed to calculate the fused coefficients. Finally, the fused image is obtained by directly applying the inverse SIST. Integrating the SIST and the HMT model, more spatial feature information of the singularities and more functional information contents can be preserved and transferred into the fused results. Visual and statistical analyses demonstrate that the fusion quality can be significantly improved over that of five typical methods in terms of entropy and mutual information, edge information, standard deviation, peak signal to noise and structural similarity. Besides, color distortion can be suppressed to a great extent, providing a better visual sense. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Wang, Lei and Li, Bin and Tian, Lian Fang},
doi = {10.1016/j.inffus.2012.03.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Wang-2014-Multi-modal-medical-image-fusion-us.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Hidden Markov Tree model,Image fusion,Medical image,Shearlet transform,Shift-invariance},
number = {1},
pages = {20--28},
publisher = {Elsevier B.V.},
title = {{Multi-modal medical image fusion using the inter-scale and intra-scale dependencies between image shift-invariant shearlet coefficients}},
url = {http://dx.doi.org/10.1016/j.inffus.2012.03.002},
volume = {19},
year = {2014}
}
@article{Zhou2018c,
abstract = {In this paper, we propose a novel and robust tracking framework based on online discriminative and low-rank dictionary learning. The primary aim of this paper is to obtain compact and low-rank dictionaries that can provide good discriminative representations of both target and background. We accomplish this by exploiting the recovery ability of low-rank matrices. That is if we assume that the data from the same class are linearly correlated, then the corresponding basis vectors learned from the training set of each class shall render the dictionary to become approximately low-rank. The proposed dictionary learning technique incorporates a reconstruction error that improves the reliability of classification. Also, a multiconstraint objective function is designed to enable active learning of a discriminative and robust dictionary. Further, an optimal solution is obtained by iteratively computing the dictionary, coefficients, and by simultaneously learning the classifier parameters. Finally, a simple yet effective likelihood function is implemented to estimate the optimal state of the target during tracking. Moreover, to make the dictionary adaptive to the variations of the target and background during tracking, an online update criterion is employed while learning the new dictionary. Experimental results on a publicly available benchmark dataset have demonstrated that the proposed tracking algorithm performs better than other state-of-the-art trackers.},
author = {Zhou, Tao and Liu, Fanghui and Bhaskar, Harish and Yang, Jie},
doi = {10.1109/TCYB.2017.2747998},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08031891.pdf:pdf},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
keywords = {Dictionary learning,likelihood function,low-rank,visual tracking},
number = {9},
pages = {2643--2655},
publisher = {IEEE},
title = {{Robust Visual Tracking via Online Discriminative and Low-Rank Dictionary Learning}},
volume = {48},
year = {2018}
}
@article{Zhu2019a,
author = {Zhu, Tao},
doi = {10.1016/j.neucom.2019.08.028},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231219311567-main.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Sparse dictionary learning,Double sparsity,Sparse,sparse dictionary learning},
pages = {226--235},
publisher = {Elsevier B.V.},
title = {{Sparse dictionary learning by block proximal gradient with global convergence}},
url = {https://doi.org/10.1016/j.neucom.2019.08.028},
volume = {367},
year = {2019}
}
@article{Xu2019a,
abstract = {This letter proposes a coupled compressed samples online robust learning (C 2 ORL) algorithm for constructing an adaptive analog-to-information conversion (AIC) structure. The C 2 ORL optimizes both the dictionary and the observation matrix in each mini-batch learning process. The compressed samples are used for learning to resolve the issue that both the analog received signals and the unstable reconstructed signals affected by reconstruction error are not suitable for direct training. Furthermore, the online mechanism and the robust objective functions are adopted in order to make the learning algorithm better matched for the requirements of the analog signal compressed sensing. Based on the C 2 , we construct an adaptive AIC structure, which can considerably improve the performance in the sense of minimizing the reconstruction error. Also, the structure is more tolerant to the outliers and the noise in the receive process and has denoising ability to improve the signal-to-noise ratio under the noise background. The mathematical expression shows that the proposed structure clearly reflects the optimization brought by the coupled learning algorithm. Finally, the experiments demonstrate that the proposed scheme considerably outperforms any existing approaches.},
author = {Xu, Hongyi and Zhang, Chaozhu and Kim, Il Min},
doi = {10.1109/LSP.2018.2880566},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08528837.pdf:pdf},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
keywords = {Adaptive AIC structure,analog signal compressed sensing,coupled optimization,robust dictionary learning},
number = {1},
pages = {139--143},
publisher = {IEEE},
title = {{Coupled Online Robust Learning of Observation and Dictionary for Adaptive Analog-to-Information Conversion}},
volume = {26},
year = {2019}
}
@article{Zhang2019a,
abstract = {Sucker rod pumping wells are systems that their operation states varies slowly. For a relatively new well, it is hard to collect all kinds of fault samples for training. Moreover, samples from different wells are not always have similar distributions, so directly using samples from other wells as the training data may hardly get good results. In this paper, a novel framework is proposed to solve the aforementioned problems. For the source data from one well and the target data from another well, a transform matrix is calculated to transfer these data into a common low dimensional subspace. In this subspace, the source data that contain all kinds of fault samples and the target data that lack some kinds of fault samples can be represented by a shared dictionary matrix. By introducing two idea regularization terms, the structure information of source data and target data are included into the dictionary learning process. So the obtained dictionary has discriminative ability. Extensive experiments are conducted to evaluate the effectiveness of the proposed method.},
author = {Zhang, Ao and Gao, Xianwen},
doi = {10.1016/j.neucom.2019.02.013},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Superviseddictionary-basedtransfersubspacelearningandapplicationsforfaultdiagnosisofsuckerrodpumpingsystems.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Dictionary learning,Fault diagnosis,Sucker rod pumping systems,Transfer learning},
pages = {293--306},
publisher = {Elsevier B.V.},
title = {{Supervised dictionary-based transfer subspace learning and applications for fault diagnosis of sucker rod pumping systems}},
url = {https://doi.org/10.1016/j.neucom.2019.02.013},
volume = {338},
year = {2019}
}
@article{Song2019b,
abstract = {{\textcopyright} 2019 Elsevier B.V. Many real world data, which we deal with today, often have very high dimensions. These high-dimensional data can be seen as collections of data points from a union of low-dimensional subspaces. Subspace clustering, one solution to the high-dimensional data problem, refers to a method by which a set of data points is divided into multiple clusters by finding multiple subspaces that fit each cluster. Most existing subspace clustering approaches construct an affinity matrix using the self-representation model, which can propagate disturbing noisy information because even noisy data points are used to represent the data; then, they perform spectral clustering on the obtained affinity matrix, which contains the irrelevant information about noise or outliers. This paper proposes a novel subspace clustering method based on the structured sparse PCA-based dictionary learning. Our proposed method learns the reduced dimensional dictionary and coefficient matrices using the structural information as well as sparsity of data. Then, the affinity matrix is constructed from inner product of the learned dictionary coefficient vectors, which shows the correlation among data points. The experimental results on three benchmark datasets verify that the proposed method outperforms state-of-the-art subspace clustering methods.},
author = {Song, Jinjoo and Yoon, Gangjoon and Hahn, Kwangsoo and Yoon, Sang Min},
doi = {10.1016/j.neucom.2019.07.025},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231219309658-main.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Subspace clustering,Dimensionality reduction,Struc},
pages = {1--10},
publisher = {Elsevier B.V.},
title = {{Subspace clustering via structure-enforced dictionary learning}},
volume = {362},
year = {2019}
}
@article{James2014a,
abstract = {Medical image fusion is the process of registering and combining multiple images from single or multiple imaging modalities to improve the imaging quality and reduce randomness and redundancy in order to increase the clinical applicability of medical images for diagnosis and assessment of medical problems. Multi-modal medical image fusion algorithms and devices have shown notable achievements in improving clinical accuracy of decisions based on medical images. This review article provides a factual listing of methods and summarizes the broad scientific challenges faced in the field of medical image fusion. We characterize the medical image fusion research based on (1) the widely used image fusion methods, (2) imaging modalities, and (3) imaging of organs that are under study. This review concludes that even though there exists several open ended technological and scientific challenges, the fusion of medical images has proved to be useful for advancing the clinical reliability of using medical imaging for medical diagnostics and analysis, and is a scientific discipline that has the potential to significantly grow in the coming years. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {James, Alex Pappachen and Dasarathy, Belur V.},
doi = {10.1016/j.inffus.2013.12.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1566253513001450-main.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Diagnostics,Image fusion,Medical image analysis,Medical imaging},
number = {1},
pages = {4--19},
publisher = {Elsevier B.V.},
title = {{Medical image fusion: A survey of the state of the art}},
url = {http://dx.doi.org/10.1016/j.inffus.2013.12.002},
volume = {19},
year = {2014}
}
@article{Hong2018,
abstract = {This paper considers the problem of simultaneously learning the Sensing Matrix and Sparsifying Dictionary (SMSD) on a large training dataset. To address the formulated joint learning problem, we propose an online algorithm that consists of a closed-form solution for optimizing the sensing matrix with a fixed sparsifying dictionary and a stochastic method for learning the sparsifying dictionary on a large dataset when the sensing matrix is given. Benefiting from training on a large dataset, the obtained compressive sensing (CS) system by the proposed algorithm yields a much better performance in terms of signal recovery accuracy than the existing ones. The simulation results on natural images demonstrate the effectiveness of the suggested online algorithm compared with the existing methods.},
archivePrefix = {arXiv},
arxivId = {1701.01000},
author = {Hong, Tao and Zhu, Zhihui},
doi = {10.1016/j.sigpro.2018.05.021},
eprint = {1701.01000},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168418301907-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Compressive sensing,Large dataset,Online learning,Sensing matrix design,Sparsifying dictionary},
pages = {188--196},
publisher = {Elsevier B.V.},
title = {{Online learning sensing matrix and sparsifying dictionary simultaneously for compressive sensing}},
url = {https://doi.org/10.1016/j.sigpro.2018.05.021},
volume = {153},
year = {2018}
}
@article{Lin2018a,
abstract = {For face recognition, conventional dictionary learning (DL) methods have some disadvantages. First, face images of the same person vary with facial expressions and pose, illumination and disguises, so it is hard to obtain a robust dictionary for face recognition. Second, they don't cover important components (e.g., particularity and disturbance) completely, which limit their performance. In the paper, we propose a novel robust and discriminative DL (RDDL) model. The proposed model uses sample diversities of the same face image to learn a robust dictionary, which includes class-specific dictionary atoms and disturbance dictionary atoms. These atoms can well represent the data from different classes. Discriminative regularizations on the dictionary and the representation coefficients are used to exploit discriminative information, which improves effectively the classification capability of the dictionary. The proposed RDDL is extensively evaluated on benchmark face image databases, and it shows superior performance to many state-of-the-art dictionary learning methods for face recognition.},
author = {Lin, Guojun and Yang, Meng and Shen, Linlin and Yang, Mingzhong and Xie, Mei},
doi = {10.1142/S0219691318400040},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Lin-2018-Robust-and-discriminative-dictionar.pdf:pdf},
issn = {02196913},
journal = {International Journal of Wavelets, Multiresolution and Information Processing},
keywords = {Dictionary learning,face recognition,sparse representation},
number = {2},
title = {{Robust and discriminative dictionary learning for face recognition}},
volume = {16},
year = {2018}
}
@article{Lei2018,
abstract = {Magnetic resonance (MR) simulators have recently gained popularity; it avoids the unnecessary radiation exposure associated with Computed Tomography (CT) when used for radiation therapy planning. We propose a method for pseudo CT estimation from MR images based on joint dictionary learning. Patient-specific anatomical features were extracted from the aligned training images and adopted as signatures for each voxel. The most relevant and informative features were identified to train the joint dictionary learning-based model. The well-trained dictionary was used to predict the pseudo CT of a new patient. This prediction technique was validated with a clinical study of 12 patients with MR and CT images of the brain. The mean absolute error (MAE), peak signal-to-noise ratio (PSNR), normalized cross correlation (NCC) indexes were used to quantify the prediction accuracy. We compared our proposed method with a state-of-the-art dictionary learning method. Overall our proposed method significantly improves the prediction accuracy over the state-of-the-art dictionary learning method. We have investigated a novel joint dictionary Iearning- based approach to predict CT images from routine MRIs and demonstrated its reliability. This CT prediction technique could be a useful tool for MRI-based radiation treatment planning or attenuation correction for quantifying PET images for PET/MR imaging.},
author = {Lei, Y. and Shu, H. K. and Tian, S. and Wang, T. and Liu, T. and Mao, H. and Shim, H. and Curran, W. J. and Yang, X.},
doi = {10.1109/EMBC.2018.8513475},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08513475.pdf:pdf},
isbn = {9781538636466},
issn = {1557170X},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
pages = {5150--5153},
title = {{Pseudo CT Estimation using Patch-based Joint Dictionary Learning}},
volume = {2018-July},
year = {2018}
}
@article{Lu2019,
abstract = {The monitoring of rotating machinery condition has been a critical component of the Industry 4.0 revolution in enhancing machine reliability and facilitating intelligent manufacturing. The introduction of condition-based monitoring has effectively reduced the catastrophic events and maintenance cost across various industries. One of the major challenges of the diagnosis remains as majority of the diagnostic model requires off-line analysis and human intervention. The offline analysis, which is normally done by previous experience, involves tuning model parameters to improve the performance of the diagnostic model. However, for newly developed models, the knowledge of the unknown parameters does not exist. One way to resolve this issue is through learning using adaptation. The adaptation algorithm adjusts itself by newly acquired data. Hence, improvement of the model performance is achieved. In this paper, a nonlinear adaptive dictionary learning algorithm is proposed to achieve early fault detection of bearing elements without using the conventional computation heavy algorithm to update the dictionary. Deterministic and random data separation is implemented using the autoregressive model to reduce the background noise. The filtered data is further analyzed by the Infogram to reveal the impulsiveness and cyclostationary signature of the vibration signal. The dictionary is initialized using random parameters. Instead of using the k means singular value decomposition algorithm to compute the dictionary for adaptation, the unscented Kalman filter (UKF) is implemented to update the dictionaries using the filtered signal from the Infogram. The updating algorithm does not require computation of the dictionary, and no previous knowledge of the dictionary's parameters is needed. The updated dictionary contains the detected fault signature from the Infogram and, therefore, is used for further fault analysis. The proposed algorithm has the advantage of self-adaptation, the capability to map the non-linear relationship of the signal and dictionary weights. The algorithm can be used in the various condition-based monitoring of rotating machineries to avoid additional human efforts and improve the performance of the diagnostic model.},
author = {Lu, Yanfei and Xie, Rui and Liang, Steven Y.},
doi = {10.1007/s00170-019-03455-1},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Bearing fault diagnosis with nonlinear adaptive dictionary learning.pdf:pdf},
issn = {14333015},
journal = {International Journal of Advanced Manufacturing Technology},
keywords = {Adaptive algorithm,Ball bearing,Dictionary learning,Fault diagnosis},
pages = {4227--4239},
publisher = {The International Journal of Advanced Manufacturing Technology},
title = {{Bearing fault diagnosis with nonlinear adaptive dictionary learning}},
year = {2019}
}
@article{Wang2014a,
abstract = {For the quality of the fused outcome is determined by the amount of the information captured from the source images, thus, a multi-modal medical image fusion method is developed in the shift-invariant shearlet transform (SIST) domain. The two-state Hidden Markov Tree (HMT) model is extended into the SIST domain to describe the dependent relationships of the SIST coefficients of the cross-scale and inter-subbands. Base on the model, we explain why the conventional Average-Maximum fusion scheme is not the best rule for medical image fusion, and therefore a new scheme is developed, where the probability density function and standard deviation of the SIST coefficients are employed to calculate the fused coefficients. Finally, the fused image is obtained by directly applying the inverse SIST. Integrating the SIST and the HMT model, more spatial feature information of the singularities and more functional information contents can be preserved and transferred into the fused results. Visual and statistical analyses demonstrate that the fusion quality can be significantly improved over that of five typical methods in terms of entropy and mutual information, edge information, standard deviation, peak signal to noise and structural similarity. Besides, color distortion can be suppressed to a great extent, providing a better visual sense. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Wang, Lei and Li, Bin and Tian, Lian Fang},
doi = {10.1016/j.inffus.2012.03.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Wang-2014-Multi-modal-medical-image-fusion-us(1).pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Hidden Markov Tree model,Image fusion,Medical image,Shearlet transform,Shift-invariance},
number = {1},
pages = {20--28},
publisher = {Elsevier B.V.},
title = {{Multi-modal medical image fusion using the inter-scale and intra-scale dependencies between image shift-invariant shearlet coefficients}},
url = {http://dx.doi.org/10.1016/j.inffus.2012.03.002},
volume = {19},
year = {2014}
}
@article{Gao2012,
author = {Gao, Xinbo and Wang, Nannan and Tao, Dacheng and Li, Xuelong},
doi = {10.1109/TCSVT.2012.2198090},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/06196209.pdf:pdf},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
number = {8},
pages = {1213--1226},
publisher = {IEEE},
title = {{Face Sketch – Photo Synthesis and Retrieval Using Sparse Representation}},
volume = {22},
year = {2012}
}
@article{Zhao2019b,
abstract = {Dictionary learning (DL) for sparse tensor representation aims to train a set of dictionaries for each dimension using tensor samples based on the Tucker decomposition. However, their applications are limited by the fact that all the training samples must be input simultaneously, and that there is no direct way to extend the existing online DL methods for the vector-based model to the Tucker-decomposition-based model. To overcome this limitation, in this brief, we develop a Tucker-decomposition-based strategy to achieve a warm start for updating dictionaries, based on which, an online tensor DL (TDL) algorithm is proposed. The proposed algorithm processes a single new training sample at a time, such that it can be used not only for offline learning from static samples, but also for online learning from dynamic samples, under the framework of the Tucker model. When new training samples are input, only the newly added samples need to be used for retraining the dictionaries. We verify the convergence and low-complexity of the proposed algorithm via theoretical analysis as well as online learning simulations. We also perform offline learning simulations, the results of which demonstrate that our algorithm has an obvious advantage in training accuracy over existing TDL algorithms. The proposed algorithm has the potential to be used in fields such as multidimensional signal processing, compressive sensing, and machine learning.},
author = {Zhao, Rongqiang and Wang, Qiang},
doi = {10.1109/TCSII.2018.2862900},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08424902.pdf:pdf},
issn = {15497747},
journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
keywords = {Dictionary learning,Tucker decomposition,sparse representation},
number = {3},
pages = {502--506},
publisher = {IEEE},
title = {{Learning Separable Dictionaries for Sparse Tensor Representation: An Online Approach}},
volume = {66},
year = {2019}
}
@article{Foroughi2018,
abstract = {For an object classification system, the most critical obstacles toward real-world applications are often caused by large intra-class variability, arising from different lightings, occlusion, and corruption, in limited sample sets. Most methods in the literature would fail when the training samples are heavily occluded, corrupted or have significant illumination or viewpoint variations. Besides, most of the existing methods and especially deep learning-based methods, need large training sets to achieve a satisfactory recognition performance. Although using the pre-trained network on a generic large-scale data set and fine-tune it to the small-sized target data set is a widely used technique, this would not help when the content of base and target data sets are very different. To address these issues simultaneously, we propose a joint projection and low-rank dictionary learning method using dual graph constraints. Specifically, a structured class-specific dictionary is learned in the low-dimensional space, and the discrimination is further improved by imposing a graph constraint on the coding coefficients, that maximizes the intra-class compactness and inter-class separability. We enforce structural incoherence and low-rank constraints on sub-dictionaries to reduce the redundancy among them, and also make them robust to variations and outliers. To preserve the intrinsic structure of data, we introduce a supervised neighborhood graph into the framework to make the proposed method robust to small-sized and high-dimensional data sets. Experimental results on several benchmark data sets verify the superior performance of our method for object classification of small-sized data sets, which include a considerable amount of different kinds of variation, and may have high-dimensional feature vectors.},
archivePrefix = {arXiv},
arxivId = {1612.01594},
author = {Foroughi, Homa and Ray, Nilanjan and Zhang, Hong},
doi = {10.1109/TIP.2017.2766446},
eprint = {1612.01594},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08082519.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Intra-class variation,Joint projection and dictionary learning,Low-rank regularization,Object classification,Occlusion and corruption,Sparse representation},
number = {2},
pages = {806--821},
publisher = {IEEE},
title = {{Object Classification with Joint Projection and Low-Rank Dictionary Learning}},
volume = {27},
year = {2018}
}
@article{Zhang2018m,
abstract = {As the process of identifying the modulation format of the received signal, automatic modulation classification (AMC) has various applications in spectrum monitoring and signal interception. In this paper, we propose a dictionary learning-based AMC framework, where a dictionary is trained using signals with known modulation formats and the modulation format of the target signal is determined by its sparse representation on the dictionary. We also design a dictionary learning algorithm called block coordinate descent dictionary learning (BCDL). Furthermore, we prove the convergence of BCDL and quantify its convergence speed in a closed form. Simulation results show that our proposed AMC scheme offers superior performance than the existing methods with low complexity.},
author = {Zhang, Kezhong and Xu, Easton Li and Feng, Zhiyong and Zhang, Ping},
doi = {10.1109/ACCESS.2018.2794587},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08262636.pdf:pdf},
isbn = {2015033114},
issn = {21693536},
journal = {IEEE Access},
keywords = {Modulation classification,block coordinate descent,data driven,dictionary learning,sparse representation},
pages = {5607--5617},
publisher = {IEEE},
title = {{A Dictionary Learning Based Automatic Modulation Classification Method}},
volume = {6},
year = {2018}
}
@article{Liu2019b,
abstract = {Micro-videos have rapidly become one of the most dominant trends in the era of social media. Accordingly, how to organize them draws our attention. Distinct from the traditional long videos that would have multi-site scenes and tolerate the hysteresis, a micro-video: 1) usually records contents at one specific venue within a few seconds. The venues are structured hierarchically regarding their category granularity. This motivates us to organize the micro-videos via their venue structure. 2) timely circulates over social networks. Thus, the timeliness of micro-videos desires effective online processing. However, only 1.22{\%} of micro-videos are labeled with venue information when uploaded at the mobile end. To address this problem, we present a framework to organize the micro-videos online. In particular, we first build a structure-guided multi-modal dictionary learning model to learn the concept-level micro-video representation by jointly considering their venue structure and modality relatedness. We then develop an online learning algorithm to incrementally and efficiently strengthen our model, as well as categorize the micro-videos into a tree structure. Extensive experiments on a real-world data set validate our model well. In addition, we have released the codes to facilitate the research in the community.},
author = {Liu, Meng and Nie, Liqiang and Wang, Xiang and Tian, Qi and Chen, Baoquan},
doi = {10.1109/TIP.2018.2875363},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-10-Online Data Organizer Micro-Video Categorization by Structure-Guided Multimodal Dictionary Learning.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Micro-video organization,multi-modal dictionary learning,online learning,tree-guided constraints},
number = {3},
pages = {1235--1247},
title = {{Online Data Organizer: Micro-Video Categorization by Structure-Guided Multimodal Dictionary Learning}},
volume = {28},
year = {2019}
}
@article{Ji2019,
abstract = {Zero-Shot Learning (ZSL) aims at recognizing unseen classes that are absent during the training stage. Unlike the existing approaches that learn a visual-semantic embedding model to bridge the low-level visual space and the high-level class prototype space, we propose a novel synthesized approach for addressing ZSL within a dictionary learning framework. Specifically, it learns both a dictionary matrix and a class-specific encoding matrix for each seen class to synthesize pseudo instances for unseen classes with auxiliary of seen class prototypes. This allows us to train the classifiers for the unseen classes with these pseudo instances. In this way, ZSL can be treated as a traditional classification task, which makes it applicable for traditional and generalized ZSL settings simultaneously. Extensive experimental results on four benchmark datasets (AwA, CUB, aPY, and SUN) demonstrate that our method yields competitive performances compared to state-of-the-art methods on both settings.},
author = {Ji, Zhong and Wang, Junyue and Yu, Yunlong and Pang, Yanwei and Han, Jungong},
doi = {10.1016/j.neucom.2018.10.069},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-Class-specificsynthesizeddictionarymodelforZero-ShotLearning.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Dictionary learning,Image recognition,Synthesized model,Zero-Shot Learning},
pages = {339--347},
publisher = {Elsevier B.V.},
title = {{Class-specific synthesized dictionary model for Zero-Shot Learning}},
url = {https://doi.org/10.1016/j.neucom.2018.10.069},
volume = {329},
year = {2019}
}
@article{Zhang2010,
abstract = {In a sparse-representation-based face recognition scheme, the desired dictionary should have good representational power (i.e., being able to span the subspace of all faces) while supporting optimal discrimination of the classes (i.e., different human subjects). We propose a method to learn an over-complete dictionary that attempts to simultaneously achieve the above two goals. The proposed method, discriminative K-SVD (D-KSVD), is based on extending the K-SVD algorithm by incorporating the classification error into the objective function, thus allowing the performance of a linear classifier and the representational power of the dictionary being considered at the same time by the same optimization procedure. The D-KSVD algorithm finds the dictionary and solves for the classifier using a procedure derived from the K-SVD algorithm, which has proven efficiency and performance. This is in contrast to most existing work that relies on iteratively solving sub-problems with the hope of achieving the global optimal through iterative approximation. We evaluate the proposed method using two commonly-used face databases, the Extended YaleB database and the AR database, with detailed comparison to 3 alternative approaches, including the leading state-of-the-art in the literature. The experiments show that the proposed method outperforms these competing methods in most of the cases. Further, using Fisher criterion and dictionary incoherence, we also show that the learned dictionary and the corresponding classifier are indeed better-posed to support sparse-representation-based recognition. {\textcopyright}2010 IEEE.},
author = {Zhang, Qiang and Li, Baoxin},
doi = {10.1109/CVPR.2010.5539989},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Zhang-2010-Discriminative-k-svd-for-dictionary.pdf:pdf},
isbn = {9781424469840},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2691--2698},
publisher = {IEEE},
title = {{Discriminative K-SVD for dictionary learning in face recognition}},
year = {2010}
}
@article{Yang2012,
abstract = {Pixel-level image fusion integrates the information from multiple images of one scene to get an informative image which is more suitable for human visual perception or further image-processing. Sparse representation is a new signal representation theory which explores the sparseness of natural signals. Comparing to the traditional multiscale transform coefficients, the sparse representation coefficients can more accurately represent the image information. Thus, this paper proposes a novel image fusion scheme using the signal sparse representation theory. Because image fusion depends on local information of source images, we conduct the sparse representation on overlapping patches instead of the whole image, where a small size of dictionary is needed. In addition, the simultaneous orthogonal matching pursuit technique is introduced to guarantee that different source images are sparsely decomposed into the same subset of dictionary bases, which is the key to image fusion. The proposed method is tested on several categories of images and compared with some popular image fusion methods. The experimental results show that the proposed method can provide superior fused image in terms of several quantitative fusion evaluation indexes. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Yang, Bin and Li, Shutao},
doi = {10.1016/j.inffus.2010.04.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Yang-2012-Pixel-level-image-fusion-with-simul.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Image fusion,Multi-sensor fusion,Multiscale transform,Simultaneous orthogonal matching pursuit,Sparse representation},
number = {1},
pages = {10--19},
publisher = {Elsevier B.V.},
title = {{Pixel-level image fusion with simultaneous orthogonal matching pursuit}},
url = {http://dx.doi.org/10.1016/j.inffus.2010.04.001},
volume = {13},
year = {2012}
}
@article{Yin2017,
author = {Yin, Ming and Duan, Puhong and Liu, Wei and Liang, Xiangyu},
doi = {10.1016/j.neucom.2016.11.051},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231216314667-main.pdf:pdf},
issn = {0925-2312},
journal = {Neurocomputing},
keywords = {Adaptive dual-channel pulse coupled neural network,Infrared and visible image fusion,Shift-invariant dual-tree complex shearlet transfo,Sparse representation,fusion,infrared and visible image,shift-invariant dual-tree complex shearlet,sparse representation,transform},
number = {July 2016},
pages = {182--191},
publisher = {Elsevier},
title = {{Neurocomputing A novel infrared and visible image fusion algorithm based on shift-invariant dual-tree complex shearlet transform and sparse representation}},
url = {http://dx.doi.org/10.1016/j.neucom.2016.11.051},
volume = {226},
year = {2017}
}
@article{Li2018a,
abstract = {Person re-identification aims to identify the same person across non-overlapping camera views. It remains very challenging due to large differences in pose, illumination, and viewpoint between images. To improve robustness to such variations, here we develop a joint asymmetric projection and dictionary-learning algorithm by adopting listwise similarity and identity consistency constraints. Benefiting from the listwise similarities, dictionary learning considers the similarity list between each pedestrian image, thus exploiting the large amount of discriminative information contained in the samples. This approach endows the dictionary with discriminative power. In addition, we impose an identity consistency constraint on the coding coefficients to further improve the discriminative ability of the dictionary. To overcome appearance variability across non-overlapping camera views, two asymmetric projection dictionaries are employed to map the pedestrian features into a unified subspace such that the correlation between data from the same people in different views is maximized. Finally, by integrating the coding coefficient and classification results, we develop a fusion strategy with a modified cosine similarity measure to match the pedestrians. Experiments on different challenging data sets demonstrate that our method is effective and outperforms some current state-of-the-art approaches.},
author = {Li, Huafeng and Zhu, Jinting and Tao, Dapeng},
doi = {10.1109/ACCESS.2018.2853259},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08410867.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Dictionary learning,identity consistency,listwise similarities,person re-identification},
pages = {37977--37990},
publisher = {IEEE},
title = {{Asymmetric projection and dictionary learning with listwise and identity consistency constraints for person re-identification}},
volume = {6},
year = {2018}
}
@article{Liu2018g,
abstract = {Perceiving and identifying material properties of surfaces and objects is a fundamental aspect, which enables us to interact with a world. Automatic material identification, therefore, plays a critical role in intelligent manufacturing systems. In many scenarios, tactile samples and the tactile adjective descriptions about some materials can be provided. How to exploit their relation is a challenging problem. In this paper, we develop a semantics-regularized dictionary learning method to incorporate such advanced semantic information into the training model to improve material identification performance. A set of optimization algorithms is developed to obtain the solutions of the proposed optimization problem. Finally, we perform extensive experimental evaluations on publicly available datasets to show the effectiveness of the proposed method.},
author = {Liu, Huaping and Sun, Fuchun},
doi = {10.1109/TMECH.2017.2775208},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08115186.pdf:pdf},
issn = {10834435},
journal = {IEEE/ASME Transactions on Mechatronics},
keywords = {Dictionary learning,intelligent manufacturing,material identification,tactile perception},
number = {3},
pages = {1050--1058},
publisher = {IEEE},
title = {{Material Identification Using Tactile Perception: A Semantics-Regularized Dictionary Learning Method}},
volume = {23},
year = {2018}
}
@article{Peng2018,
abstract = {In this paper, we propose a novel viewpoint about dictionary learning (DL) and collaborative representation for face recognition. Different from conventional learning methods, we consider both the native spatial domain and the Fourier frequency domain of datasets for dictionary learning. Based on the Fourier spectrum of images, the proposed method provides new insights into two crucial complementations in dictionary learning: data domain complementation and classification algorithm complementation. On the one hand, we perform the dictionary learning on the original dataset and the Fourier transformed dataset respectively, which makes data complementary in both spatial and frequency domains. On the other hand, we integrate dictionary learning and collaborative representation (CRC) for classification. Specifically, CRC is conducted on frequency-domain dataset to obtain residual scores, and the residual scores are fused with the ones obtained by the previous DL algorithms as the ultimate fusion score to classify the test samples. The proposed method with two aspects of complementation promotes the discriminative ability of dictionary learning and obtains a better classification performance. The experimental results demonstrate the superior performance of our method over the original dictionary learning methods.},
author = {Peng, Yali and Li, Liping and Liu, Shigang and Lei, Tao},
doi = {10.1016/j.sigpro.2018.01.013},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168418300215-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Dictionary learning,Face recognition,Fourier transform,Representation based classification},
pages = {101--109},
publisher = {Elsevier B.V.},
title = {{Space–frequency domain based joint dictionary learning and collaborative representation for face recognition}},
url = {https://doi.org/10.1016/j.sigpro.2018.01.013},
volume = {147},
year = {2018}
}
@article{Deng2017,
abstract = {The estimation accuracy of the wall displacement, delay time, and linear-regression-based Pulse Wave Velocity (PWV) affected by different scanning frame rates and beam density is investigated quantitatively in the measurement of the regional PWV with ultrasound transit time method based on a model of pulse wave propagation along a carotid artery segment. Through statistical variance analysis, the significance levels of measurement errors as well as the primary and secondary relations of these two influence factors are ascertained. The results show that the frame rates do not significantly affect the wall displacement estimation accuracy (p{\textgreater}0.05) with relative errors ranged from 0.23 to 0.28. The delay time measurement accuracy is influenced significantly by the frame rates and spacing between two beams simultaneously (p{\textless}0.01). The relative errors decrease from 0.99 to 0.06 as the distances from the first beam to others increase from 2.38 mm to 38 mm. However, the mean transit time errors increase from 0.19 to 0.43 when the frame rates decrease from 1127 Hz to 226 Hz. The PWV estimation errors ranging from 7{\%} to 20{\%} are affected significantly by the number of beams as well as frame rates under the condition that the beams used for regression fitness are no less than 10. The frame rate is the main influence factor in this situation (p{\textless}0.01). Therefore, the PWV measurement accuracy can be improved by increasing frame rate with a proper beam setting. Experimental results could be helpful to explore novel measurement method for improving PWV accuracy in the follow-up work.},
author = {Deng, Li and Zhang, Yufeng and Yang, Lichun and Hu, Xiao and Li, Zhiyao and Gao, Lian and Zhang, Junhua},
doi = {10.11999/JEIT160306},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/{\%}E8{\%}B6{\%}85{\%}E5{\%}A3{\%}B0{\%}E4{\%}BC{\%}A0{\%}E8{\%}BE{\%}93{\%}E6{\%}97{\%}B6{\%}E9{\%}97{\%}B4{\%}E6{\%}B3{\%}95{\%}E9{\%}A2{\%}88{\%}E5{\%}8A{\%}A8{\%}E8{\%}84{\%}89{\%}E8{\%}84{\%}89{\%}E6{\%}90{\%}8F{\%}E6{\%}B3{\%}A2{\%}E9{\%}80{\%}9F{\%}E4{\%}BC{\%}B0{\%}.pdf:pdf},
issn = {10095896},
journal = {Dianzi Yu Xinxi Xuebao/Journal of Electronics and Information Technology},
keywords = {Accurate performance,Carotid artery,Pulse wave velocity,Ultrasound radio frequency signal},
number = {2},
pages = {316--321},
title = {{Accurate performance and associated influence factors for Pulse Wave Velocity measurement of carotid arteriesbased on ultrasonic transit time method}},
volume = {39},
year = {2017}
}
@article{Qin2019,
abstract = {Sound event tagging is a process that adds texts or labels to sound segments based on their salient features and/or annotations. In the real world, since annotating cost is much expensive, tagged sound segments are limited, while untagged sound segments can be obtained easily and inexpensively. Thus, semi-automatic tagging becomes very important, which can assign labels to massive untagged sound segments according to a small number of manually annotated sound segments. Active learning is an effective technique to solve this problem, in which selected sound segments are manually tagged while other sound segments are automatically tagged. In this paper, a learnt dictionary based active learning method is proposed for environmental sound event tagging, which can significantly reduce the annotating cost in the process of semi-automatic tagging. The proposed method is based on a learnt dictionary, as dictionary learning is more adapt to sound feature extraction. Moreover, tagging accuracy and annotating cost are used to measure the performance of the proposed method. Experimental results demonstrate that the proposed method has higher tagging accuracy but requires much less annotating cost than other existing methods.},
author = {Qin, Xiao and Ji, Wanting and Wang, Ruili and Yuan, Chang An},
doi = {10.1007/s11042-018-7139-2},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Qin2019{\_}Article{\_}LearntDictionaryBasedActiveLea.pdf:pdf},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Active learning,Dictionary learning,Internet of things,Sound event tagging,Sparse coding,k-medoids clustering},
pages = {29493--29508},
publisher = {Multimedia Tools and Applications},
title = {{Learnt dictionary based active learning method for environmental sound event tagging}},
year = {2019}
}
@article{Yin2019a,
author = {Yin, Ming and Liu, Xiaoning and Liu, Yu and Chen, Xun},
doi = {10.1109/TIM.2018.2838778},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/03-10-Medical Image Fusion in NonsubsampledShearlet.pdf:pdf},
issn = {00189456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Activity level measure,image fusion,medical imaging,nonsubsampled shearlet transform (NSST),pulse coupled neural network (PCNN)},
number = {1},
pages = {49--64},
publisher = {IEEE},
title = {{Medical Image Fusion with Parameter-Adaptive Pulse Coupled Neural Network in Nonsubsampled Shearlet Transform Domain}},
volume = {68},
year = {2019}
}
@article{Lu2019a,
abstract = {The restoration of images degraded by blur and multiplicative noise is a critical preprocessing step in medical ultrasound images which exhibit clinical diagnostic features of interest. This paper proposes a novel non-smooth non-convex variational model for ultrasound images denoising and deblurring motivated by the successes of sparse representation of images and FoE based approaches. Dictionaries are well adapted to textures and extended to arbitrary image sizes by defining a global image prior, while FoE image prior explicitly characterizes the statistics properties of natural image. Following these ideas, the new model is composed of the data-fidelity term, the sparse and redundant representations via learned dictionaries, and the FoE image prior model. The iPiano algorithm can efficiently deal with this optimization problem. The new proposed model is applied to several simulated images and real ultrasound images. The experimental results of denoising and deblurring show that proposed method gives a better visual effect by efficiently removing noise and preserving details well compared with two state-of-the-art methods.},
author = {Lu, Jian and Yang, Hanmei and Shen, Lixin and Zou, Yuru},
doi = {10.1016/j.camwa.2018.10.031},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-Ultrasoundimagerestorationbasedonalearneddicti.pdf:pdf},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
keywords = {Deblurring,Denoising,FoE image prior,Sparse representation,iPiano algorithm},
number = {4},
pages = {991--1009},
publisher = {Elsevier Ltd},
title = {{Ultrasound image restoration based on a learned dictionary and a higher-order MRF}},
url = {https://doi.org/10.1016/j.camwa.2018.10.031},
volume = {77},
year = {2019}
}
@article{Zhang2018g,
abstract = {The miniaturization of spectrometer can broaden the application area of spectrometry, which has huge academic and industrial value. Among various miniaturization approaches, filter-based miniaturization is a promising implementation by utilizing broadband filters with distinct transmission functions. Mathematically, filter-based spectral reconstruction can be modeled as solving a system of linear equations. In this paper, we propose an algorithm of spectral reconstruction based on sparse optimization and dictionary learning. To verify the feasibility of the reconstruction algorithm, we design and implement a simple prototype of a filter-based miniature spectrometer. The experimental results demonstrate that sparse optimization is well applicable to spectral reconstruction whether the spectra are directly sparse or not. As for the non-directly sparse spectra, their sparsity can be enhanced by dictionary learning. In conclusion, the proposed approach has a bright application prospect in fabricating a practical miniature spectrometer.},
author = {Zhang, Shang and Dong, Yuhan and Fu, Hongyan and Huang, Shao Lun and Zhang, Lin},
doi = {10.3390/s18020644},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/sensors-18-00644-v2.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Dictionary learning,Filter-based miniature spectrometer,Sparse optimization,Spectral reconstruction},
number = {2},
title = {{A spectral reconstruction algorithm of miniature spectrometer based on sparse optimization and dictionary learning}},
volume = {18},
year = {2018}
}
@article{Zhang2018i,
abstract = {The central task of reconstruction-based single image super-resolution (SR) approaches is to design an effective prior to well pose the solution to unknown up-sampled image. In this paper, we present a novel single image SR method by learning a set of local dictionaries and non-local similar structures from the input low-resolution (LR) image itself. The local dictionaries are learned by segmenting structurally different regions into different clusters and then training an individual dictionary for each cluster. With the learned dictionaries and similar information, each HR pixel in the expected HR image is estimated as the weighted average of a non-local dictionary (NLD)-based regression which assembles the local structural regularity and the non-local similar redundancies. We further transform the proposed NLD-based regression model into a unified regularization term for a maximum a posteriori probability (MAP) based SR framework. Thorough experimental results carried out on five publicly available datasets indicate that the proposed SR method is promising in producing high-quality images with finer details and sharper edges in terms of both quantitative and perceptual quality assessments.},
author = {Zhang, Kaibing and Li, Jie and Wang, Haijun and Liu, Xiuping and Gao, Xinbo},
doi = {10.1016/j.sigpro.2017.07.020},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168417302682-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Gradient descent,Local dictionary learning,Non-local similarity,Single image super-resolution (SR),Steering kernel regression},
pages = {231--243},
publisher = {Elsevier B.V.},
title = {{Learning local dictionaries and similarity structures for single image super-resolution}},
url = {http://dx.doi.org/10.1016/j.sigpro.2017.07.020},
volume = {142},
year = {2018}
}
@article{Wang2018c,
abstract = {Learning good representation for images is always a hot topic in machine learning and pattern recognition fields. Among the numerous algorithms, dictionary learning is a wellknown strategy for effective feature extraction. Recently, more discriminative sub-dictionaries have been built by Fisher discriminative dictionary learning with specific class labels. Different types of constraints, such as sparsity, low rankness, and locality, are also exploited to make use of global and local information. On the other hand, as the basic building block of deep structure, the auto-encoder has demonstrated its promising performance in extracting new feature representation. To this end, we develop a unified feature learning framework by incorporating the marginalized denoising auto-encoder into a locality-constrained dictionary learning scheme, named marginalized denoising dictionary learning. Overall, we deploy low-rank constraint on each sub-dictionary and locality constraint instead of sparsity on coefficients, in order to learn a more concise and pure feature spaces meanwhile inheriting the discrimination from subdictionary learning. Finally, we evaluate our algorithm on several face and object data sets. Experimental results have demonstrated the effectiveness and efficiency of our proposed algorithm by comparing with several state-of-the-art methods.},
author = {Wang, Shuyang and Ding, Zhengming and Fu, Yun},
doi = {10.1109/TIP.2017.2764622},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08076907.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Dictionary learning,Locality constraint,Marginalized denoising auto-encoder},
number = {1},
pages = {500--510},
publisher = {IEEE},
title = {{Marginalized denoising dictionary learning with locality constraint}},
volume = {27},
year = {2018}
}
@article{Yang2013,
abstract = {Phase retrieval refers to a classical nonconvex problem of recovering a signal from its Fourier magnitude measurements. Inspired by the compressed sensing technique, signal sparsity is exploited in recent studies of phase retrieval to reduce the required number of measurements, known as compressive phase retrieval (CPR). In this paper, l1 minimization problems are formulated for CPR to exploit the signal sparsity and alternating direction algorithms are presented for problem solving. For real-valued, nonnegative image reconstruction, the image of interest is shown to be an optimal solution of the formulated l1 minimization in the noise free case. Numerical simulations demonstrate that the proposed approach is fast, accurate and robust to measurements noises.},
archivePrefix = {arXiv},
arxivId = {1302.0081},
author = {Yang, Zai and Zhang, Cishen and Xie, Lihua},
eprint = {1302.0081},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/oe-26-16-19773.pdf:pdf},
number = {16},
pages = {19773--19796},
title = {{Robust Compressive Phase Retrieval via L1 Minimization With Application to Image Reconstruction}},
url = {http://arxiv.org/abs/1302.0081},
volume = {26},
year = {2013}
}
@article{Li2013a,
abstract = {Remote sensing image fusion can integrate the spatial detail of panchromatic (PAN) image and the spectral information of a low-resolution multispectral (MS) image to produce a fused MS image with high spatial resolution. In this paper, a remote sensing image fusion method is proposed with sparse representations over learned dictionaries. The dictionaries for PAN image and low-resolution MS image are learned from the source images adaptively. Furthermore, a novel strategy is designed to construct the dictionary for unknown high-resolution MS images without training set, which can make our proposed method more practical. The sparse coefficients of the PAN image and low-resolution MS image are sought by the orthogonal matching pursuit algorithm. Then, the fused high-resolution MS image is calculated by combining the obtained sparse coefficients and the dictionary for the high-resolution MS image. By comparing with six well-known methods in terms of several universal quality evaluation indexes with or without references, the simulated and real experimental results on QuickBird and IKONOS images demonstrate the superiority of our method. {\textcopyright} 1980-2012 IEEE.},
author = {Li, Shutao and Yin, Haitao and Fang, Leyuan},
doi = {10.1109/TGRS.2012.2230332},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/06428669.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Dictionary learning,image fusion,multispectral (MS) image,panchromatic (PAN) image,remote sensing,sparse representation},
number = {9},
pages = {4779--4789},
publisher = {IEEE},
title = {{Remote sensing image fusion via sparse representations over learned dictionaries}},
volume = {51},
year = {2013}
}
@article{Zu2019,
abstract = {Simultaneous-source acquisition, breaking the limit of conventional seismic acquisition, is a rapidly evolving research field, due to its advantage in reducing survey time and improving data quality. The benefits of simultaneous-source acquisition are compromised by the intense blending interference. Separating a blended record into a group of individual records, known as 'deblending' is one of the most popular solution to the problem. However, the blended records are often corrupted by random noise, which causes difficulties in separation. In an iterative deblending algorithm, the incoherent interference can be simulated and subtracted from the blended record. When the random noise is strong, it is difficult to simulate the incoherent interference. In this paper, we propose a hybrid-sparsity constraint model that applies the dictionary learning into the deblending framework that is based on the sparsity-promoting transform to deal with extremely noisy simultaneous source data. The dictionary learning with fine-tuned adaptation can learn the incoherent interference into atoms and reject random noise. Then, the sparse transform-based framework is implemented to iteratively separate the signal and interference. We use two synthetic examples to demonstrate the advantage of the proposed method in extremely noisy situations. Two field examples further confirm the superior deblending performance of the proposed method for the noisy simultaneous-source data over the curvelet transform-based and rank reduction-based methods.},
author = {Zu, Shaohuan and Zhou, Hui and Wu, Rushan and Mao, Weijian and Chen, Yangkang},
doi = {10.1109/TGRS.2018.2872416},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-8-Hybrid-Sparsity Constrained Dictionary Learningfor Iterative Deblending of Extremely NoisySimultaneous-Source Data.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Dictionary learning,noisy blended data,sparsity promoting},
number = {4},
pages = {2249--2262},
publisher = {IEEE},
title = {{Hybrid-Sparsity Constrained Dictionary Learning for Iterative Deblending of Extremely Noisy Simultaneous-Source Data}},
volume = {57},
year = {2019}
}
@article{Ou2018,
abstract = {Face recognition in real-world video surveillance needs to deal with a lot of challenges including low resolution, illumination variations, pose changes, occlusions and so on. Among them, occlusions are difficult and have not attracted enough attentions. To address this problem, in this paper, we propose a robust discriminative nonnegative dictionary learning method for occluded face recognition, which estimates the occlusions adaptively and selects the features robustly. Instead of modeling the reconstruction errors using a specific distribution, we estimate occlusions adaptively according to the reconstruction errors and learn different weights for different pixels during the iterative processing. To enhance discriminant ability of the dictionary, we constrain the low-dimensional representations of samples from the same class to be as close as possible and select the discriminative features robustly via ℓ2, 1-norm. For the induced non-convex problem, we reformulate it into local convex optimization subproblem via utilizing the half-quadratic technique and propose new update rules. Extensive experiments are implemented on four benchmark datasets, and the experimental results demonstrate the effectiveness and robustness of the proposed method.},
author = {Ou, Weihua and Luan, Xiao and Gou, Jianping and Zhou, Quan and Xiao, Wenjun and Xiong, Xiangguang and Zeng, Wu},
doi = {10.1016/j.patrec.2017.07.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0167865517302386-main.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Face recognition,Nonnegative dictionary learning,Occlusion,Robust feature selection,Video surveillance},
pages = {41--49},
publisher = {Elsevier B.V.},
title = {{Robust discriminative nonnegative dictionary learning for occluded face recognition}},
url = {https://doi.org/10.1016/j.patrec.2017.07.006},
volume = {107},
year = {2018}
}
@article{Zhang2018j,
abstract = {Inverse halftoning is the restoration of a continuous-tone image from its halftone version, which is a critical process for halftone transform, digital archive management and high precision identification of halftone. In this paper, a novel inverse halftoning method based on semi-coupled multi-dictionary learning is proposed to address the cross-style image restoration from halftone images to continuous-tone images. By using semi-coupled multi-dictionary learning, multiple dictionary pairs and their corresponding mapping functions between continuous-tone image and its halftone version could be simultaneously learned. The learned multiple dictionary pairs can well represent the structure characteristics of halftone images and continuous-tone images, respectively. In addition, the mapping functions learned by semi-coupled manner can bridge the gap between the two different style images of halftone image and continuous-tone image. Unlike the existed methods, the proposed method could effectively relax the assumption of the same sparse coding coefficients in coupled dictionary learning. To obtain more accurate mapping functions, a structural clustering method for cross-style image patches is proposed by using SUSAN (smallest univalue segment assimilating nucleus) filtering and HOG (histogram of oriented gradient) features, which can capture the similar structure features from halftone images and continuous-tone images, and thus improve the classification accurate rate of halftone image patches. The experimental results demonstrate that the proposed method can restore higher quality continuous-tone images than that produced by the state-of-the-art methods, which not only reduce the screen noise in smooth regions, but also provide well fine details and clear edges.},
author = {Zhang, Yan and Zhang, Erhu and Chen, Wanjun and Chen, Yajun and Duan, Jinghong},
doi = {10.1016/j.engappai.2018.03.012},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0952197618300617-main.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Inverse halftoning,Multi-dictionary learning,Semi-coupled dictionary,Sparse representation,Structure clustering},
number = {5},
pages = {43--53},
publisher = {Elsevier Ltd},
title = {{Sparsity-based inverse halftoning via semi-coupled multi-dictionary learning and structural clustering}},
url = {https://doi.org/10.1016/j.engappai.2018.03.012},
volume = {72},
year = {2018}
}
@article{Veshki2019,
author = {Veshki, Farshad G. and Vorobyov, Sergiy A.},
doi = {10.1109/lsp.2019.2934045},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08792154.pdf:pdf},
issn = {1070-9908},
journal = {IEEE Signal Processing Letters},
number = {10},
pages = {1441--1445},
publisher = {IEEE},
title = {{An Efficient Coupled Dictionary Learning Method}},
volume = {26},
year = {2019}
}
@article{Zhang2018n,
abstract = {Automatic modulation classification (AMC) is the process of identifying the modulation format of the received signal. It is generally a difficult task due to the limited knowledge of the signal. In this letter, we propose a data driven dictionary-learning-based AMC framework, where we first use the known training signals to train the dictionary set and then classify the unknown modulation format via certain sparse representations, for which we design a dictionary-learning-based algorithm called block coordinate descent dictionary learning. Simulation results show that the proposed method out performs other existing approaches, achieving higher accuracy with a less training time.},
author = {Zhang, Kezhong and Xu, Easton Li and Zhang, Han and Feng, Zhiyong and Cui, Shuguang},
doi = {10.1109/LWC.2018.2798572},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08270380.pdf:pdf},
isbn = {2015033114},
issn = {21622345},
journal = {IEEE Wireless Communications Letters},
keywords = {Modulation classification,block coordinate descent,data driven,dictionary learning,sparse representation},
number = {4},
pages = {586--589},
publisher = {IEEE},
title = {{Data driven automatic modulation classification via dictionary learning}},
volume = {7},
year = {2018}
}
@article{Sun2019,
abstract = {Facial expression recognition (FER) plays a significant role in human-computer interaction. In this paper, adopting a dictionary learning feature space (DLFS) via sparse representation classification (SRC), we propose a method for FER. First, we obtain a difference dictionary (DD) from the feature space by indirectly using an auxiliary neutral training set. Next, we use a dictionary learning algorithm to train the DD; this algorithm considers the samples from the DD are approximately symmetrical structure. Finally, we use SRC to represent and determine the label of each query sample. We then verify out proposed method from the perspective of training samples, dimension reduction methods and Gaussian noise variances using a variety of public databases. In addition, we compare our DLFS{\_}SRC approach with DLFS{\_}CRC and DLFS{\_}LRC approaches on the Extended Cohn-Kanade (CK+) database to analyze recognition results. Our simulation experiments show that our proposed method achieved satisfying performance levels for FER.},
author = {Sun, Zhe and ping Hu, Zheng and Wang, Meng and huan Zhao, Shu},
doi = {10.1007/s10462-017-9554-6},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-Dictionary learning feature space via sparserepresentation classification for facial expressionrecognition.pdf:pdf},
issn = {15737462},
journal = {Artificial Intelligence Review},
keywords = {Dictionary learning,Difference dictionary,Facial expression recognition,Sparse representation classification},
number = {1},
pages = {1--18},
publisher = {Springer Netherlands},
title = {{Dictionary learning feature space via sparse representation classification for facial expression recognition}},
volume = {51},
year = {2019}
}
@article{Ouzir2018,
abstract = {This paper introduces a new method for cardiac motion estimation in 2-D ultrasound images. The motion estimation problem is formulated as an energy minimization, whose data fidelity term is built using the assumption that the images are corrupted by multiplicative Rayleigh noise. In addition to a classical spatial smoothness constraint, the proposed method exploits the sparse properties of the cardiac motion to regularize the solution via an appropriate dictionary learning step. The proposed method is evaluated on one data set with available ground-truth, including four sequences of highly realistic simulations. The approach is also validated on both healthy and pathological sequences of in vivo data. We evaluate the method in terms of motion estimation accuracy and strain errors and compare the performance with state-of-the-art algorithms. The results show that the proposed method gives competitive results for the considered data. Furthermore, the in vivo strain analysis demonstrates that meaningful clinical interpretation can be obtained from the estimated motion vectors.},
author = {Ouzir, Nora and Basarab, Adrian and Liebgott, Herve and Harbaoui, Brahim and Tourneret, Jean Yves},
doi = {10.1109/TIP.2017.2753406},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08039230.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Cardiac ultrasound,dictionary learning,motion estimation,sparse representations},
number = {1},
pages = {64--77},
title = {{Motion Estimation in Echocardiography Using Sparse Representation and Dictionary Learning}},
volume = {27},
year = {2018}
}
@article{Wang2018e,
abstract = {A great number of studies show that considering information from multiple views results in better performance than their single-view counterparts. However, many previous works aiming to improve classification performance fail to effectively tackle the inter-view correlation or the intra-class variability. Analysis dictionary learning (ADL) has theoretic significance and practical potential in classification tasks. Based on the ADL, this paper proposes a new method, namely, multi-view analysis dictionary learning (MvADL) for image classification. Specifically, multi-view analysis dictionaries are designed to reduce the intra-class variability in the transformed space in the multi-view scenario. Then, a marginalized classification term is incorporated to integrate the semantic information into the basic dictionary learning model. In the marginalized classification term, a marginalized target learning strategy is applied to improve the flexibility and discriminability of the whole model. Besides, an iteratively optimizing algorithm is designed to solve the proposed MvADL. Experiments on benchmark data sets demonstrate the superiority of our proposed method.},
author = {Wang, Qianyu and Guo, Yanqing and Wang, Jiujun and Luo, Xiangyang and Kong, Xiangwei},
doi = {10.1109/ACCESS.2018.2791578},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08253446.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Analysis dictionary learning,image classification,marginalized regression target,multi-view learning},
number = {Cccv},
pages = {20174--20183},
publisher = {IEEE},
title = {{Multi-View Analysis Dictionary Learning for Image Classification}},
volume = {6},
year = {2018}
}
@article{Li2018e,
abstract = {Recently there has been increasing attention towards analysis dictionary learning. In analysis dictionary learning, it is an open problem to obtain the strong sparsity-promoting solutions efficiently while simultaneously avoiding the trivial solutions of the dictionary. In this paper, to obtain the strong sparsity-promoting solutions, we employ the ℓ1∕2 norm as a regularizer. The very recent study on ℓ1∕2 norm regularization theory in compressive sensing shows that its solutions can give sparser results than using the ℓ1 norm. We transform a complex nonconvex optimization into a number of one-dimensional minimization problems. Then the closed-form solutions can be obtained efficiently. To avoid trivial solutions, we apply manifold optimization to update the dictionary directly on the manifold satisfying the orthonormality constraint, so that the dictionary can avoid the trivial solutions well while simultaneously capturing the intrinsic properties of the dictionary. The experiments with synthetic and real-world data verify that the proposed algorithm for analysis dictionary learning can not only obtain strong sparsity-promoting solutions efficiently, but also learn more accurate dictionary in terms of dictionary recovery and image processing than the state-of-the-art algorithms.},
author = {Li, Zhenni and Ding, Shuxue and Li, Yujie and Yang, Zuyuan and Xie, Shengli and Chen, Wuhui},
doi = {10.1016/j.neunet.2017.11.015},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0893608017302782-main.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Analysis dictionary learning,Manifold optimization,Orthonormality constraint,Sparse model,ℓ1∕2 norm regularizer},
pages = {212--222},
publisher = {Elsevier Ltd},
title = {{Manifold optimization-based analysis dictionary learning with an ℓ1∕2-norm regularizer}},
url = {https://doi.org/10.1016/j.neunet.2017.11.015},
volume = {98},
year = {2018}
}
@article{Pathak2018,
abstract = {Computed tomography (CT) approach is extensively utilized in clinical diagnoses. However, X-ray residue in human body may introduce somatic damage such as cancer. Owing to radiation risk, research has focused on the radiation exposure distributed to patients through CT investigations. Therefore, low-dose CT has become a significant research area. Many researchers have proposed different low-dose CT reconstruction techniques. But, these techniques suffer from various issues such as over smoothing, artifacts, noise, etc. Therefore, in this paper, we have proposed a novel integrated low-dose CT reconstruction technique. The proposed technique utilizes global dictionary-based statistical iterative reconstruction (GDSIR) and adaptive dictionary-based statistical iterative reconstruction (ADSIR)-based reconstruction techniques. In case the dictionary (D) is predetermined, then GDSIR can be used and if D is adaptively defined then ADSIR is appropriate choice. The gain intervention-based filter is also used as a post-processing technique for removing the artifacts from low-dose CT reconstructed images. Experiments have been done by considering the proposed and other low-dose CT reconstruction techniques on well-known benchmark CT images. Extensive experiments have shown that the proposed technique outperforms the available approaches.},
author = {Pathak, Yadunath and Arya, K. V. and Tiwari, Shailendra},
doi = {10.1142/S0217984918501488},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/s0217984918501488.pdf:pdf},
issn = {02179849},
journal = {Modern Physics Letters B},
keywords = {Low-dose CT,dictionary learning,gain intervention filter,reconstruction},
number = {14},
pages = {1--18},
title = {{Low-dose CT image reconstruction using gain intervention-based dictionary learning}},
volume = {32},
year = {2018}
}
@article{Fu2018,
abstract = {An enhanced sequential Monte Carlo probability hypothesis density (PHD) filter-based multiple human tracking system is presented. The proposed system mainly exploits two concepts: a novel adaptive gating technique and an online group-structured dictionary learning strategy. Conventional PHD filtering methods preset the target birth intensity and the gating threshold for selecting real observations for the PHD update. This often yields inefficiency in false positives and missed detections in a cluttered environment. To address this issue, a measurement-driven mechanism based on a novel adaptive gating method is proposed to adaptively update the gating sizes. This yields an accurate approach to discriminate between survival and residual measurements by reducing the clutter inferences. In addition, online group-structured dictionary learning with a maximum voting method is used to robustly estimate the target birth intensity. It enables the new-born targets to be automatically detected from noisy sensor measurements. To improve the adaptability of our group-structured dictionary to appearance and illumination changes, we employ the simultaneous code word optimization algorithm for the dictionary update stage. Experimental results demonstrate our proposed method achieves the best performance amongst state-of-the-art random finite set-based methods, and the second best online tracker ranked on the leaderboard of latest MOT17 challenge.},
author = {Fu, Zeyu and Feng, Pengming and Angelini, Federico and Chambers, Jonathon and Naqvi, Syed Mohsen},
doi = {10.1109/ACCESS.2018.2816805},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08318585.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Multiple human tracking,SMC-PHD filter,adaptive gating,birth intensity estimation,dictionary learning,group-structured sparsity},
pages = {14764--14778},
publisher = {IEEE},
title = {{Particle PHD Filter Based Multiple Human Tracking Using Online Group-Structured Dictionary Learning}},
volume = {6},
year = {2018}
}
@article{Ding2018,
abstract = {This paper addresses the problem of uplink (UL) and downlink (DL) channel estimation in frequency-division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems. By utilizing the sparse recovery and compressive sensing algorithms, we are able to improve the accuracy of the UL/DL channel estimation and reduce the number of UL/DL pilot symbols. Such successful channel estimation builds upon the assumption that the channel can be sparsely represented under some basis/dictionary. Previous works model the channel using some predefined basis/dictionary; while in this paper, we present a dictionary learning-based channel model such that a dictionary is learned from comprehensively collected channel measurements. The learned dictionary adapts specifically to the cell characteristics and promotes a more efficient and robust channel representation, which in turn improves the performance of the channel estimation. Furthermore, we extend the dictionary learning-based channel model into a joint UL/DL learning framework by observing the reciprocity of the angle of arrival/angle of departure between the UL/DL transmissions and propose a joint channel estimation algorithm that combines the UL and DL received training signals to obtain a more accurate channel estimate. In other words, the DL training overhead, which is a bottleneck in FDD massive MIMO system, can be reduced by utilizing the information from simpler UL training.},
archivePrefix = {arXiv},
arxivId = {1612.06553},
author = {Ding, Yacong and Rao, Bhaskar D.},
doi = {10.1109/TWC.2018.2843786},
eprint = {1612.06553},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08383706.pdf:pdf},
issn = {15361276},
journal = {IEEE Transactions on Wireless Communications},
keywords = {Channel estimation,Compressive sensing (CS),Dictionary learning,FDD,Joint dictionary learning,Joint sparse recovery,Massive MIMO},
number = {8},
pages = {5437--5451},
publisher = {IEEE},
title = {{Dictionary learning-based sparse channel representation and estimation for FDD massive MIMO systems}},
volume = {17},
year = {2018}
}
@article{Pajares2004,
abstract = {The objective of image fusion is to combine information from multiple images of the same scene. The result of image fusion is a new image which is more suitable for human and machine perception or further image-processing tasks such as segmentation, feature extraction and object recognition. Different fusion methods have been proposed in literature, including multiresolution analysis. This paper is an image fusion tutorial based on wavelet decomposition, i.e. a multiresolution image fusion approach. We can fuse images with the same or different resolution level, i.e. range sensing, visual CCD, infrared, thermal or medical. The tutorial performs a synthesis between the multiscale-decomposition-based image approach (Proc. IEEE 87 (8) (1999) 1315), the ARSIS concept (Photogramm. Eng. Remote Sensing 66 (1) (2000) 49) and a multisensor scheme (Graphical Models Image Process. 57 (3) (1995) 235). Some image fusion examples illustrate the proposed fusion approach. A comparative analysis is carried out against classical existing strategies, including those of multiresolution. {\textcopyright} 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Pajares, Gonzalo and de la Cruz, Jes{\'{u}}es Manuel},
doi = {10.1016/j.patcog.2004.03.010},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Pajares-2004-A-wavelet-based-image-fusion-tutori.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Image fusion,Multiresolution,Wavelets},
number = {9},
pages = {1855--1872},
title = {{A wavelet-based image fusion tutorial}},
volume = {37},
year = {2004}
}
@article{Easley2008,
abstract = {In spite of their remarkable success in signal processing applications, it is now widely acknowledged that traditional wavelets are not very effective in dealing multidimensional signals containing distributed discontinuities such as edges. To overcome this limitation, one has to use basis elements with much higher directional sensitivity and of various shapes, to be able to capture the intrinsic geometrical features of multidimensional phenomena. This paper introduces a new discrete multiscale directional representation called the discrete shearlet transform. This approach, which is based on the shearlet transform, combines the power of multiscale methods with a unique ability to capture the geometry of multidimensional data and is optimally efficient in representing images containing edges. We describe two different methods of implementing the shearlet transform. The numerical experiments presented in this paper demonstrate that the discrete shearlet transform is very competitive in denoising applications both in terms of performance and computational efficiency.},
author = {Easley, Glenn and Labate, Demetrio and Lim, Wang Q.},
doi = {10.1016/j.acha.2007.09.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Easley-2008-Sparse-directional-image-representa.pdf:pdf},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
keywords = {Curvelets,Denoising,Image processing,Shearlets,Sparse representation,Wavelets},
number = {1},
pages = {25--46},
title = {{Sparse directional image representations using the discrete shearlet transform}},
volume = {25},
year = {2008}
}
@article{Wang2018b,
abstract = {In past decades, saliency detection has received increasing attention from computer vision communities, for its potential usage in many vision-related tasks. However, finding representative and discriminative features to accurately locate salient regions from complex scenes remains a challenging problem. Recent research on primary visual cortex (V1) shows that vision neurons are sparsely connected to form a compact representation of natural scenes and different visual stimuli are processed separately according to their semantic importance. Inspired by the above characteristics of visual perception, in this paper we advance a novel saliency detection method via representative and discriminative dictionary learning. An assumption that salient and nonsalient information are sparsely coded under two separate dictionaries is cast on the problem and we propose to learn a compact background dictionary from the image itself for saliency estimation. Different from previous methods, our saliency cues are obtained via active learning strategies rather than artificially designed rules, and thus is more adaptive. Followed by this, a probabilistic inference model is deduced to fully excavate multisource information about the scenes for high-quality saliency map generation. This joint inference scheme takes both spatial and color space information into consideration and is proved to be quite effective in practice. Finally, to investigate the performance of the proposed model, some experiments are conducted on two benchmark data sets along with other 20 state-of-the-art saliency detection approaches. The experimental results show that our method outperforms its counterparts and can correctly detect salient regions, even when other methods fail. Besides, the usability of the proposed method in real application-based cases is verified by applying it to content-based image resizing and promising results are obtained.},
author = {Wang, Shigang and Wang, Min and Yang, Shuyuan and Zhang, Kai},
doi = {10.1109/TCSVT.2016.2642341},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/07803559.pdf:pdf},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Discriminative dictionary learning,image retargeting,joint Bayesian inference,visual saliency modeling},
number = {5},
pages = {1116--1129},
publisher = {IEEE},
title = {{Salient Region Detection via Discriminative Dictionary Learning and Joint Bayesian Inference}},
volume = {28},
year = {2018}
}
@article{Chen2018a,
abstract = {Rician noise removal for Magnetic Resonance Imaging (MRI) is very important because the MRI has been widely used in various clinical applications and the associated Rician noise deteriorates the image quality and causes errors in interpreting the images. Great efforts have recently been devoted to develop the corresponding noise-removal algorithms, particularly the development based on the newly-established Total Variation (TV) theorem. However, all the TV-based algorithms depend mainly on the gradient information and have been shown to produce the so called “blocky” artifact, which also deteriorates the image quality and causes image interpretation errors. In order to avoid producing the artifact, this paper presents a new de-noising model based on sparse representation and dictionary learning. The Split Bregman Iteration strategy is employed to implement the model. Furthermore, an appropriate dictionary is designed by the use of the Kernel Singular Value Decomposition method, resulting in a new Rician noise removal algorithm. Compared with other de-noising algorithms, the presented new algorithm can achieve superior performance, in terms of quantitative measures of the Structural Similarity Index and Peak Signal to Noise Ratio, by a series of experiments using different images in the presence of Rician noise.},
author = {Chen, Wensheng and You, Jie and Chen, Bo and Pan, Binbin and Li, Lihong and Pomeroy, Marc and Liang, Zhengrong},
doi = {10.1016/j.neucom.2018.01.066},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231218300997-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {De-noising,Dictionaries,Rician noise,Sparse representations},
pages = {130--140},
publisher = {Elsevier B.V.},
title = {{A sparse representation and dictionary learning based algorithm for image restoration in the presence of Rician noise}},
url = {https://doi.org/10.1016/j.neucom.2018.01.066},
volume = {286},
year = {2018}
}
@article{Mademlis2018,
abstract = {Recently, dictionary learning methods for unsupervised video summarization have surpassed traditional video frame clustering approaches. This paper addresses static summarization of videos depicting activities, which possess certain recurrent properties. In this context, a flexible definition of an activity video summary is proposed, as the set of key-frames that can both reconstruct the original, full-length video and simultaneously represent its most salient parts. Both objectives can be jointly optimized across several information modalities. The two criteria are merged into a “salient dictionary” learning task that is proposed as a strict definition of the video summarization problem, encapsulating many existing algorithms. Three specific, novel video summarization methods are derived from this definition: the Numerical, the Greedy and the Genetic Algorithm. In all formulations, the reconstruction term is modeled algebraically as a Column Subset Selection Problem (CSSP), while the saliency term is modeled as an outlier detection problem, a low-rank approximation problem, or a summary dispersion maximization problem. In quantitative evaluation, the Greedy Algorithm seems to provide the best balance between speed and overall performance, with the faster Numerical Algorithm a close second. All the proposed methods outperform a baseline clustering approach and two competing state-of-the-art static video summarization algorithms.},
author = {Mademlis, Ioannis and Tefas, Anastasios and Pitas, Ioannis},
doi = {10.1016/j.ins.2017.12.020},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0020025517311398-main.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Column subset selection problem,Genetic Algorithm,Key-frame extraction,Video saliency,Video summarization},
pages = {319--331},
publisher = {Elsevier Inc.},
title = {{A salient dictionary learning framework for activity video summarization via key-frame extraction}},
url = {https://doi.org/10.1016/j.ins.2017.12.020},
volume = {432},
year = {2018}
}
@article{Yu2018,
abstract = {As an important and challenging problem in computer vision, zero-shot learning (ZSL) aims at automatically recognizing the instances from unseen object classes without training data. To address this problem, ZSL is usually carried out in the following two aspects: 1) capturing the domain distribution connections between seen classes data and unseen classes data and 2) modeling the semantic interactions between the image feature space and the label embedding space. Motivated by these observations, we propose a bidirectional mapping-based semantic relationship modeling scheme that seeks for cross-modal knowledge transfer by simultaneously projecting the image features and label embeddings into a common latent space. Namely, we have a bidirectional connection relationship that takes place from the image feature space to the latent space as well as from the label embedding space to the latent space. To deal with the domain shift problem, we further present a transductive learning approach that formulates the class prediction problem in an iterative refining process, where the object classification capacity is progressively reinforced through bootstrapping-based model updating over highly reliable instances. Experimental results on four benchmark datasets (animal with attribute, Caltech-UCSD Bird2011, aPascal-aYahoo, and SUN) demonstrate the effectiveness of the proposed approach against the state-of-the-art approaches.},
archivePrefix = {arXiv},
arxivId = {1703.08893},
author = {Yu, Yunlong and Ji, Zhong and Li, Xi and Guo, Jichang and Zhang, Zhongfei and Ling, Haibin and Wu, Fei},
doi = {10.1109/TCYB.2017.2751741},
eprint = {1703.08893},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08272453.pdf:pdf},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
keywords = {Bidirectional mapping,bootstrapping,domain adaptation,transductive learning,zero-shot learning (ZSL)},
number = {10},
pages = {2908--2919},
title = {{Transductive zero-shot learning with a self-training dictionary approach}},
volume = {48},
year = {2018}
}
@article{Li2018d,
abstract = {Vision sensor systems (VSS) are widely deployed in surveillance, traffic and industrial contexts. A large number of images can be obtained via VSS. Because of the limitations of vision sensors, it is difficult to obtain an all-focused image. This causes difficulties in analyzing and understanding the image. In this paper, a novel multi-focus image fusion method (SRGF) is proposed. The proposed method uses sparse coding to classify the focused regions and defocused regions to obtain the focus feature maps. Then, a guided filter (GF) is used to calculate the score maps. An initial decision map can be obtained by comparing the score maps. After that, consistency verification is performed, and the initial decision map is further refined by the guided filter to obtain the final decision map. By performing experiments, our method can obtain satisfying fusion results. This demonstrates that the proposed method is competitive with the existing state-of-the-art fusion methods.},
author = {Li, Qilei and Yang, Xiaomin and Wu, Wei and Liu, Kai and Jeon, Gwanggil},
doi = {10.3390/s18072143},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/sensors-18-02143.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Dictionary learning,Guided filter,Multi-focus image fusion,Vision sensor system},
number = {7},
pages = {1--17},
title = {{Multi-focus image fusion method for vision sensor systems via dictionary learning with guided filter}},
volume = {18},
year = {2018}
}
@article{Yang2019,
abstract = {In modern process industries, many parameters or states can be acquired with sensors, and these parameters or states often have a close relationship with operation conditions. Unfortunately, the process often operates under different modes, and labels thereof are often unknown. In practice, labeling for sampled data is expensive and time-consuming, so identifying the operation conditions of the industrial process is difficult. In addition, sampled data from the industrial system are always contaminated by outliers or noise. Therefore, a robust process monitoring method for the multimode process is particularly important and challenging. In this paper, a robust dictionary learning method is proposed for processes with multiple unknown modes. Firstly, by taking the sparsity of outliers into account, a robust dictionary learning method is proposed to identify and remove the outliers and noise in the sampled training data. Secondly, an iterative minimization algorithm is designed for solving the dictionary learning optimization program. Thirdly, based on the sparsity of the sparse code, we partition the sparse code into different clusters via spectral clustering method, and then the dictionary is divided into some sub-dictionaries according to the cluster results of sparse code. Lastly, when a new sample is generated, we reconstruct it under different sub-dictionaries, and the smallest dictionary reconstruction error is calculated as a classifier for process monitoring and fault detection. To evaluate the validity and effectiveness of the proposed monitoring approach, we conduct extensive experiments on a numerical simulation, the continuous stirred tank heater (CSTH) process, and an industrial aluminum electrolysis process, in comparison with several state-of-the-art methods. The experimental results demonstrate that the proposed method is able to provide satisfying monitoring results, and it is also robust to outliers in the sampled training data. It is worth mentioning that the proposed method is an unsupervised learning method, therefore, it is more suitable for the process monitoring of real industrial systems.},
author = {Yang, Chunhua and Zhou, Longfei and Huang, Keke and Ji, Hongquan and Long, Cheng and Chen, Xiaofang and Xie, Yongfang},
doi = {10.1016/j.neucom.2018.12.024},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-Multimode process monitoring based on robust dictionary learning with application to aluminium electrolysis process.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Aluminum electrolysis process,Multimode process monitoring,Outliers,Robust dictionary learning,Unsupervised learning},
pages = {305--319},
publisher = {Elsevier B.V.},
title = {{Multimode process monitoring based on robust dictionary learning with application to aluminium electrolysis process}},
url = {https://doi.org/10.1016/j.neucom.2018.12.024},
volume = {332},
year = {2019}
}
@article{Yang2012a,
author = {Yang, Bin and Li, Shutao},
doi = {10.1016/j.inffus.2010.04.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1566253510000448-main.pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
number = {1},
pages = {10--19},
publisher = {Elsevier B.V.},
title = {{Pixel-level image fusion with simultaneous orthogonal matching pursuit}},
url = {http://dx.doi.org/10.1016/j.inffus.2010.04.001},
volume = {13},
year = {2012}
}
@article{Said2018,
abstract = {In the context of mobile Health (mHealth) applications, data are prone to several sources of contamination which would lead to false interpretation and misleading classification results. In this paper, a robust deep learning approach with low rank model is proposed to classify mHealth vital signs. Further-more, we propose using the Schatten-p norm instead of the classic nuclear norm since it has shown better recovery performance for several applications. We conduct a comprehensive study where we compare our method to the state-of-art methods and evaluate its performance with respect to the key system parameters. Our findings show indeed that combining deep network with dictionary learning model is effective for vital signs classification even in presence of 50{\%} corruption with 8{\%} improvement over the closest performance.},
author = {Said, Ahmed Ben and Mohamed, Amr and Elfouly, Tarek and Abualsaud, Khalid and Harras, Khaled},
doi = {10.1109/IWCMC.2018.8450434},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08450434.pdf:pdf},
isbn = {9781538620700},
journal = {2018 14th International Wireless Communications and Mobile Computing Conference, IWCMC 2018},
keywords = {classification,deep learning,low rank,mHealth},
pages = {358--363},
publisher = {IEEE},
title = {{Deep learning and low rank dictionary model for mHealth data classification}},
year = {2018}
}
@article{Wang2019a,
abstract = {Online dictionary learning (ODL) is an emerging and efficient dictionary learning algorithm, which can extract fault features information of fault signals in most occasions. However, the typical ODL algorithm fails to consider the interference of noise and the structural features of the fault signals, which leads to the fault features of weak fault signals that are difficult to extract. For that, a novel feature enhancement method based on an improved constraint model of an ODL (ICM-ODL) algorithm has been proposed in this paper. For the stage of dictionary learning, the elastic-net constraint is used to promote the anti-noise performance of the dictionary atoms. For the stage of signals sparse coding, the l 2 ,1 norm constraint is added to learn the structural features of fault signals. In addition, a variational mode decomposition algorithm is used to reduce the impact of noise on the signal initially. Taking the weak fault signals of bearing as examples for analysis, the results show that the feature enhancement of the weak fault signals is fulfilled by using the ICM-ODL algorithm. Compared with the typical ODL method, the ICM-ODL algorithm can not only improves the anti-noise performance of the dictionary atoms, but also removes the noise compositions of the reconstructed signal significantly.},
author = {Wang, Huaqing and Wang, Pengxin and Song, Liuyang and Ren, Bangyue and Cui, Lingli},
doi = {10.1109/ACCESS.2019.2895776},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-24-A Novel Feature Enhancement MethodBased on Improved Constraint Modelof Online Dictionary Learning.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Online dictionary learning,elastic-net,feature enhancement,l 2 ,1 norm,sparse representation},
pages = {17599--17607},
publisher = {IEEE},
title = {{A Novel Feature Enhancement Method Based on Improved Constraint Model of Online Dictionary Learning}},
volume = {7},
year = {2019}
}
@article{Liu2019c,
abstract = {For most sparse coding methods, data samples are first encoded as hand-crafted features, followed by another separate learning step that generates dictionary and sparse codes. However, such feature representations may not be optimally compatible with the learning process, thus producing suboptimal results. In this paper, we propose a new architecture for nonlinear dictionary learning with sparse coding, in which samples are mapped into sparse codes via carefully designed stacked auto-encoder (SAE) networks. We jointly learn a low-dimensional embedding of the data samples by means of an SAE and a dictionary in the low-dimensional space. Further, to leverage the prior knowledge, we develop a kernel regularized nonlinear dictionary learning method, which effectively incorporates the knowledge provided by the hand-crafted kernel. An iterative algorithm is developed to jointly search the solutions of the associated optimization problem and extensive experimental validations are performed to show that the proposed kernel regularized dictionary learning method achieves satisfactory performance.},
author = {Liu, Huaping and Liu, He and Sun, Fuchun and Fang, Bin},
doi = {10.1109/TSMC.2017.2736248},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-4-Kernel Regularized Nonlinear DictionaryLearning for Sparse Coding.pdf:pdf},
issn = {21682232},
journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
keywords = {Kernel dictionary learning,kernel sparse coding,stacked auto-encoder (SAE)},
number = {4},
pages = {766--775},
publisher = {IEEE},
title = {{Kernel Regularized Nonlinear Dictionary Learning for Sparse Coding}},
volume = {49},
year = {2019}
}
@article{Shakeri2018,
abstract = {This paper provides fundamental limits on the sample complexity of estimating dictionaries for tensor data. The specific focus of this work is on K th-order tensor data and the case where the underlying dictionary can be expressed in terms of K smaller dictionaries. It is assumed the data are generated by linear combinations of these structured dictionary atoms and observed through white Gaussian noise. This work first provides a general lower bound on the minimax risk of dictionary learning for such tensor data and then adapts the proof techniques for specialized results in the case of sparse and sparse-Gaussian linear combinations. The results suggest the sample complexity of dictionary learning for tensor data can be significantly lower than that for unstructured data: for unstructured data it scales linearly with the product of the dictionary dimensions, whereas for tensor-structured data the bound scales linearly with the sum of the product of the dimensions of the (smaller) component dictionaries. A partial converse is provided for the case of 2nd-order tensor data to show that the bounds in this paper can be tight. This involves developing an algorithm for learning highly-structured dictionaries from noisy tensor data. Finally, numerical experiments highlight the advantages associated with explicitly accounting for tensor data structure during dictionary learning.},
archivePrefix = {arXiv},
arxivId = {1608.02792},
author = {Shakeri, Zahra and Bajwa, Waheed U. and Sarwate, Anand D.},
doi = {10.1109/TIT.2018.2799931},
eprint = {1608.02792},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08274934.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Dictionary learning,Kronecker-structured dictionary,minimax bounds,sparse representations,tensor data},
number = {4},
pages = {2706--2726},
publisher = {IEEE},
title = {{Minimax Lower Bounds on Dictionary Learning for Tensor Data}},
volume = {64},
year = {2018}
}
@article{Vishwakarma2018,
abstract = {Recently, several machine learning algorithms have been applied for classifying micro-Doppler signatures from different human motions. However, these algorithms must demonstrate versatility in handling diversity in test and training data to be used for real-life scenarios. For example, situations may arise where the propagation channel or the presence of interference sources in the test site will permit only specific frequency bands of radar operation. These bands may differ from those used previously while training. In this paper, we examine the performances of three sparsity driven dictionary learning algorithms - synthesis, deep, and analysis - for learning unique features extracted from training data gathered across multiple carrier frequencies. These features are subsequently used for classifying test data from another distinct carrier frequency. Our experimental results, from measurement data, show that the dictionary learning algorithms are capable of extracting meaningful representations of the micro-Dopplers despite the rich frequency diversity in the data. In particular, the deep dictionary learning algorithm yields a high classification accuracy of 91{\%} with a very low computational time for testing.},
author = {Vishwakarma, Shelly and Ram, Shobha Sundar},
doi = {10.1109/ACCESS.2018.2843391},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08375093.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Radar,analysis dictionary learning,classification,deep learning,micro-Dopplers,sparse coding,synthesis dictionary learning},
pages = {29793--29805},
publisher = {IEEE},
title = {{Dictionary Learning with Low Computational Complexity for Classification of Human Micro-Dopplers Across Multiple Carrier Frequencies}},
volume = {6},
year = {2018}
}
@article{Huang2018,
abstract = {Multi-modality medical imaging is increasingly used for comprehensive assessment of complex diseases in either diagnostic examinations or as part of medical research trials. Different imaging modalities provide complementary information about living tissues. However, multi-modal examinations are not always possible due to adversary factors, such as patient discomfort, increased cost, prolonged scanning time, and scanner unavailability. In additionally, in large imaging studies, incomplete records are not uncommon owing to image artifacts, data corruption or data loss, which compromise the potential of multi-modal acquisitions. In this paper, we propose a weakly coupled and geometry co-regularized joint dictionary learning method to address the problem of cross-modality synthesis while considering the fact that collecting the large amounts of training data is often impractical. Our learning stage requires only a few registered multi-modality image pairs as training data. To employ both paired images and a large set of unpaired data, a cross-modality image matching criterion is proposed. Then, we propose a unified model by integrating such a criterion into the joint dictionary learning and the observed common feature space for associating cross-modality data for the purpose of synthesis. Furthermore, two regularization terms are added to construct robust sparse representations. Our experimental results demonstrate superior performance of the proposed model over state-of-the-art methods.},
author = {Huang, Yawen and Shao, Ling and Frangi, Alejandro F.},
doi = {10.1109/TMI.2017.2781192},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08169118.pdf:pdf},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Dictionary learning,MRI,domain adaption,image synthesis,manifold learning,sparse representation},
number = {3},
pages = {815--827},
publisher = {IEEE},
title = {{Cross-Modality Image Synthesis via Weakly Coupled and Geometry Co-Regularized Joint Dictionary Learning}},
volume = {37},
year = {2018}
}
@article{Upla2015,
abstract = {In this paper, we propose a new approach for multiresolution fusion using contourlet transform (CT). The method is based on modeling the low spatial resolution (LR) and high spectral resolution multispectral (MS) image as the degraded and noisy version of their high spatial resolution version. Since this is an ill-posed problem, it requires regularization in order to obtain the final solution. In this paper, we first obtain the initial estimate of the fused image from the available MS image and the panchromatic (Pan) image by using the CT domain learning. Since CT provides better directional edges, the initial estimate has better edge details. Using the initial estimate, we obtain the degradation that accounts for the aliasing between the LR MS image and fused image. Regularization is carried out by modeling the texture of the final fused image as a homogeneous Markov random field (MRF) prior, where the MRF parameter is estimated using the initial estimate. The use of MRF prior on the final fused image takes care of the spatial dependencies among the pixels. A simple gradient-based optimization technique is used to obtain the final fused image. Although we use homogeneous MRF, the proposed approach preserves the edges in the final fused image by retaining the edges from the initial estimate and by carrying out the optimization on nonedge pixels only. Therefore, the advantage of the proposed method lies in preserving the discontinuities without using the discontinuity preserving prior, thus avoiding the use of computationally taxing optimization techniques for regularization purposes. In addition, the proposed method causes minimum spectral distortion since it learns the texture using contourlet coefficients and does not use actual Pan image pixel intensities. We demonstrate the effectiveness of our approach by conducting the experiments using subsampled and nonsubsampled CT on different data sets captured using Ikonos-2, Quickbird, and Worldview-2 satellites.},
author = {Upla, Kishor P. and Joshi, Manjunath V. and Gajjar, Prakash P.},
doi = {10.1109/TGRS.2014.2371812},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Upla-2015-An-edge-preserving-multiresolution-.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Canny edge detector,Contourlet transform (CT),Markov random field (MRF),gradient descent,image fusion,maximum a posteriori (MAP)},
number = {6},
pages = {3210--3220},
publisher = {IEEE},
title = {{An edge preserving multiresolution fusion: Use of contourlet transform and MRF prior}},
volume = {53},
year = {2015}
}
@article{Garcia-Cardona2018,
abstract = {Convolutional sparse representations are a form of sparse representation with a dictionary that has a structure that is equivalent to convolution with a set of linear filters. While effective algorithms have recently been developed for the convolutional sparse coding problem, the corresponding dictionary learning problem is substantially more challenging. Furthermore, although a number of different approaches have been proposed, the absence of thorough comparisons between them makes it difficult to determine which of them represents the current state of the art. The present work both addresses this deficiency and proposes some new approaches that outperform existing ones in certain contexts. A thorough set of performance comparisons indicates a very wide range of performance differences among the existing and proposed methods, and clearly identifies those that are the most effective.},
archivePrefix = {arXiv},
arxivId = {1709.02893},
author = {Garcia-Cardona, Cristina and Wohlberg, Brendt},
doi = {10.1109/tci.2018.2840334},
eprint = {1709.02893},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08364626.pdf:pdf},
issn = {2573-0436},
journal = {IEEE Transactions on Computational Imaging},
number = {3},
pages = {366--381},
publisher = {IEEE},
title = {{Convolutional Dictionary Learning: A Comparative Review and New Algorithms}},
volume = {4},
year = {2018}
}
@misc{Manafy2006,
abstract = {The article focuses on literacy and access to books in a time of the proliferation of the so-lled digital natives. A National Literacy Trust research revealed that 86{\%} of young British people own a mobile phone while only 73{\%} of which have books of their own and added that there is a strong link between the reading ability of the youth with their access to books. ReadWriteWeb said that parental supervision is also responsible for the literacy of their young and that there are ways of taking advantage of the advanced technology for the kids to learn.},
author = {Manafy, Michelle},
booktitle = {EContent},
doi = {10.2307/1348337},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/read{\_}me.txt:txt},
issn = {15252531},
number = {4},
pages = {6},
title = {{Read me}},
volume = {29},
year = {2006}
}
@article{Tang2019,
abstract = {A discriminative structured analysis dictionary is proposed for the classification task. A structure of the union of subspaces (UoS) is integrated into the conventional analysis dictionary learning to enhance the capability of discrimination. A simple classifier is also simultaneously included into the formulated functional to ensure a more complete consistent classification. The solution of the algorithm is efficiently obtained by the linearized alternating direction method of multipliers. Moreover, a distributed structured analysis dictionary learning is also presented to address large scale datasets. It can group-(class-) independently train the structured analysis dictionaries by different machines/cores/threads, and therefore avoid a high computational cost. A consensus structured analysis dictionary and a global classifier are jointly learned in the distributed approach to safeguard the discriminative power and the efficiency of classification. Experiments demonstrate that our method achieves a comparable or better performance than the state-of-the-art algorithms in a variety of visual classification tasks. In addition, the training and testing computational complexity are also greatly reduced.},
archivePrefix = {arXiv},
arxivId = {1807.04899},
author = {Tang, Wen and Panahi, Ashkan and Krim, Hamid and Dai, Liyi},
doi = {10.1109/tip.2019.2919409},
eprint = {1807.04899},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08745700.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
number = {12},
pages = {6035--6046},
publisher = {IEEE},
title = {{Analysis Dictionary Learning Based Classification: Structure for Robustness}},
volume = {28},
year = {2019}
}
@article{Protter2009,
abstract = {In this paper, we consider denoising of image sequences that are corrupted by zero-mean additive white Gaussian noise. Relative to single image denoising techniques, denoising of sequences aims to also utilize the temporal dimension. This assists in getting both faster algorithms and better output quality. This paper focuses on utilizing sparse and redundant representations for image sequence denoising, extending the work reported in [1], [2]. In the single image setting, the K-SVD algorithm is used to train a sparsifying dictionary for the corrupted image. This paper generalizes the above algorithm by offering several extensions: i) the atoms used are 3-D; ii) the dictionary is propagated from one frame to the next, reducing the number of required iterations; and iii) averaging is done on patches in both spatial and temporal neighboring locations. These modifications lead to substantial benefits in complexity and denoising performance, compared to simply running the single image algorithm sequentially. The algorithm's performance is experimentally compared to several state-of-the-art algorithms, demonstrating comparable or favorable results. {\textcopyright} 2008 IEEE.},
author = {Protter, Matan and Elad, Michael},
doi = {10.1109/TIP.2008.2008065},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/10.1.1.123.6271.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Denoising,K-SVD,OMP,Sparse representations,Video},
number = {1},
pages = {27--35},
title = {{Image sequence denoising via sparse and redundant representations}},
volume = {18},
year = {2009}
}
@article{Yan2018,
abstract = {Over the past years, dictionary learning (DL) based methods have achieved excellent performance in facial expression recognition (FER), where training and testing data are usually presumed to have the same distributions. But in the practical scenarios, this assumption is often broken, especially when training and testing data come from different databases, a.k.a. the cross-database FER problem. In this paper, we focus on the unsupervised cross-domain FER problem where all the samples in target domain are completely unannotated. To address this problem, we propose an unsupervised domain adaptive dictionary learning (UDADL) model to bridge source domain and target domain by learning a shared dictionary. The encoding of the two domains on this dictionary are constrained to be mutually embedded on each other. To bypass the solution complexity, we borrow an analysis dictionary to seek for approximate solutions as the latent variable to favor sub-solvers to be analyzed. To evaluate the performance of the proposed UDADL model, we conduct extensive experiments on the widely used Multi-PIE and BU-3DFE databases. The experimental results demonstrated that the proposed UDADL method outperforms recent domain adaptation FER methods and achieved the state-of-the-art performance.},
author = {Yan, Keyu and Zheng, Wenming and Cui, Zhen and Zong, Yuan and Zhang, Tong and Tang, Chuangao},
doi = {10.1016/j.neucom.2018.07.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231218308294-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Cross-domain facial expression recognition,Dictionary learning,Domain adaptation,Facial expression recognition},
pages = {84--91},
publisher = {Elsevier B.V.},
title = {{Unsupervised facial expression recognition using domain adaptation based dictionary learning approach}},
url = {https://doi.org/10.1016/j.neucom.2018.07.003},
volume = {319},
year = {2018}
}
@article{Jiang2019,
abstract = {Face sketch synthesis is a crucial issue in digital entertainment and law enforcement. It can bridge the considerable texture discrepancy between face photos and sketches. Most of the current face sketch synthesis approaches directly to learn the relationship between the photos and sketches, and it is very difficult for them to generate the individual specific features, which we call rare characteristics. In this paper, we propose a novel face sketch synthesis approach through residual learning. In contrast to traditional approaches, which aim to reconstruct a sketch image directly (i.e., learn the mapping relationship between the photo and sketch), we aim to predict the residual image by learning the mapping relationship between the photo and residual, i.e., the difference between the photo and sketch, given an observed photo. This technique will render optimizing the residual mapping easier than optimizing the original mapping and deriving rare characteristic information. We also introduce a joint dictionary learning algorithm by preserving the local geometry structure of a data space. Through the learned joint dictionary, we transform the face sketch synthesis from an image space to a new and compact space; the new and compact space is spanned by learned dictionary atoms, where the manifold assumption can be further guaranteed. Results show that the proposed method demonstrates an impressive performance in the face sketch synthesis task on three public face sketch datasets and various real-world photos. These results are derived by comparing the proposed method with several state-of-the-art techniques, including certain recently proposed deep learning-based approaches.},
author = {Jiang, Junjun and Yu, Yi and Wang, Zheng and Liu, Xianming and Ma, Jiayi},
doi = {10.1109/TIP.2018.2870936},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-5-Graph-Regularized Locality-Constrained JointDictionary and Residual Learning forFace Sketch Synthesis.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Face sketch synthesis,joint dictionary learning,local geometry structure,rare characteristics,residual learning},
number = {2},
pages = {628--641},
title = {{Graph-regularized locality-constrained joint dictionary and residual learning for face sketch synthesis}},
volume = {28},
year = {2019}
}
@article{Alguri2018,
abstract = {{\textcopyright} 2018 Acoustical Society of America. In guided wave structural health monitoring, damage detection is often accomplished by comparing measurements before damage (i.e., baseline data) and after damage (i.e., test data). Yet, in practical scenarios, baseline data is often unavailable. Data from surrogate structures (structures similar to the test structure) could replace baseline data, but due to small differences in material properties, such as thickness, temperature, and other effects, this data is often unreliable. In this paper, a dictionary learning framework overcomes this challenge and detects damage with surrogate information. The framework combines wave propagation characteristics of a test structure with geometric information from surrogate structures to create a synthetic damage-free baseline. The test data is compared with the synthetic baseline to detect damage. The framework is evaluated with four 108 mm ×108 mm plates: two 1.6-mm thick aluminum plates, one 1.6-mm thick steel plate, and one 6.25 mm thick aluminum plate. The framework is applied to each test structure after learning from plates with different material properties and thicknesses. With full wavefield data, this paper successfully isolates reflections from a mass without using explicit baseline data. Furthermore, with sparse guided wave data, this paper shows that a drop in a correlation coefficient can detect a mass without using explicit baseline data.},
author = {Alguri, K. Supreet and Melville, Joseph and Harley, Joel B.},
doi = {10.1121/1.5042240},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1.5042240.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pages = {3807--3818},
title = {{Baseline-free guided wave damage detection with surrogate data and dictionary learning}},
volume = {143},
year = {2018}
}
@article{Liu2015,
abstract = {In this study, a novel adaptive sparse representation (ASR) model is presented for simultaneous image fusion and denoising. As a powerful signal modelling technique, sparse representation (SR) has been successfully employed in many image processing applications such as denoising and fusion. In traditional SR-based applications, a highly redundant dictionary is always needed to satisfy signal reconstruction requirement since the structures vary significantly across different image patches. However, it may result in potential visual artefacts as well as high computational cost. In the proposed ASR model, instead of learning a single redundant dictionary, a set of more compact sub-dictionaries are learned from numerous high-quality image patches which have been pre-classified into several corresponding categories based on their gradient information. At the fusion and denoising processes, one of the sub-dictionaries is adaptively selected for a given set of source image patches. Experimental results on multi-focus and multi-modal image sets demonstrate that the ASR-based fusion method can outperform the conventional SR-based method in terms of both visual quality and objective assessment.},
author = {Liu, Yu and Wang, Zengfu},
doi = {10.1049/iet-ipr.2014.0311},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Simultaneous image fusion .pdf:pdf},
issn = {17519659},
journal = {IET Image Processing},
number = {5},
pages = {347--357},
title = {{Simultaneous image fusion and denoising with adaptive sparse representation}},
volume = {9},
year = {2015}
}
@article{Xu2018,
abstract = {Cross-Project Defect Prediction (CPDP) is an active topic for predicting defects on projects (target projects) with scarce-labeled data by reusing the classification models from other projects (source projects). Traditional CPDP methods require common features between the data of two projects and utilize them to construct defect prediction models. However, when cross-project data do not satisfy the requirement, i.e., heterogeneous CPDP (HCPDP) scenario, these methods become infeasible. In this paper, we propose a novel HCPDP method called Heterogeneous Domain Adaptation (HDA) to address the issue. HDA treats the cross-project data as being from two different domains with heterogeneous feature sets. It employs the domain adaptation method to embed the data from the two domains into a comparable feature space with a lower dimension, then measures the difference between the two mapped domains of data using the dictionaries learned from them with the dictionary learning technique. We comprehensively evaluate HDA on 94 cross-project pairs of 12 projects from three open-source defect data sets with three performance indicators, i.e., F-measure, Balance, and AUC. Compared with the two state-of-the-art HCPDP methods, the experimental results indicate that HDA improves 0.219 and 0.336 in terms of F-measure, 0.185 and 0.215 in terms of Balance, and 0.131 and 0.035 in terms of AUC. In addition, HDA achieves comparable results compared with Within-Project Defect Prediction (WPDP) setting and a state-of-the-art unsupervised learning method in most cases.},
author = {Xu, Zhou and Yuan, Peipei and Zhang, Tao and Tang, Yutian and Li, Shuai and Xia, Zhen},
doi = {10.1109/ACCESS.2018.2873755},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08481686.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Heterogeneous cross-project defect prediction,dictionary learning,heterogeneous domain adaptation},
pages = {57597--57613},
publisher = {IEEE},
title = {{HDA: Cross-project defect prediction via heterogeneous domain adaptation with dictionary learning}},
volume = {6},
year = {2018}
}
@article{Li2013,
abstract = {A fast and effective image fusion method is proposed for creating a highly informative fused image through merging multiple images. The proposed method is based on a two-scale decomposition of an image into a base layer containing large scale variations in intensity, and a detail layer capturing small scale details. A novel guided filtering-based weighted average technique is proposed to make full use of spatial consistency for fusion of the base and detail layers. Experimental results demonstrate that the proposed method can obtain state-of-the-art performance for fusion of multispectral, multifocus, multimodal, and multiexposure images.},
author = {Li, Shutao and Kang, Xudong and Hu, Jianwen},
doi = {10.1109/TIP.2013.2244222},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/GF.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Guided filter,image fusion,spatial consistency,two-scale decomposition},
number = {7},
pages = {2864--2875},
title = {{Image fusion with guided filtering}},
volume = {22},
year = {2013}
}
@article{Du2018,
abstract = {The dictionary used in sparse coding plays a key role in sparse representation-based classification. A desired dictionary should have powerful representational and discriminative capability. In this paper, we propose a discriminative low-rank graph preserving dictionary learning (DLRGP{\_}DL) method to learn a discriminative structured dictionary for sparse representation-based image recognition, in which training samples might be corrupted with relatively large noise. Specifically, we impose the Schatten-p quasi-norm regularization on sub-dictionaries to make them to be of low-rank, which can effectively reduce the negative effect of noise contained in training samples and make the learned dictionary pure and compact. To improve the discriminative capability of the learned dictionary, we apply a discriminative graph preserving criterion to coding coefficients during the dictionary learning process with the goal that the similar training samples from the same class have similar coding coefficients. The learned dictionary is first used for sparse coding, and then both the learned coding coefficients of training samples and the class-specific reconstruction errors are used for classification. The experimental results on four image datasets demonstrate the effectiveness and robustness of DLRGP{\_}DL.},
author = {Du, Haishun and Zhao, Zhaolong and Wang, Sheng and Zhang, Fan},
doi = {10.1016/j.neucom.2017.08.068},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231217315138-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Dictionary learning,Graph preserving,Image recognition,Low-rank,Sparse representation},
pages = {697--710},
publisher = {Elsevier B.V.},
title = {{Discriminative low-rank graph preserving dictionary learning with Schatten-p quasi-norm regularization for image recognition}},
url = {https://doi.org/10.1016/j.neucom.2017.08.068},
volume = {275},
year = {2018}
}
@article{Yang2012b,
abstract = {In this paper, we present a novel pixel-level color-image fusion method with extension of the joint sparsity model which exploits the inter-correlations among the R, G and B planes. The objective is to achieve the colors more natural for the fused images, compared to individually reconstructing the R, G, B images. This paper also demonstrates an extension of the fusion algorithm to the proper handling of additional Gaussian and impulse noises. Several color multi-focus images are used to test the performances of the proposed method. The results clearly indicate the feasibility of the proposed approach. {\textcopyright} 2012 ICPR Org Committee.},
author = {Yang, Bin and Luo, Jie and Li, Shutao},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/06460150.pdf:pdf},
isbn = {9784990644109},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
number = {Icpr},
pages = {376--379},
publisher = {IEEE},
title = {{Color image fusion with extend joint sparse model}},
year = {2012}
}
@article{Yin2013,
abstract = {Given multiple source images of the same scene, image fusion integrates the inherent complementary information into one single image, and thus provides a more complete and accurate description. However, when the source images are of low-resolution, the resultant fused image can still be of low-quality, hindering further image analysis. To improve the resolution, a separate image super-resolution step can be performed. In this paper, we propose a novel framework for simultaneous image fusion and super-resolution. It is based on the use of sparse representations, and consists of three steps. First, the low-resolution source images are interpolated and decomposed into high- And low-frequency components. Sparse coefficients from these components are then computed and fused by using image fusion rules. Finally, the fused sparse coefficients are used to reconstruct a high-resolution fused image. Experiments on various types of source images (including magnetic resonance images, X-ray computed tomography images, visible images, infrared images, and remote sensing images) demonstrate the superiority of the proposed method both quantitatively and qualitatively. {\textcopyright} 2012 Elsevier B.V.},
author = {Yin, Haitao and Li, Shutao and Fang, Leyuan},
doi = {10.1016/j.inffus.2012.01.008},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Yin-2013-Simultaneous-image-fusion-and-super.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Image fusion,Image super-resolution,Sparse representation},
number = {3},
pages = {229--240},
publisher = {Elsevier B.V.},
title = {{Simultaneous image fusion and super-resolution using sparse representation}},
url = {http://dx.doi.org/10.1016/j.inffus.2012.01.008},
volume = {14},
year = {2013}
}
@article{Kim2016,
author = {Kim, Minjae and Han, David K and Ko, Hanseok},
doi = {10.1016/j.inffus.2015.03.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Joint patch clustering-based dictionary learning for multimodal imagefusion.pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {multimodal image fusion,sparse representation},
pages = {198--214},
publisher = {Elsevier B.V.},
title = {{Joint patch clustering-based dictionary learning for multimodal image fusion}},
url = {http://dx.doi.org/10.1016/j.inffus.2015.03.003},
volume = {27},
year = {2016}
}
@article{Kim2016a,
abstract = {Constructing a good dictionary is the key to a successful image fusion technique in sparsity-based models. An efficient dictionary learning method based on a joint patch clustering is proposed for multimodal image fusion. To construct an over-complete dictionary to ensure sufficient number of useful atoms for representing a fused image, which conveys image information from different sensor modalities, all patches from different source images are clustered together with their structural similarities. For constructing a compact but informative dictionary, only a few principal components that effectively describe each of joint patch clusters are selected and combined to form the over-complete dictionary. Finally, sparse coefficients are estimated by a simultaneous orthogonal matching pursuit algorithm to represent multimodal images with the common dictionary learned by the proposed method. The experimental results with various pairs of source images validate effectiveness of the proposed method for image fusion task.},
author = {Kim, Minjae and Han, David K. and Ko, Hanseok},
doi = {10.1016/j.inffus.2015.03.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Kim-2016-Joint-patch-clustering-based-dictio.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Clustering,Dictionary learning,K-SVD,Multimodal image fusion,Sparse representation},
pages = {198--214},
publisher = {Elsevier B.V.},
title = {{Joint patch clustering-based dictionary learning for multimodal image fusion}},
url = {http://dx.doi.org/10.1016/j.inffus.2015.03.003},
volume = {27},
year = {2016}
}
@article{Kelsey2018,
abstract = {Electrodermal Activity (EDA) − an index of sympathetic nervous system arousal − is one of the primary methods used in psychophysiology to assess the autonomic nervous system [1]. While many studies collect EDA data in short, laboratory-based experiments, recent developments in wireless biosensing have enabled longer, ‘out-of-lab' ambulatory studies to become more common [2]. Such ambulatory methods are beneficial in that they facilitate more longitudinal and environmentally diverse EDA data collection. However, they also introduce challenges for efficiently and accurately identifying discrete skin conductance responses (SCRs) and measurement artifacts, which complicate analyses of ambulatory EDA data. Therefore, interest in developing automated systems that facilitate analysis of EDA signals has increased in recent years. Ledalab is one such system that automatically identifies SCRs and is currently considered a gold standard in the field of ambulatory EDA recording. However, Ledalab, like other current systems, cannot distinguish between SCRs and artifacts. The present manuscript describes a novel technique to accurately and efficiently identify SCRs and artifacts using curve fitting and sparse recovery methods We show that our novel approach, when applied to expertly labeled EDA data, detected 69{\%} of the total labeled SCRs in an EDA signal compared to 45{\%} detection ability of Ledalab. Additionally, we demonstrate that our system can distinguish between artifact and SCR shapes with an accuracy of 74{\%}. This work, along with our previous work [3], suggests that matching pursuit is a viable methodology to quickly and accurately identify SCRs in ambulatory collected EDA data, and that artifact shapes can be separated from SCR shapes.},
author = {Kelsey, Malia and Akcakaya, Murat and Kleckner, Ian R. and Palumbo, Richard Vincent and Barrett, Lisa Feldman and Quigley, Karen S. and Goodwin, Matthew S.},
doi = {10.1016/j.bspc.2017.08.024},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1746809417302008-main.pdf:pdf},
issn = {17468108},
journal = {Biomedical Signal Processing and Control},
keywords = {Artifact detection,Electrodermal activity,Orthogonal matching pursuit,Skin conductance response,Sparse recovery},
pages = {58--70},
publisher = {Elsevier Ltd},
title = {{Applications of sparse recovery and dictionary learning to enhance analysis of ambulatory electrodermal activity data}},
url = {https://doi.org/10.1016/j.bspc.2017.08.024},
volume = {40},
year = {2018}
}
@article{You2018,
abstract = {We present a probabilistic modeling and inference framework for discriminative analysis dictionary learning under a weak supervision setting. Dictionary learning approaches have been widely used for tasks such as low-level signal denoising and restoration as well as high-level classification tasks, which can be applied to audio and image analysis. Synthesis dictionary learning aims at jointly learning a dictionary and corresponding sparse coefficients to provide accurate data representation. This approach is useful for denoising and signal restoration, but may lead to suboptimal classification performance. By contrast, analysis dictionary learning provides a transform that maps data to a sparse discriminative representation suitable for classification. We consider the problem of analysis dictionary learning for time-series data under a weak supervision setting in which signals are assigned with a global label instead of an instantaneous label signal. We propose a discriminative probabilistic model that incorporates both label information and sparsity constraints on the underlying latent instantaneous label signal using cardinality control. We present the expectation-maximization procedure for maximum likelihood estimation of the proposed model. To facilitate a computationally efficient E-step, we propose both a chain and a novel tree graph reformulation of the graphical model. The performance of the proposed model is demonstrated on both synthetic and real-world data.},
archivePrefix = {arXiv},
arxivId = {1802.01709},
author = {You, Zeyu and Raich, Raviv and Fern, Xiaoli Z. and Kim, Jinsub},
doi = {10.1109/TSP.2018.2807422},
eprint = {1802.01709},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08294264.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Weakly-supervision learning,chain inference,convolutive analysis dictionary,tree inference},
number = {10},
pages = {2527--2541},
publisher = {IEEE},
title = {{Weakly Supervised Dictionary Learning}},
volume = {66},
year = {2018}
}
@article{Alonso-Fernandez2019,
abstract = {The lack of resolution has a negative impact on the performance of image-based biometrics. While many generic super-resolution methods have been proposed to restore low-resolution images, they usually aim to enhance their visual appearance. However, an overall visual enhancement of biometric images does not necessarily correlate with a better recognition performance. Reconstruction approaches thus need to incorporate the specific information from the target biometric modality to effectively improve recognition performance. This paper presents a comprehensive survey of iris super-resolution approaches proposed in the literature. We have also adapted an eigen-patches' reconstruction method based on the principal component analysis eigen-transformation of local image patches. The structure of the iris is exploited by building a patch-position-dependent dictionary. In addition, image patches are restored separately, having their own reconstruction weights. This allows the solution to be locally optimized, helping to preserve local information. To evaluate the algorithm, we degraded the high-resolution images from the CASIA Interval V3 database. Different restorations were considered, with 15×15 pixels being the smallest resolution evaluated. To the best of our knowledge, this is the smallest resolutions employed in the literature. The experimental framework is complemented with six publicly available iris comparators that were used to carry out biometric verification and identification experiments. The experimental results show that the proposed method significantly outperforms both the bilinear and bicubic interpolations at a very low resolution. The performance of a number of comparators attains an impressive equal error rate as low as 5{\%} and a Top-1 accuracy of 77{\%}-84{\%} when considering the iris images of only 15×15 pixels. These results clearly demonstrate the benefit of using trained super-resolution techniques to improve the quality of iris images prior to matching.},
author = {Alonso-Fernandez, Fernando and Farrugia, Reuben A. and Bigun, Josef and Fierrez, Julian and Gonzalez-Sosa, Ester},
doi = {10.1109/ACCESS.2018.2889395},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08586871.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Iris hallucination,PCA,eigen-patch,iris recognition,super-resolution},
pages = {6519--6544},
publisher = {IEEE},
title = {{A Survey of Super-Resolution in Iris Biometrics with Evaluation of Dictionary-Learning}},
volume = {7},
year = {2019}
}
@article{Wang2018a,
abstract = {Sparse representation techniques have become increasingly promising for localizing the sound source in reverberant environment, where the multipath channel effects can be accurately characterized by the image model. In this paper, a dictionary is constructed by discretizing the inner space of the enclosure, which is parameterized by the unknown energy reflective ratio. More specifically, each atom of the dictionary can characterize a specific source-to-microphone multipath channel. Subsequently, source localization can be reformulated as a joint sparse signal recovery and parametric dictionary learning problem. In particular, a sparse Bayesian framework is utilized for modeling, where its solution can be obtained by variational Bayesian expectation maximization technique. Moreover, the joint sparsity in frequency domain is exploited to improve the dictionary learning performances. A remarkably advantage of this approach is that no laborious parameter tuning procedure is required and statistical information can be provided. Numerical simulation results have shown that the proposed algorithm achieves high source localization accuracy, low sidelobes and high robustness for multiple sources with low computational complexity in strong reverberant environments, compared with other state-of-the-art methods.},
author = {Wang, Lu and Liu, Yanshan and Zhao, Lifan and Wang, Qiang and Zeng, Xiangyang and Chen, Kean},
doi = {10.1016/j.sigpro.2017.09.005},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168417303249-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Parametric dictionary learning,Reverberant environment,Source localization,Sparse Bayesian method},
pages = {232--240},
publisher = {Elsevier B.V.},
title = {{Acoustic source localization in strong reverberant environment by parametric Bayesian dictionary learning}},
volume = {143},
year = {2018}
}
@article{Kumar2019,
abstract = {Diffusion magnetic resonance imaging, a non-invasive tool to infer white matter fiber connections, produces a large number of streamlines containing a wealth of information on structural connectivity. The size of these tractography outputs makes further analyses complex, creating a need for methods to group streamlines into meaningful bundles. In this work, we address this problem by proposing a set of flexible and efficient streamline clustering approaches based on kernel dictionary learning and sparsity priors. Proposed approaches, which include L0 norm, group sparsity, and manifold regularization prior, allow streamlines to be assigned to more than one bundle, making the clustering more robust to overlapping bundles and inter-subject variations. We evaluate the performance of our method on an expert labeled dataset as well as data from the Human Connectome Project. Results highlight the ability of our method to group streamlines into plausible bundles and illustrate the impact of sparsity priors on the performance of the proposed methods. Methods presented in this work are relevant for the neuroscience studies on diffusion tractography analysis, as well as pattern recognition applications requiring the unsupervised clustering of 3D curves.},
archivePrefix = {arXiv},
arxivId = {1804.05427},
author = {Kumar, Kuldeep and Siddiqi, Kaleem and Desrosiers, Christian},
doi = {10.1016/j.patcog.2019.06.002},
eprint = {1804.05427},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S003132031930233X-main.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Clustering,Diffusion MRI,Human Connectome project,Kernel dictionary learning,Sparsity priors,White matter fibers},
pages = {83--95},
publisher = {Elsevier Ltd},
title = {{White matter fiber analysis using kernel dictionary learning and sparsity priors}},
url = {https://doi.org/10.1016/j.patcog.2019.06.002},
volume = {95},
year = {2019}
}
@article{Petrovic2004,
abstract = {A novel approach to multiresolution signal-level image fusion is presented for accurately transferring visual information from any number of input image signals, into a single fused image without loss of information or the introduction of distortion. The proposed system uses a "fuse-then-decompose" technique realized through a novel, fusion/decomposition system architecture. In particular, information fusion is performed on a multiresolution gradient map representation domain of image signal information. At each resolution, input images are represented as gradient maps and combined to produce new, fused gradient maps. Fused gradient map signals are processed, using gradient filters derived from high-pass quadrature mirror filters to yield a fused multiresolution pyramid representation. The fused output image is obtained by applying, on the fused pyramid, a reconstruction process that is analogous to that of conventional discrete wavelet transform. This new gradient fusion significantly reduces the amount of distortion artefacts and the loss of contrast information usually observed in fused images obtained from conventional multiresolution fusion schemes. This is because fusion in the gradient map domain significantly improves the reliability of the feature selection and information fusion processes. Fusion performance is evaluated through informal visual inspection and subjective psychometric preference tests, as well as objective fusion performance measurements. Results clearly demonstrate the superiority of this new approach when compared to conventional fusion systems.},
author = {Petrovi{\'{c}}, Valdimir S. and Xydeas, Costas S.},
doi = {10.1109/TIP.2004.823821},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Petrovic-2004-Gradient-based-multiresolution-imag.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Gradient image representation,Image fusion,Information fusion,Multiresolution image processing},
number = {2},
pages = {228--237},
pmid = {15376943},
title = {{Gradient-based multiresolution image fusion}},
volume = {13},
year = {2004}
}
@article{Zhu2018a,
abstract = {Person re-identification plays an important role in video surveillance and forensics applications. In many cases, person re-identification needs to be conducted between image and video clip, e.g., re-identifying a suspect from large quantities of pedestrian videos given a single image of the suspect. We call re-identification in this scenario as image to video person reidentification (IVPR). In practice, image and video are usually represented with different features, and there usually exist large variations between frames within each video. These factors make matching between image and video become a very challenging task. In this paper, we propose a joint feature projection matrix and heterogeneous dictionary pair learning (PHDL) approach for IVPR. Specifically, the PHDL jointly learns an intra-video projection matrix and a pair of heterogeneous image and video dictionaries. With the learned projection matrix, the influence caused by the variations within each video on the matching can be reduced. With the learned dictionary pair, the heterogeneous image and video features can be transformed into coding coefficients with the same dimension, such that the matching can be conducted by using the coding coefficients. Furthermore, to ensure that the obtained coding coefficients own favorable discriminability, the PHDL designs a point-to-set coefficient discriminant term. To make better use of the complementary spatial-temporal and visual appearance information contained in pedestrian video data, we further propose a multi-view PHDL approach, which can fuse different video information effectively in the dictionary learning process. Experiments on four publicly available person sequence data sets demonstrate the effectiveness of the proposed approaches.},
author = {Zhu, Xiaoke and Jing, Xiao Yuan and You, Xinge and Zuo, Wangmeng and Shan, Shiguang and Zheng, Wei Shi},
doi = {10.1109/TIFS.2017.2765524},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08078250.pdf:pdf},
issn = {15566013},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {Feature projection matrix,Heterogeneous dictionary pair learning,Image to video person re-identification,Multi-view learning.,Person re-identification},
number = {3},
pages = {717--732},
publisher = {IEEE},
title = {{Image to video person re-identification by learning heterogeneous dictionary pair with feature projection matrix}},
volume = {13},
year = {2018}
}
@article{Ding2018a,
abstract = {Zero-shot learning for visual recognition, which approaches recognizing unseen categories through a shared visual-semantic function learned on the seen categories and is expected to well adapt to unseen categories, has received considerable research attention in the most recent years. Here, we propose a two-stage generative adversarial networks to enhance the generalizability of semantic dictionary through low-rank embedding for zero-shot learning in this paper. Specifically, we formulate a novel framework to jointly seek a two-stage generative model and a semantic dictionary to link visual features with their semantic representations under low-rank embedding, which manages to capture shared features across different observed classes. Our first-stage generative model is able to synthesize more semantic features for the unseen classes, which are then used to generate more discriminant visual features in the second stage, to expand the seen visual feature space. Therefore, we will be able to seek a better semantic dictionary to constitute the latent basis for the unseen classes based on the augmented semantic and visual data. Finally, our model could extract a variety of visual characteristics from seen categories that are "ready-to-use" for unknown categories. Extensive experiments on four zero-shot benchmarks demonstrate that the proposed algorithm outperforms the state-of-the-art approaches},
author = {Ding, Zhengming and Shao, Ming and Fu, Yun},
doi = {10.1109/TPAMI.2018.2867870},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08451907.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Data models,Dictionaries,Gallium nitride,Generative Adversarial Network,Generative adversarial networks,Low-Rank Embedding,Semantic Dictionary,Semantics,Training,Visualization,Zero-Shot Learning},
number = {c},
pages = {1},
publisher = {IEEE},
title = {{Generative Zero-Shot Learning via Low-Rank Embedded Semantic Dictionary}},
volume = {PP},
year = {2018}
}
@article{Liu2019,
abstract = {With rapid development of digital imaging and communication technologies, image set based face recognition (ISFR) is becoming increasingly important and popular. On one hand, easy capture of large number of samples for each subject in training and testing makes us have more information for possible utilization. On the other hand, this large size of data will eventually increase training and classification time and possibly reduce the recognition rate if they are not used appropriately. In this paper, a new face recognition approach is proposed based on the K-SVD dictionary learning to solve this large sample problem by using joint sparse representation. The core idea of this proposed approach is to learn variation dictionaries from gallery and probe face images separately, and then we propose an improved joint sparse representation, which employs the information learned from both gallery and probe samples effectively. Finally, the proposed method is compared with some related methods on several popular face databases, including YaleB, AR, CMU-PIE, Georgia and LFW databases. The experimental results show that the proposed method outperforms several related face recognition methods.},
author = {Liu, Jingjing and Liu, Wanquan and Ma, Shiwei and Wang, Meixi and Li, Ling and Chen, Guanghua},
doi = {10.1007/s13042-017-0782-5},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Image‑set based face recognition using K‑SVD dictionary learning.pdf:pdf},
isbn = {0123456789},
issn = {1868808X},
journal = {International Journal of Machine Learning and Cybernetics},
keywords = {Face recognition,Image set,Improved joint sparse representation,K-SVD dictionary learning},
number = {5},
pages = {1051--1064},
publisher = {Springer Berlin Heidelberg},
title = {{Image-set based face recognition using K-SVD dictionary learning}},
url = {http://dx.doi.org/10.1007/s13042-017-0782-5},
volume = {10},
year = {2019}
}
@article{Jiang2018,
abstract = {In this paper, a single-computed tomography (CT) image super-resolution (SR) reconstruction scheme is proposed. This SR reconstruction scheme is based on sparse representation theory and dictionary learning of low- and high-resolution image patch pairs to improve the poor quality of low-resolution CT images obtained in clinical practice using low-dose CT technology. The proposed strategy is based on the idea that image patches can be well represented by sparse coding of elements from an overcomplete dictionary. To obtain similarity of the sparse representations, two dictionaries of low- and high-resolution image patches are jointly trained. Then, sparse representation coefficients extracted from the low-resolution input patches are used to reconstruct the high-resolution output. Sparse representation is used such that the trained dictionary pair can reduce computational costs. Combined with several appropriate iteration operations, the reconstructed high-resolution image can attain better image quality. The effectiveness of the proposed method is demonstrated using both clinical CT data and simulation image data. Image quality evaluation indexes (root mean squared error (RMSE) and peak signal-to-noise ratio (PSNR)) indicate that the proposed method can effectively improve the resolution of a single CT image.},
author = {Jiang, Changhui and Zhang, Qiyang and Fan, Rui and Hu, Zhanli},
doi = {10.1038/s41598-018-27261-z},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/s41598-018-27261-z.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--10},
publisher = {Springer US},
title = {{Super-resolution CT Image Reconstruction Based on Dictionary Learning and Sparse Representation}},
url = {http://dx.doi.org/10.1038/s41598-018-27261-z},
volume = {8},
year = {2018}
}
@article{Dong2018,
abstract = {This paper proposes a new framework of dictionary learning for a recently developed study, sparse representation of monogenic signal. The proposed framework is applied to target recognition in SAR image. Unlike the preceding works, where the sparse model is formed via an overcomplete dictionary whose atoms are the training samples themselves, a new approach to learn a more discriminative dictionary is proposed. To achieve target classification, two specific implementation schemes, global learning, and local learning, are developed. The global learning generates a single, universal dictionary for all target class. Since the class membership committed to each atom (element) is lost, the reconstruction error committed to each class is incapable to be computed. The conventional decision rule by the minimal residual could not be applied any more. Hence, this paper develops two decision rules for global learning. The first resorts to a third-party classifier, while the other recommends a nonparametric criterion. Different from the global learning, the local learning learns a subdictionary for each target class. These subdictionaries are concatenated to form a global one. Each subdictionary has been learned within certain target class, the generated atoms can be therefore labeled. The identification is predicted by evaluating which class of atom could produce the minimal reconstruction error. The effectiveness of proposed scheme is verified with multiple comparative studies.},
author = {Dong, Ganggang and Wang, Na and Kuang, Gangyao and Qiu, Hongbing},
doi = {10.1109/JSTARS.2017.2754553},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08058440.pdf:pdf},
issn = {21511535},
journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
keywords = {Dictionary learning,SAR,low rank,sparse representation,target recognition},
number = {1},
pages = {141--153},
publisher = {IEEE},
title = {{Sparsity and low-rank dictionary learning for sparse representation of monogenic signal}},
volume = {11},
year = {2018}
}
@article{Wright2009,
author = {Wright, John and Ganesh, Arvind and Yang, Allen and Zhou, Zihan and Ma, Yi},
doi = {10.1109/TPAMI.2008.79},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Robust Face Recognitionvia Sparse Representation.pdf:pdf},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {2},
pages = {210 -- 227},
title = {{Sparsity and Robustness in Face Recognition A tutorial on how to apply the models and tools correctly Linear Models for Face Recognition with Varying Illumi- nation}},
volume = {31},
year = {2009}
}
@article{Zhang2018,
abstract = {As a result of several successful applications in computer vision and image processing, sparse representation (SR) has attracted significant attention in multi-sensor image fusion. Unlike the traditional multiscale transforms (MSTs) that presume the basis functions, SR learns an over-complete dictionary from a set of training images for image fusion, and it achieves more stable and meaningful representations of the source images. By doing so, the SR-based fusion methods generally outperform the traditional MST image fusion methods in both subjective and objective tests. In addition, they are less susceptible to mis-registration among the source images, thus facilitating the practical applications. This survey paper proposes a systematic review of the SR-based multi-sensor image fusion literature, highlighting the pros and cons of each category of approaches. Specifically, we start by performing a theoretical investigation of the entire system from three key algorithmic aspects, (1) sparse representation models; (2) dictionary learning methods; and (3) activity levels and fusion rules. Subsequently, we show how the existing works address these scientific problems and design the appropriate fusion rules for each application such as multi-focus image fusion and multi-modality (e.g., infrared and visible) image fusion. At last, we carry out some experiments to evaluate the impact of these three algorithmic components on the fusion performance when dealing with different applications. This article is expected to serve as a tutorial and source of reference for researchers preparing to enter the field or who desire to employ the sparse representation theory in other fields.},
author = {Zhang, Qiang and Liu, Yi and Blum, Rick S. and Han, Jungong and Tao, Dacheng},
doi = {10.1016/j.inffus.2017.05.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Sparserepresentationbasedmulti-sensorimagefusion.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Activity level,Dictionary learning,Image fusion,Sparse representation},
pages = {57--75},
publisher = {Elsevier B.V.},
title = {{Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review}},
url = {http://dx.doi.org/10.1016/j.inffus.2017.05.006},
volume = {40},
year = {2018}
}
@article{Kanoga2019a,
abstract = {The authors regret writing a request letter asking for a corrigendum of published paper titled “Multi-scale dictionary learning for ocular artifact reduction from single-channel electroencephalograms”. This paper is having an unnecessary figure on the 10th page (p.249), which has no caption.},
author = {Kanoga, Suguru and Kanemura, Atsunori and Asoh, Hideki},
doi = {10.1016/j.neucom.2019.06.036},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Kanoga-2019-Corrigendum-to-multi-scale-dictiona.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
number = {June},
pages = {2312},
publisher = {Elsevier B.V.},
title = {{Corrigendum to “Multi-scale dictionary learning for ocular artifact reduction from single-channel electroencephalograms” (Neurocomputing (2019) 347 (240–250), (S0925231219305260), (10.1016/j.neucom.2019.02.060))}},
volume = {359},
year = {2019}
}
@article{Liu2019d,
abstract = {This study aims to explore types of motivation for smartphone dictionary use among Chinese university EFL learners. It is a mixed-method inquiry carried out under the frameworks of the Function Theory of Lexicography (Tarp 2007) and the Strategy Inventory for Dictionary Use (Gavriilidou 2013). Twenty-two semi-structured interviews were conducted, followed by a confirmatory survey (N=577). The interview data revealed ten themes of user strategies and purposes. Using a latent class analytical tool, Mplus, we identified from the survey a model with three user classes: Customisation (33.3{\%}), Learning (51.9{\%}) and Utility (14.8{\%}). They respectively imply individuating use of dictionary features and automatic messaging, authentic English language learning, and utilitarian purposes like passing exams. In addition, three variables were used for predicting class membership, namely gender (male and female), English proficiency (high and low), and university type (key and non-key). Multinomial logistic regressions showed motivation tendencies among these demographic groups: male users or non-key university students were more likely to fall into the Customisation class; high-proficiency learners or key university students, Learning; and female users or low-proficiency learners, Utility. In sum, this research has furthered our understanding of motivation for second language learning through mobile technology applications. It has theoretical, methodological and practical implications for future studies, offering fresh insights into e-dictionary customisation and education in e-dictionary use.},
author = {Liu, Xiqin and Zheng, Dongping and Chen, Yushuai},
doi = {10.1093/ijl/ecy019},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/ecy019.pdf:pdf},
issn = {14774577},
journal = {International Journal of Lexicography},
keywords = {Chinese EFL learner,customisation,latent class,mobile assisted language learning,motivation,smartphone dictionary use},
number = {1},
pages = {68--91},
title = {{Latent Classes of Smartphone Dictionary Users among Chinese EFL Learners: A Mixed-Method Inquiry into Motivation for Mobile Assisted Language Learning}},
volume = {32},
year = {2019}
}
@article{Yuan2018,
abstract = {Abnormal event detection is now a widely concerned research topic, especially for crowded scenes. In recent years, many dictionary learning algorithms have been developed to learn normal event regularities, and have presented promising performance for abnormal event detection. However, they seldom consider the structural information, which plays important roles in many computer vision tasks, such as image denoising and segmentation. In this paper, structural information is explored within a sparse representation framework. On the one hand, we introduce a new concept named reference event, which indicates the potential event patterns in normal video events. Compared with abnormal events, normal ones are more likely to approximate these reference events. On the other hand, a smoothness regularization is constructed to describe the relationships among video events. The relationships consist of both similarities in the feature space and relative positions in the video sequences. In this case, video events related to each other are more likely to possess similar representations. The structured dictionary and sparse representation coefficients are optimized through an iterative updating strategy. In the testing phase, abnormal events are identified as samples which cannot be well represented using the learned dictionary. Extensive experiments and comparisons with state-of-the-art algorithms have been conducted to prove the effectiveness of the proposed algorithm.},
author = {Yuan, Yuan and Feng, Yachuang and Lu, Xiaoqiang},
doi = {10.1016/j.patcog.2017.08.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0031320317303047-main.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Abnormal event detection,Dictionary learning,Reference event,Sparse representation,Video surveillance},
pages = {99--110},
publisher = {Elsevier Ltd},
title = {{Structured dictionary learning for abnormal event detection in crowded scenes}},
url = {http://dx.doi.org/10.1016/j.patcog.2017.08.001},
volume = {73},
year = {2018}
}
@article{Takashima2019,
author = {Takashima, Yuki and Nakashika, Toru and Takiguchi, Tetsuya and Ariki, Yasuo},
doi = {10.1186/s13636-019-0160-1},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/document.pdf:pdf},
issn = {1687-4722},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
keywords = {non-negative matrix factorization,non-negative tucker decomposition,non-parallel,voice conversion},
number = {1},
pages = {1--11},
publisher = {EURASIP Journal on Audio, Speech, and Music Processing},
title = {{Non-parallel dictionary learning for voice conversion using non-negative Tucker decomposition}},
volume = {2019},
year = {2019}
}
@article{Xiang2018,
abstract = {Classifier training plays an important role in image classification, while a good classifier could more effectively exploit the discriminative information of input features to separate the difficult samples. Inspired by the recent advance of representation based classifiers and the success of multi-layer architectures in visual recognition, we propose a multi-layer dictionary pair learning based classifier to enhance the image classification performance. With the multi-layer structure and a nonlinear feature transform in each layer, the proposed classifier learning model could accumulate stronger discrimination capability than the previous single-layer representation based classifiers. Furthermore, to make our learning model applicable to datasets with a larger amount of samples, we propose an online training algorithm which updates model parameters with data batches. The so-called online multi-layer dictionary pair learning (OMDPL) method is evaluated on benchmark image classification datasets. With the same input features, OMDPL exhibits better classification performance than other popular classifiers.},
author = {Xiang, Yu and Zhang, Guoqiang and Gu, Shuhang and Cai, Jianrui},
doi = {10.1016/j.eswa.2018.03.048},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0957417418302069-main.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Dictionary pair learning,Image classification,Multi-layer learning,Online training},
pages = {174--182},
publisher = {Elsevier Ltd},
title = {{Online multi-layer dictionary pair learning for visual classification}},
url = {https://doi.org/10.1016/j.eswa.2018.03.048},
volume = {105},
year = {2018}
}
@article{Zhu2018,
abstract = {Video-based person re-identification (re-id) has attracted a lot of research interest. When facing dramatic growth in new pedestrian videos, existing video-based person re-id methods usually need large quantities of labeled pedestrian videos to train a discriminative model. In practice, labeling large quantities of pedestrian videos is a costly and time-consuming task, which will limit the application of these methods in the real environment. Therefore, it is valuable and necessary to investigate how to learn a discriminative re-id model by using limited labeled training pedestrian videos. In this paper, we propose a semi-supervised cross-view projection-based dictionary learning (SCPDL) approach for video-based person re-id. Specifically, SCPDL jointly learns a pair of feature projection matrices and a pair of dictionaries by integrating the information contained in labeled and unlabeled pedestrian videos. With the learned feature projection matrices, the influence of variations within each video to the re-id can be reduced. With the learned dictionary pair, pedestrian videos from two different cameras can be converted into coding coefficients in a common representation space, such that the differences between different cameras can be bridged. In the learning process, the labeled pedestrian videos are used to ensure that the learned dictionaries have favorable discriminability; the large quantities of unlabeled pedestrian videos are used to ensure that SCPDL can better capture the variations between pedestrian videos, such that the learned dictionaries can own stronger representative capability. Experiments on two public pedestrian sequence data sets (iLIDS-VID and PRID 2011) demonstrate the effectiveness of the proposed approach.},
author = {Zhu, Xiaoke and Jing, Xiao Yuan and Yang, Liang and You, Xinge and Chen, Dan and Gao, Guangwei and Wang, Yunhong},
doi = {10.1109/TCSVT.2017.2718036},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/07954687.pdf:pdf},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Video-based person re-identification,cross-view learning,dictionary learning,semi-supervised learning},
number = {10},
pages = {2599--2611},
publisher = {IEEE},
title = {{Semi-Supervised Cross-View Projection-Based Dictionary Learning for Video-Based Person Re-Identification}},
volume = {28},
year = {2018}
}
@article{Liu2018b,
abstract = {Infrared (IR) spectra are the fingerprints of the molecules, and the spectral band location closely relates to the structure of a molecule. Thus, specimen identification can be performed based on IR spectroscopy. However, spectrally overlapping components prevent the specific identification of hyperfine molecular information of different substances. In this paper, we propose a fast blind reconstruction approach for IR spectra, which is based on sparse and redundant representations over a dictionary. The proposed method recovers the spectrum with the discrete wavelet transform dictionary on its content. The experimental results demonstrate that the proposed method is superior because of the better performance when compared with other state-of-the-art methods. The method the authors used remove the instrument aging issue to a large extent, thus leading the reconstruction IR spectra a more convenient tool for extracting features of an unknown material and interpreting it.},
author = {Liu, Tingting and Liu, Hai and Chen, Zengzhao and Chen, Yingying and Wang, Shengming and Liu, Zhi and Zhang, Hao},
doi = {10.1016/j.infrared.2018.02.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1350449517308162-main.pdf:pdf},
issn = {13504495},
journal = {Infrared Physics and Technology},
keywords = {Infrared microscopy spectra,Instrument response function,Regularization,Sparse representation},
pages = {101--109},
publisher = {Elsevier B.V.},
title = {{FBRDLR: Fast blind reconstruction approach with dictionary learning regularization for infrared microscopy spectra}},
url = {https://doi.org/10.1016/j.infrared.2018.02.006},
volume = {90},
year = {2018}
}
@article{Xu2019,
abstract = {With the continuous development and progress of the healthcare monitoring system, medical diagnosis for human health plays a, particularly, critical role, which can help doctors make correct choices and effective treatment plans. However, effective feature extraction is very important for the analysis of functional magnetic resonance imaging data; the traditional feature-based dictionary learning algorithm ignores the relationship between atoms and the input samples, and the small sample data is prone to over-fitting. In this paper, we propose a new weighting mechanism, which effectively considers the relationship between the atom and the input sample; meanwhile, the cross-validation method performed well on obtaining additional validation sets but proved to be over-fitting on small datasets in the traditional dictionary learning algorithm. Therefore, mathrm {\{}ell 2{\}}-norm and mathfrak{\{}F{\}}-norm regularization constraint is adopted to avoid over-fitting, achieve the limitations of the model space, and improve the generalization ability of the model. In order to extract features better, this paper uses the cosine similarity method to select good feature subsets, which effectively improves further the generalization ability and enhances the feature extraction accuracy. The results show that the improved dictionary classification algorithm has better performance in terms of accuracy, sensitivity, and specificity, and it also demonstrates that the proposed algorithm has an effective classification about mobile multimedia medical diseases, which can provide a better guidance for the diagnosis of later diseases, so as to promote the rapid development of medical feature extraction.},
author = {Xu, Yuting and Yang, Haima and Jun, J. and Liu, J. and Xiong, Naixue},
doi = {10.1109/ACCESS.2018.2889327},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-An Effective Dictionary Learning Algorithm Based on fMRI Data for Mobile Medical Disease Analysis.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Healthcare monitoring,classification,dictionary learning,feature extraction,mobile multimedia,regularization},
pages = {3958--3966},
publisher = {IEEE},
title = {{An Effective Dictionary Learning Algorithm Based on fMRI Data for Mobile Medical Disease Analysis}},
volume = {7},
year = {2019}
}
@article{Wang2018d,
abstract = {Robust and effective shape prior modeling from a set of training data remains a challenging task, since the shape variation is complicated, and shape models should preserve local details as well as handle shape noises. To address these challenges, a novel robust projective dictionary learning (RPDL) scheme is proposed in this paper. Specifically, the RPDL method integrates the dimension reduction and dictionary learning into a unified framework for shape prior modeling, which can not only learn a robust and representative dictionary with the energy preservation of the training data, but also reduce the dimensionality and computational cost via the subspace learning. In addition, the proposed RPDL algorithm is regularized by using the $\backslash$ell -{\{}1{\}} norm to handle the outliers and noises, and is embedded in an online framework so that of memory and time efficiency. The proposed method is employed to model prostate shape prior for the application of magnetic resonance transrectal ultrasound registration. The experimental results demonstrate that our method provides more accurate and robust shape modeling than the state-of-the-art methods do. The proposed RPDL method is applicable for modeling other organs, and hence, a general solution for the problem of shape prior modeling.},
author = {Wang, Yi and Zheng, Qingqing and Heng, Pheng Ann},
doi = {10.1109/TMI.2017.2777870},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08119989.pdf:pdf},
isbn = {2015052509294},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Dictionary learning,MR-TRUS registration,dimension reduction,online,prostate segmentation,shape modelling},
number = {4},
pages = {1067--1078},
publisher = {IEEE},
title = {{Online Robust Projective Dictionary Learning: Shape Modeling for MR-TRUS Registration}},
volume = {37},
year = {2018}
}
@article{Liu2019a,
abstract = {Dictionary learning (DL) has been successfully applied to blind hyperspectral unmixing due to the similarity of underlying mathematical models. Both of them are linear mixture models and quite often sparsity and nonnegativity are incorporated. However, the mainstream sparse DL algorithms are crippled by the difficulty in prespecifying suitable sparsity. To solve this problem, this paper proposes an efficient algorithm to find all paths of the ℓ1-regularization problem and select the best set of variables for the final abundances estimation. Based on the proposed algorithm, a DL framework is designed for hyperspectral unmixing. Our experimental results indicate that our method performs much better than conventional methods in terms of DL and hyperspectral data reconstruction. More importantly, it alleviates the difficulty of prescribing the sparsity.},
author = {Liu, Yang and Guo, Yi and Li, Feng and Xin, Lei and Huang, Puming},
doi = {10.1109/LGRS.2018.2878036},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-sparse dictionary learning for blind.pdf:pdf},
issn = {1545598X},
journal = {IEEE Geoscience and Remote Sensing Letters},
keywords = {Dictionary learning (DL),hyperspectral unmixing,path algorithm,sparse coding,ℓ1 -regularization},
number = {4},
pages = {578--582},
publisher = {IEEE},
title = {{Sparse Dictionary Learning for Blind Hyperspectral Unmixing}},
volume = {16},
year = {2019}
}
@article{Sun2018b,
abstract = {Deep subspace learning (DSL) models based on the principal component analysis network (PCANet) and linear discriminant analysis network (LDANet) have shown to be promising alternatives to deep learning models when there are computing power and training data constraints. However, high dimensionality of the feature space remains a major issue for DSL models. This paper presents a novel DSL approach based on an extended dictionary representation with deep subspace features for facial expression recognition. First, we propose the use of feature pooling with DSL by adding rank-based average pooling between each subspace mapping layer. We then use spatial pyramid pooling in the output layer to overcome the high-dimensionality problem. After that, the extended dictionary is formed by expanding the feature dictionary. Finally, we apply sparse representation classification with squared ℓ2-regularization to improve the recognition accuracy. Comprehensive experiments based on several well-established datasets confirm that our proposed approach has superior performance compared to both the baseline as well as state-of-the-art PCANet and LDANet methods, not just in terms of accuracy but also robustness against block occlusion and random corruption.},
author = {Sun, Zhe and Chiong, Raymond and ping Hu, Zheng},
doi = {10.1016/j.neucom.2018.07.045},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231218308804-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Extended dictionary representation,Facial expression recognition,Feature pooling with deep subspace learning,LDANet,PCANet},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{An extended dictionary representation approach with deep subspace learning for facial expression recognition}},
url = {https://doi.org/10.1016/j.neucom.2018.07.045},
volume = {316},
year = {2018}
}
@article{Chang2018,
abstract = {Computer-mediated dictionaries have been important and widely used aids in the comprehension of, and learning from online texts. However, despite the convenience of computer-mediated dictionaries in retrieving word meaning, its use may reduce the time that readers spend reading each word and negatively affect word retention. In addition, readers' vocabulary size is a key factor influencing the lookup process, and its effectiveness. Therefore, in this study, we propose a new ‘checking-meaning' function to optimize word retention and to explain readers' cognitive resources allocation in computer-mediated dictionary assisted learning. We conducted a 2 (checking meaning function: with vs. without) × 2 (vocabulary size: large vs. small) between-subjects design to explore the effectiveness of vocabulary acquisition and reading comprehension performance in computer-mediated dictionary-assisted reading. In line with the hypotheses, results revealed that the computer-mediated dictionary with checking-meaning function enhanced small vocabulary size learners' vocabulary acquisition, but negatively influenced large vocabulary size learners' reading comprehension performance. Based on these results, we propose the competition-cooperation relationship to explain readers' cognitive resources allocation in computer-mediated dictionary assisted learning.},
author = {Chang, You Hsuan and Liu, Tzu Chien and Paas, Fred},
doi = {10.1016/j.compedu.2018.08.013},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0360131518302173-main.pdf:pdf},
issn = {03601315},
journal = {Computers and Education},
keywords = {Evaluation of CAL systems,Human-computer interface,Media in education},
number = {August},
pages = {113--129},
publisher = {Elsevier},
title = {{Cognitive resources allocation in computer-mediated dictionary assisted learning: From word meaning to inferential comprehension}},
url = {https://doi.org/10.1016/j.compedu.2018.08.013},
volume = {127},
year = {2018}
}
@article{Nannuru2019,
abstract = {Sparse Bayesian learning (SBL) has emerged as a fast and competitive method to perform sparse processing. The SBL algorithm, which is developed using a Bayesian framework, iteratively solves a non-convex optimization problem using fixed point updates. It provides comparable performance and is significantly faster than convex optimization techniques used in sparse processing. We propose a multi-dictionary SBL algorithm that simultaneously can process observations generated by different underlying dictionaries sharing the same sparsity profile. Two algorithms are proposed and corresponding fixed point update equations are derived. Noise variances are estimated using stochastic maximum likelihood. The multi-dictionary SBL has many practical applications. We demonstrate this using direction-of-arrival (DOA) estimation. The first example uses the proposed multi-dictionary SBL to process multi-frequency observations. We show how spatial aliasing can be avoided while processing multi-frequency observations using SBL. SWellEx-96 experimental data demonstrates qualitatively these advantages. In the second example we show how data corrupted with heteroscedastic noise can be processed using multi-dictionary SBL with data pre-whitening.},
author = {Nannuru, Santosh and Gemba, Kay L. and Gerstoft, Peter and Hodgkiss, William S. and Mecklenbr{\"{a}}uker, Christoph F.},
doi = {10.1016/j.sigpro.2019.02.003},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-2-Nannuru-2019-Sparse-bayesian-learning-with-multi.pdf:pdf},
isbn = {9781509059904},
issn = {01651684},
journal = {Signal Processing},
keywords = {Aliasing,Beamforming,Compressive sensing,DOA estimation,Heteroscedastic noise,Multi frequency,Multiple dictionaries,Sparse Bayesian learning,Wide band},
pages = {159--170},
publisher = {Elsevier B.V.},
title = {{Sparse Bayesian learning with multiple dictionaries}},
url = {https://doi.org/10.1016/j.sigpro.2019.02.003},
volume = {159},
year = {2019}
}
@article{Li2018c,
abstract = {Medical image fusion is important in image-guided medical diagnostics, treatment, and other computer vision tasks. However, most current approaches assume that the source images are noise-free, which is not usually the case in practice. The performance of traditional fusion methods decreases significantly when images are corrupted with noise. It is therefore necessary to develop a fusion method that accurately preserves detailed information even when images are corrupted. However, suppressing noise and enhancing textural details are difficult to achieve simultaneously. In this paper, we develop a novel medical image fusion, denoising, and enhancement method based on low-rank sparse component decomposition and dictionary learning. Specifically, to improve the discriminative ability of the learned dictionaries, we incorporate low-rank and sparse regularization terms into the dictionary learning model. Furthermore, in the image decomposition model, we impose a weighted nuclear norm and sparse constraint on the sparse component to remove noise and preserve textural details. Finally, the fused result is constructed by combining the fused low-rank and sparse components of the source images. Experimental results demonstrate that the proposed method consistently outperforms existing state-of-the-art methods in terms of both visual and quantitative evaluations.},
author = {Li, Huafeng and He, Xiaoge and Tao, Dapeng and Tang, Yuanyan and Wang, Ruxin},
doi = {10.1016/j.patcog.2018.02.005},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Li-2018-Joint-medical-image-fusion-denoisin.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Denoising,Dictionary learning,Low-rank decomposition,Medical image fusion,Sparse representation},
pages = {130--146},
publisher = {Elsevier Ltd},
title = {{Joint medical image fusion, denoising and enhancement via discriminative low-rank sparse dictionaries learning}},
url = {https://doi.org/10.1016/j.patcog.2018.02.005},
volume = {79},
year = {2018}
}
@article{Sun2018a,
abstract = {In this paper, we propose an efficient 2-D direction-of-arrival (DOA) estimation method for co-prime parallel arrays. By using the second-order statistics of the received signals with different time lags, a conjugate augmented spatial-temporal virtual array is constructed to extend the array aperture and enhance the degrees-of-freedom (DOFs). Vectorizing the cross covariance matrix of the virtual array, the 2-D DOA estimation can be cast as a 1-D sparsity-based recovery problem. A dictionary learning technique is then proposed to compensate the off-grid bias caused by discretization. Simulation results show the effectiveness of the proposed method as compared with the state-of-the-art methods.},
author = {Sun, Fenggang and Lan, Peng and Gao, Bin and Zhang, Guowei},
doi = {10.1109/ACCESS.2018.2805168},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08289429.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {DOA estiamtion,automatic pair matching,co-prime parallel arrays,dictionary learning,spatial-temporal processing},
pages = {8510--8518},
publisher = {IEEE},
title = {{An Efficient Dictionary Learning-Based 2-D DOA Estimation Without Pair Matching for Co-Prime Parallel Arrays}},
volume = {6},
year = {2018}
}
@article{Hu2019a,
abstract = {Ghost imaging (GI) is a novel imaging technique based on the second-order correlation of light fields. Due to limited number of samplings in practice, traditional GI methods often reconstructs objects with unsatisfactory quality. Although some reconstruction methods have been developed to improve the imaging results, the reconstruction quality of GI may be fundamentally restricted by the modulated light fields. In this paper, we propose to improve the imaging quality of GI by optimizing the light fields, which is realized via matrix optimization for a learned dictionary incorporating the sparsity prior of objects. A closed-form solution of the sampling matrix, which enables successive sampling, has been derived. We demonstrate by simulation and experimental results that the proposed scheme has better imaging quality compared to the state-of-the-art GI methods, especially at a low sampling rate.},
archivePrefix = {arXiv},
arxivId = {1906.03050},
author = {Hu, Chenyu and Tong, Zhishen and Liu, Zhentao and Huang, Zengfeng and Wang, Jian and Han, Shensheng},
doi = {10.1364/oe.27.028734},
eprint = {1906.03050},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/oe-27-20-28734.pdf:pdf},
issn = {10944087},
journal = {Optics Express},
number = {20},
pages = {28734},
title = {{Optimization of light fields in ghost imaging using dictionary learning}},
volume = {27},
year = {2019}
}
@misc{Ebara2003,
author = {Ebara, Masaaki and Fukuda, Hiroyuki and Saisho, Hiromitsu},
booktitle = {Journal of Gastroenterology},
doi = {10.1007/s005350300016},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/applsci-08-00903.pdf:pdf},
issn = {09441174},
number = {1},
pages = {104--105},
title = {{The copper/zinc ratio in patients with hepatocellular carcinoma}},
volume = {38},
year = {2003}
}
@article{Abolghasemi2018,
abstract = {We enhance the efficacy of an existing dictionary pair learning algorithm by adding a dictionary incoherence penalty term. After presenting an alternating minimization solution, we apply the proposed incoherent dictionary pair learning (InDPL) method in classification of a novel open-source database of Chinese numbers. Benchmarking results confirm that the InDPL algorithm offers enhanced classification accuracy, especially when the number of training samples is limited.},
author = {Abolghasemi, Vahid and Chen, Mingyang and Alameer, Ali and Ferdowsi, Saideh and Chambers, Jonathon and Nazarpour, Kianoush},
doi = {10.1109/LSP.2018.2798406},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08269282.pdf:pdf},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
keywords = {Chinese numbers,classification,incoherent dictionary pair learning},
number = {4},
pages = {472--476},
publisher = {IEEE},
title = {{Incoherent dictionary pair learning: Application to a novel open-source database of Chinese numbers}},
volume = {25},
year = {2018}
}
@article{Liu2018c,
abstract = {Infrared images always suffer from low-resolution problems resulting from limitations of imaging devices. An economical approach to combat this problem involves reconstructing high-resolution images by reasonable methods without updating devices. Inspired by compressed sensing theory, this study presents and demonstrates a Classified Dictionary Learning method to reconstruct high-resolution infrared images. It classifies features of the samples into several reasonable clusters and trained a dictionary pair for each cluster. The optimal pair of dictionaries is chosen for each image reconstruction and therefore, more satisfactory results is achieved without the increase in computational complexity and time cost. Experiments and results demonstrated that it is a viable method for infrared images reconstruction since it improves image resolution and recovers detailed information of targets.},
author = {Liu, Fei and Han, Pingli and Wang, Yi and Li, Xuan and Bai, Lu and Shao, Xiaopeng},
doi = {10.1016/j.infrared.2018.03.008},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1350449517308575-main.pdf:pdf},
issn = {13504495},
journal = {Infrared Physics and Technology},
keywords = {Classified dictionaries,Dictionary learning,Infrared imaging,Super-resolution},
pages = {146--155},
publisher = {Elsevier B.V.},
title = {{Super resolution reconstruction of infrared images based on classified dictionary learning}},
url = {https://doi.org/10.1016/j.infrared.2018.03.008},
volume = {90},
year = {2018}
}
@article{Iqbal2018a,
abstract = {Analysis of functional magnetic resonance imaging (fMRI) data from multiple subjects is at the heart of many medical imaging studies, and recently, the approaches based on dictionary learning (DL) are noted as promising solutions to the problem. However, the DL-based methods for fMRI analysis proposed to date do not naturally extend to multi-subject analysis. In this paper, we propose a DL algorithm for multi-subject fMRI data analysis which is derived using a hybrid (temporal and spatial) concatenation scheme. It differs from existing DL methods in both its sparse coding and dictionary update stages. It has the advantage of learning a dictionary common to all subjects as well as a set of subject-specific dictionaries, as a result, it is able to generate both group-level spatial activation maps as well as group-level temporal dynamics, which are particularly attractive for task-based fMRI studies. In addition, by simultaneously learning multiple sub-specific dictionaries, it also provides us with unique sub-specific features as well. Performance of the proposed DL method is illustrated using simulated and real fMRI datasets. The results show that it can successfully extract common as well as sub-specific latent components.},
author = {Iqbal, Asif and Seghouane, Abd Krim},
doi = {10.1016/j.dsp.2018.09.007},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1051200418307632-main.pdf:pdf},
issn = {10512004},
journal = {Digital Signal Processing: A Review Journal},
keywords = {Dictionary learning,Functional magnetic resonance imaging (fMRI),Multi-subject analysis,Sparse decomposition},
pages = {249--260},
publisher = {Elsevier Inc.},
title = {{A dictionary learning algorithm for multi-subject fMRI analysis based on a hybrid concatenation scheme}},
url = {https://doi.org/10.1016/j.dsp.2018.09.007},
volume = {83},
year = {2018}
}
@article{De2018,
abstract = {The ambient assisted living (AAL) technology aims to provide more safety and self-sufficiency, while permitting older persons to live self-dependently in their homes. Monitoring of activities of daily living (ADL) is one of the key ideas of AAL. This becomes an interesting research idea in modern world, where condition monitoring of various ADLs and their automatic classification is a big challenge. This paper proposes a new approach for activity recognition of motion primitives relying on the sparse representation of signals, where signals are represented using a sparse combination of atoms from an over-complete dictionary. This paper intends to investigate the suitability of applying dictionary learning algorithms like K-singular value decomposition (K-SVD), which is usually used to construct an over-complete dictionary, for the effective progress of the ADL monitoring system. This paper proposes to formulate the classification approach by using SRC classifiers, based on the dictionaries learned using K-SVD algorithm. We have validated our proposed approach on a publicly available ADL data set of wrist-worn accelerometer sensor for activity recognition. Performance evaluations demonstrate that the proposed method outperforms several other competing methods.},
author = {De, Pubali and Chatterjee, Amitava and Rakshit, Anjan},
doi = {10.1109/JSEN.2017.2787616},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08240683.pdf:pdf},
issn = {1530437X},
journal = {IEEE Sensors Journal},
keywords = {ADL problem,K-singular value decomposition,data clustering,dictionary learning,sparse representation classifier},
number = {6},
pages = {2434--2441},
publisher = {IEEE},
title = {{Recognition of Human Behavior for Assisted Living Using Dictionary Learning Approach}},
volume = {18},
year = {2018}
}
@article{Li2017,
abstract = {Pixel-level image fusion is designed to combine multiple input images into a fused image, which is expected to be more informative for human or machine perception as compared to any of the input images. Due to this advantage, pixel-level image fusion has shown notable achievements in remote sensing, medical imaging, and night vision applications. In this paper, we first provide a comprehensive survey of the state of the art pixel-level image fusion methods. Then, the existing fusion quality measures are summarized. Next, four major applications, i.e.; remote sensing, medical diagnosis, surveillance, photography, and challenges in pixel-level image fusion applications are analyzed. At last, this review concludes that although various image fusion methods have been proposed, there still exist several future directions in different image fusion applications. Therefore, the researches in the image fusion field are still expected to significantly grow in the coming years.},
author = {Li, Shutao and Kang, Xudong and Fang, Leyuan and Hu, Jianwen and Yin, Haitao},
doi = {10.1016/j.inffus.2016.05.004},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Li-2017-Pixel-level-image-fusion-a-survey-o.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Image fusion,Medical imaging,Multiscale decomposition,Remote sensing,Sparse representation},
pages = {100--112},
publisher = {Elsevier B.V.},
title = {{Pixel-level image fusion: A survey of the state of the art}},
url = {http://dx.doi.org/10.1016/j.inffus.2016.05.004},
volume = {33},
year = {2017}
}
@article{Feng2019,
abstract = {Learning effective image representations is a vital issue for remote sensing (RS) image recognition tasks. Although numerous algorithms have been proposed, it is still challenging due to the limited labeled data. One representative work is the Laplacian-regularized multitask dictionary learning (LR-MTDL) that employs graph Laplacian regularization terms to fully utilize both the labeled and unlabeled information. However, it probably conduces to poor extrapolating power because Laplacian regularization biases the solution toward a constant function. In this letter, we propose a Hessian-regularized multitask dictionary learning to learn a source-data set-shared but target-data set-biased representation for RS image recognition. Particularly, Hessian can properly exploit the intrinsic local geometry of the data manifold and finally leverage the performance. Extensive experiments on four RS image data sets validate the effectiveness of the proposed method by comparing with baseline algorithms including single-task dictionary learning and LR-MTDL.},
author = {Feng, Guanhua and Liu, Weifeng and Li, Shuying and Tao, Dapeng and Zhou, Yicong},
doi = {10.1109/LGRS.2018.2881834},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Hessian-Regularized Multitask Dictionary Learningfor Remote Sensing Image Recognition.pdf:pdf},
issn = {1545598X},
journal = {IEEE Geoscience and Remote Sensing Letters},
keywords = {Hessian regularization,multitask dictionary learning,remote sensing (RS) image recognition},
number = {5},
pages = {821--825},
publisher = {IEEE},
title = {{Hessian-Regularized Multitask Dictionary Learning for Remote Sensing Image Recognition}},
volume = {16},
year = {2019}
}
@article{Yuan2019,
abstract = {Hyperspectral anomaly detection is a research hot spot in the field of remote sensing. It can distinguish abnormal targets from the scene just by utilizing the spectral differences and requiring no prior information. A series of anomaly detectors based on Reed-Xiaoli methods are very important and typical algorithms in this research area, which generally have the hypothesis about background subject to the Gaussian distribution. However, this assumption is inaccurate to describe a hyperspectral image with a complex scene in practice. Besides, due to the unavoidable existence of abnormal targets, background statistics will be affected which will reduce the detection performance. To address these problems, we propose a sparse dictionary learning method by using a capped norm to realize hyperspectral anomaly detection. Moreover, a new training data selection strategy based on clustering technique is also proposed to learn a more representative background dictionary. The main contributions are concluded in threefold: 1) neither making any assumptions on the background distribution nor computing the covariance matrix, the proposed method is more adaptive to all kinds of complex hyperspectral images in practice; 2) owing to the good qualities of the capped norm, the learned sparse background dictionary is resistant to the effect of anomalies and has stronger distinctiveness to anomalies from background; 3) without using the traditional sliding hollow window technique, the proposed method is more effective to detect different sizes of abnormal targets. The extensive experiments on four commonly used real-world hyperspectral images demonstrate the effectiveness of the proposed method and show its superiority over the benchmark methods.},
author = {Yuan, Yuan and Ma, Dandan and Wang, Qi},
doi = {10.1109/ACCESS.2019.2894590},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08631110.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Anomaly detection,capped norm,dictionary learning,hyperspectral images,sparse},
pages = {16132--16144},
publisher = {IEEE},
title = {{Hyperspectral Anomaly Detection via Sparse Dictionary Learning Method of Capped Norm}},
volume = {7},
year = {2019}
}
@article{Jiao2018,
abstract = {A multiple instance dictionary learning approach, dictionary learning using functions of multiple instances (DL-FUMI), is used to perform beat-to-beat heart rate estimation and to characterize heartbeat signatures from ballistocardiogram (BCG) signals collected with a hydraulic bed sensor. DL-FUMI estimates a 'heartbeat concept' that represents an individual's personal ballistocardiogram heartbeat pattern. DL-FUMI formulates heartbeat detection and heartbeat characterization as a multiple instance learning problem to address the uncertainty inherent in aligning BCG signals with ground truth during training. Experimental results show that the estimated heartbeat concept obtained by DL-FUMI is an effective heartbeat prototype and achieves superior performance over comparison algorithms.},
author = {Jiao, Changzhe and Su, Bo Yu and Lyons, Princess and Zare, Alina and Ho, K. C. and Skubic, Marjorie},
doi = {10.1109/TBME.2018.2812602},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08307229.pdf:pdf},
issn = {15582531},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Ballistocardiogram,bed sensor,dictionary learning,heart rate,heartbeat characterization,multiple instance learning,target characterization,target detection},
number = {11},
pages = {2634--2648},
title = {{Multiple instance dictionary learning for beat-to-beat heart rate monitoring from ballistocardiograms}},
volume = {65},
year = {2018}
}
@article{Shen2019,
abstract = {Discriminative dictionary learning (DDL) provides an appealing paradigm for appearance modeling in visual tracking. However, most existing DDL-based trackers cannot handle drastic appearance changes, especially for scenarios with background cluster and/or similar object interference. One reason is that they often suffer from the loss of subtle visual information, which is critical to distinguish an object from distracters. In this paper, we explore the use of activations from the convolutional layer of a convolutional neural network to improve the object representation and then propose a robust distracter-resistive tracker via learning a multi-component discriminative dictionary. The proposed method exploits both the intra-class and inter-class visual information to learn shared atoms and the class-specific atoms. By imposing several constraints into the objective function, the learned dictionary is reconstructive, compressive, and discriminative, and thus can better distinguish an object from the background. In addition, our convolutional features have structural information for object localization and balance the discriminative power and semantic information of the object. Tracking is carried out within a Bayesian inference framework where a joint decision measure is used to construct the observation model. To alleviate the drift problem, the reliable tracking results obtained online are accumulated to update the dictionary. Both the qualitative and quantitative results on the CVPR2013 benchmark, the VOT2015 data set, and the SPOT data set demonstrate that our tracker achieves substantially better overall performance against the state-of-the-art approaches.},
author = {Shen, Weichao and Wu, Yuwei and Yuan, Junsong and Duan, Lingyu and Zhang, Jian and Jia, Yunde},
doi = {10.1109/TCSVT.2018.2862151},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Robust Distracter-Resistive Tracker via Learning aMulti-Component Discriminative Dictionary.pdf:pdf},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Visual tracking,appearance changes,multi-component discriminative dictionary,multi-object tracking},
number = {7},
pages = {2012--2028},
publisher = {IEEE},
title = {{Robust Distracter-Resistive Tracker via Learning a Multi-Component Discriminative Dictionary}},
volume = {29},
year = {2019}
}
@article{Ben-Cohen2018,
abstract = {In this work we focus on liver metastases detection in computed tomography (CT) examinations, using both a global context with a fully convolutional network (FCN), and a local patch level analysis with superpixel sparse based classification. The task of detecting metastases in the liver, in particular the small metastases, is important for early detection of liver cancer. Using a combined global and local approach, we present a system that can enhance detection capabilities. Our data contains a development set with CT examinations from 20 patients with a total of 68 lesions and a testing set with CT examinations from 14 patients with overall 55 lesions, out of which 35{\%} were considered small lesions (longest diameter ≤ 1.5 cm). Experiments using 3-fold cross-validation resulted in a true positive rate of 94.6{\%} with 2.9 false positives per case. These results are clinically promising, and should lead to better detection capabilities, including of small lesions, which is critical in cancer diagnosis.},
author = {Ben-Cohen, Avi and Klang, Eyal and Kerpel, Ariel and Konen, Eli and Amitai, Michal Marianne and Greenspan, Hayit},
doi = {10.1016/j.neucom.2017.10.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231217316259-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {CT,Deep learning,Detection,Liver lesions,Metastases},
pages = {1585--1594},
publisher = {Elsevier B.V.},
title = {{Fully convolutional network and sparsity-based dictionary learning for liver lesion detection in CT examinations}},
url = {https://doi.org/10.1016/j.neucom.2017.10.001},
volume = {275},
year = {2018}
}
@article{Pan2018,
abstract = {Image restoration is a difficult and challenging problem in various imaging applications. However, despite of the benefits of a single overcomplete dictionary, there are still several challenges for capturing the geometric structure of image of interest. To more accurately represent the local structures of the underlying signals, we propose a new problem formulation for sparse representation with block-orthogonal constraint. There are three contributions. First, a framework for discriminative structured dictionary learning is proposed, which leads to a smooth manifold structure and quotient search spaces. Second, an alternating minimization scheme is proposed after taking both the cost function and the constraints into account. This is achieved by iteratively alternating between updating the block structure of the dictionary defined on Grassmann manifold and sparsifying the dictionary atoms automatically. Third, Riemannian conjugate gradient is considered to track local subspaces efficiently with a convergence guarantee. Extensive experiments on various datasets demonstrate that the proposed method outperforms the state-of-the-art methods on the removal of mixed Gaussian-impulse noise.},
author = {Pan, Han and Jing, Zhongliang and Qiao, Lingfeng and Li, Minzhe},
doi = {10.1109/TCYB.2017.2751585},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08049506.pdf:pdf},
issn = {21682267},
journal = {IEEE Transactions on Cybernetics},
keywords = {Grassmann manifold,image restoration (IR),sparse representation},
number = {10},
pages = {2875--2886},
publisher = {IEEE},
title = {{Discriminative structured dictionary learning on grassmann manifolds and its application on image restoration}},
volume = {48},
year = {2018}
}
@article{Zhao2018,
abstract = {Planet bearing vibrations feature high complexity due to the intricate kinematics and multiple modulation effects. This leads to difficulty in planet bearing fault identification. In order to overcome this difficulty, a sparse classification framework based on dictionary learning is proposed. It operates directly on raw signals and is free from steps involved in conventional pattern identification such as feature design which requires prior expertise. First, a raw signal matrix is generated by partitioning the raw signal into segments, where each segment in all signal states has the same number of data points, and the length of the segment should guarantee that at least two adjacent fault impulses with the maximum interval can occur. Then, a dictionary initialized with the training sample set is learnt from the signal matrix, based on which the sparse representation is carried out afterwards. A dictionary learnt over signals under a certain state is best suited for signal reconstruction under the same state only but cannot recover signals well under other states. Inspired by this fact, sparse classification can be accomplished by comparing signal recovery errors over dictionaries under different states. The proposed method is validated using the experimental data of a planetary gearbox. Localized faults on the outer race, roller element and inner race of planet bearings are all identified successfully.},
author = {Zhao, Chuan and Feng, Zhipeng and Wei, Xiukun and Qin, Yong},
doi = {10.1016/j.eswa.2018.05.012},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0957417418302951-main.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Dictionary learning,Fault identification,Planet bearing,Sparse classification},
pages = {233--245},
publisher = {Elsevier Ltd},
title = {{Sparse classification based on dictionary learning for planet bearing fault identification}},
url = {https://doi.org/10.1016/j.eswa.2018.05.012},
volume = {108},
year = {2018}
}
@article{Liu2017a,
author = {Liu, Yu and Chen, Xun and Peng, Hu and Wang, Zengfu},
doi = {10.1016/j.inffus.2016.12.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1566253516302081-main.pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {Image fusion,Multi-focus image fusion,Deep learnin},
pages = {191--207},
publisher = {Elsevier B.V.},
title = {{Multi-focus image fusion with a deep convolutional neural network}},
url = {http://dx.doi.org/10.1016/j.inffus.2016.12.001},
volume = {36},
year = {2017}
}
@article{Du2019,
abstract = {Compressed sensing (CS) has shown to be a successful technique for image recovery. Designing an effective regularization term reflecting the image sparse prior information plays a critical role in this field. Dictionary learning (DL) strategy alleviates the drawback of fixed bases. But the structure information of the image is easy to be blurred in complex regions due to the absence of sparsity in dictionary learning. This paper proposes a novel joint dictionary learning and Shape-Adaptive DCT (SADCT) thresholding method. We first propose to exploit sparsity of image in shape-adaptive regions, which is beneficial to medical images of complex textures. In this framework, the local sparsity depicts the smoothness redundancies exploited by dictionary learning. Moreover, the sparsity is enhanced especially in detail areas by the newly introduced SADCT thresholding. The attenuated SADCT coefficients are used to reconstruct a local estimation of the signal within the adaptive-shape support. Image is represented sparser in SADCT transform domain and the details of the image information can be kept with a much larger probability. Based on split Bregman iterations, an efficient alternating minimization algorithm is developed to solve the proposed CS medical image recovery problem. The results of various experiments on MR images consistently demonstrate that the proposed algorithm efficiently recovers MR images and shows advantages over the current leading CS reconstruction approaches.},
author = {Du, Dong and Pan, Zhibin and Zhang, Penghui and Li, Yuxin and Ku, Weiping},
doi = {10.1016/j.mri.2018.09.014},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0730725X18304624-main.pdf:pdf},
issn = {18735894},
journal = {Magnetic Resonance Imaging},
keywords = {Compressed sensing,Dictionary learning,Image reconstruction,Shape-adaptive DCT,Sparse representation,Splitting Bregman iteration},
number = {September 2018},
pages = {60--71},
publisher = {Elsevier},
title = {{Compressive sensing image recovery using dictionary learning and shape-adaptive DCT thresholding}},
url = {https://doi.org/10.1016/j.mri.2018.09.014},
volume = {55},
year = {2019}
}
@article{Zhou2018a,
abstract = {Recently, lots of dictionary learning methods have been proposed and successfully applied. However, many of them assume that the noise in data is drawn from Gaussian or Laplacian distribution and therefore they typically adopt the ℓ2 or ℓ1 norm to characterize these two kinds of noise, respectively. Since this assumption is inconsistent with the real cases, the performance of these methods is limited. In this paper, we propose a novel dictionary learning with structured noise (DLSN) method for handling noisy data. We decompose the original data into three parts: clean data, structured noise, and Gaussian noise, and then characterize them separately. We utilize the low-rank technique to preserve the inherent subspace structure of clean data. Instead of only using the predefined distribution to fit the real distribution of noise, we learn an adaptive dictionary to characterize structured noise and employ the ℓ2 norm to depict Gaussian noise. Such a mechanism can characterize noise more precisely. We also prove that our proposed optimization method can converge to a critical point and the convergence rate is at least sublinear. Experimental results on the data clustering task demonstrate the effectiveness and robustness of our method.},
author = {Zhou, Pan and Fang, Cong and Lin, Zhouchen and Zhang, Chao and Chang, Edward Y.},
doi = {10.1016/j.neucom.2017.07.041},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0925231217313437-main.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Dictionary learning,Low rank representation,Sparse representation,Structured noise},
pages = {414--423},
publisher = {Elsevier B.V.},
title = {{Dictionary learning with structured noise}},
url = {https://doi.org/10.1016/j.neucom.2017.07.041},
volume = {273},
year = {2018}
}
@article{Zhang2019b,
abstract = {In this work, we conduct comprehensive comparisons between four variants of independent component analysis (ICA) methods and three variants of sparse dictionary learning (SDL) methods, both at the subject-level, by using synthesized fMRI data with ground-truth. Our results showed that ICA methods perform very well and slightly better than SDL methods when functional networks' spatial overlaps are minor, but ICA methods have difficulty in differentiating functional networks with moderate or significant spatial overlaps. In contrast, the SDL algorithms perform consistently well no matter how functional networks spatially overlap, and importantly, SDL methods are significantly better than ICA methods when spatial overlaps between networks are moderate or severe. This work offers empirical better understanding of ICA and SDL algorithms in inferring functional networks from fMRI data and provides new guidelines and caveats when constructing and interpreting functional networks in the era of fMRI-based connectomics.},
author = {Zhang, Wei and Lv, Jinglei and Li, Xiang and Zhu, Dajiang and Jiang, Xi and Zhang, Shu and Zhao, Yu and Guo, Lei and Ye, Jieping and Hu, Dewen and Liu, Tianming},
doi = {10.1109/TBME.2018.2831186},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-5-Experimental Comparisons of Sparse DictionaryLearning and Independen.pdf:pdf},
issn = {15582531},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Resting state fMRI,functional network,independent component analysis,sparse dictionary learning},
number = {1},
pages = {289--299},
publisher = {IEEE},
title = {{Experimental Comparisons of Sparse Dictionary Learning and Independent Component Analysis for Brain Network Inference from fMRI Data}},
volume = {66},
year = {2019}
}
@article{Zhu2018b,
author = {Zhu, Zhiqin and Yin, Hongpeng and Chai, Yi and Li, Yanxia and Qi, Guanqiu},
doi = {10.1016/j.ins.2017.09.010},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0020025517309325-main(2).pdf:pdf},
issn = {0020-0255},
journal = {Information Sciences},
keywords = {Sparse representation,Dictionary construction,Mult,dictionary construction,multi-modality image fusion,sparse representation},
pages = {516--529},
publisher = {Elsevier Inc.},
title = {{A novel multi-modality image fusion method based on image decomposition and sparse representation}},
url = {https://doi.org/10.1016/j.ins.2017.09.010},
volume = {432},
year = {2018}
}
@article{Abreu2019,
abstract = {Most fMRI studies of the brain's intrinsic functional connectivity (FC) have assumed that this is static; however, it is now clear that it changes over time. This is particularly relevant in epilepsy, which is characterized by a continuous interchange between epileptic and normal brain states associated with the occurrence of epileptic activity. Interestingly, recurrent states of dynamic FC (dFC) have been found in fMRI data using unsupervised learning techniques, assuming either their sparse or non-sparse combination. Here, we propose an l1-norm regularized dictionary learning (l1-DL) approach for dFC state estimation, which allows an intermediate and flexible degree of sparsity in time, and demonstrate its application in the identification of epilepsy-related dFC states using simultaneous EEG-fMRI data. With this l1-DL approach, we aim to accommodate a potentially varying degree of sparsity upon the interchange between epileptic and non-epileptic dFC states. The simultaneous recording of the EEG is used to extract time courses representative of epileptic activity, which are incorporated into the fMRI dFC state analysis to inform the selection of epilepsy-related dFC states. We found that the proposed l1-DL method performed best at identifying epilepsy-related dFC states, when compared with two alternative methods of extreme sparsity (k-means clustering, maximum; and principal component analysis, minimum), as well as an l0-norm regularization framework (l0-DL), with a fixed amount of temporal sparsity. We further showed that epilepsy-related dFC states provide novel insights into the dynamics of epileptic networks, which go beyond the information provided by more conventional EEG-correlated fMRI analysis, and which were concordant with the clinical profile of each patient. In addition to its application in epilepsy, our study provides a new dFC state identification method of potential relevance for studying brain functional connectivity dynamics in general.},
author = {Abreu, Rodolfo and Leal, Alberto and Figueiredo, Patr{\'{i}}cia},
doi = {10.1038/s41598-018-36976-y},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/s41598-018-36976-y.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--18},
title = {{Identification of epileptic brain states by dynamic functional connectivity analysis of simultaneous EEG-fMRI: a dictionary learning approach}},
volume = {9},
year = {2019}
}
@article{Zhang2013,
abstract = {Recently, sparse representation (SR) and joint sparse representation (JSR) have attracted a lot of interest in image fusion. The SR models signals by sparse linear combinations of prototype signal atoms that make a dictionary. The JSR indicates that different signals from the various sensors of the same scene form an ensemble. These signals have a common sparse component and each individual signal owns an innovation sparse component. The JSR offers lower computational complexity compared with SR. First, for JSR-based image fusion, we give a new fusion rule. Then, motivated by the method of optimal directions (MOD), for JSR, we propose a novel dictionary learning method (MODJSR) whose dictionary updating procedure is derived by employing the JSR structure one time with singular value decomposition (SVD). MODJSR has lower complexity than the K-SVD algorithm which is often used in previous JSR-based fusion algorithms. To capture the image details more efficiently, we proposed the generalized JSR in which the signals ensemble depends on two dictionaries. MODJSR is extended to MODGJSR in this case. MODJSR/MODGJSR can simultaneously carry out dictionary learning, denoising, and fusion of noisy source images. Some experiments are given to demonstrate the validity of the MODJSR/MODGJSR for image fusion. {\textcopyright} 2013 Society of Photo-Optical Instrumentation Engineers (SPIE).},
author = {Zhang, Qiheng and Fu, Yuli and Li, Haifeng and Zou, Jian},
doi = {10.1117/1.oe.52.5.057006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Dictionary learning method for joint.pdf:pdf},
issn = {0091-3286},
journal = {Optical Engineering},
number = {5},
pages = {057006},
title = {{Dictionary learning method for joint sparse representation-based image fusion}},
volume = {52},
year = {2013}
}
@article{James2014,
abstract = {Medical image fusion is the process of registering and combining multiple images from single or multiple imaging modalities to improve the imaging quality and reduce randomness and redundancy in order to increase the clinical applicability of medical images for diagnosis and assessment of medical problems. Multi-modal medical image fusion algorithms and devices have shown notable achievements in improving clinical accuracy of decisions based on medical images. This review article provides a factual listing of methods and summarizes the broad scientific challenges faced in the field of medical image fusion. We characterize the medical image fusion research based on (1) the widely used image fusion methods, (2) imaging modalities, and (3) imaging of organs that are under study. This review concludes that even though there exists several open ended technological and scientific challenges, the fusion of medical images has proved to be useful for advancing the clinical reliability of using medical imaging for medical diagnostics and analysis, and is a scientific discipline that has the potential to significantly grow in the coming years. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {James, Alex Pappachen and Dasarathy, Belur V.},
doi = {10.1016/j.inffus.2013.12.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/James-2014-Medical-image-fusion-a-survey-of-th.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Diagnostics,Image fusion,Medical image analysis,Medical imaging},
number = {1},
pages = {4--19},
publisher = {Elsevier B.V.},
title = {{Medical image fusion: A survey of the state of the art}},
url = {http://dx.doi.org/10.1016/j.inffus.2013.12.002},
volume = {19},
year = {2014}
}
@article{Zhu2019,
abstract = {Purpose: To develop and evaluate an integrated motion correction and dictionary learning (MoDic) technique to accelerate data acquisition for myocardial T 1 mapping with improved accuracy. Methods: MoDic integrates motion correction with dictionary learning–based reconstruction. A random undersampling scheme was implemented for slice-interleaved T 1 mapping sequence to allow prospective undersampled data acquisition. Phantom experiments were performed to evaluate the effect of reconstruction on T 1 measurement. In vivo T 1 mappings were acquired in 8 healthy subjects using 6 different acceleration approaches: uniform or randomly undersampled k-space data with reduction factors (R) of 2, 3, and 4. Uniform undersampled data were reconstructed with SENSE, and randomly undersampled k-space data were reconstructed using dictionary learning, compressed sensing SENSE, and MoDic methods. Three expert readers subjectively evaluated the quality of T 1 maps using a 4-point scoring system. The agreement between T 1 values was assessed by Bland-Altman analysis. Results: In the phantom study, the accuracy of T 1 measurements improved with increasing reduction factors (-31 ± 35 ms, -13 ± 18 ms, and -5 ± 11 ms for reduction factor (R) = 2 to 4, respectively). The image quality of in vivo T 1 maps assessed by subjective scoring using MoDic was similar to that of SENSE at R = 2 (P =.61) but improved at R = 3 and 4 (P {\textless}.01). The scores of dictionary learning (2.98 ± 0.71, 2.91 ± 0.60, and 2.67 ± 0.71 for R = 2 to 4) and CS-SENSE (3.32 ± 0.42, 3.05 ± 0.43, and 2.53 ± 0.43) were lower than those of MoDic (3.48 ± 0.46, 3.38 ± 0.52, and 2.9 ± 0.60) for all reduction factors (P {\textless}.05 for all). Conclusion: The MoDic method accelerates data acquisition for myocardial T 1 mapping with improved T 1 measurement accuracy.},
author = {Zhu, Yanjie and Kang, Jinkyu and Duan, Chong and Nezafat, Maryam and Neisius, Ulf and Jang, Jihye and Nezafat, Reza},
doi = {10.1002/mrm.27579},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/10.1002{\_}mrm.27579.pdf:pdf},
issn = {15222594},
journal = {Magnetic Resonance in Medicine},
keywords = {compressed sensing,dictionary learning,motion correction,myocardial T 1 mapping},
number = {4},
pages = {2644--2654},
title = {{Integrated motion correction and dictionary learning for free-breathing myocardial T 1 mapping}},
volume = {81},
year = {2019}
}
@article{Gogineni2018,
abstract = {The significant issues in remote sensing image fusion are enhancing the spatial details and preserving the essential spectral information. The classical pan-sharpening methods often incur spectral distortion and still striving to produce the fused images with prominent spatial and spectral attributes. Motivated by the desirable results of sparse representation (SR) theory, a novel pan-sharpening method is developed based on SR of high frequency (HF) components over a multi-scale learned dictionary (MSLD). MSLD technique acquires the capability of extracting the intrinsic characteristics of images, wherein, it possess the features of both multi-scale representation and learned dictionaries. In this paper, the dictionaries are adaptively learned from HF sub-images derived from the two versions of panchromatic image, realized at different spatial resolutions. A fast and computationally efficient algorithm is used for dictionary learning. The notion of SR together with patch recurrence over different scales is incorporated to estimate the high frequency details. The fused image is reconstructed by injecting the band specific spatial details into the up-sampled multi-spectral images. The performance of the proposed method is appraised with the datasets from different satellite sensors namely, QuickBird, IKONOS, WorldView-2 and Pl{\'{e}}iades. The observations inferred from visual perception and quality indices analysis manifest the efficiency of proposed method over several well-known methods for the datasets considered at reduced-scale and full-scale resolutions. Further, the quantitative analysis of obtained performance measures confirms the efficacy of the proposed method for the reduced-scale and full-scale data sets. Especially, at a reduced-scale, proposed method yields an optimal value of Correlation coefficient, Structural similarity and Q4. In a comparative sense, usage of the proposed method at full-scale results in 4{\%} and 2.56{\%} improvement in the Spatial distortion index for QuickBird and WorldView-2 data respectively contrary to the best reported outcome obtained from Sparse Representation of injected details (SR-D) scheme. Invariably, for full-scale data, the QNR attains its optimal value.},
author = {Gogineni, Rajesh and Chaturvedi, Ashvini},
doi = {10.1016/j.isprsjprs.2018.10.009},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0924271618302879-main.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Dictionary learning,Multi-scale learned dictionary,Pan-sharpening,Sparse representation,Wavelet transform},
number = {October},
pages = {360--372},
publisher = {Elsevier},
title = {{Sparsity inspired pan-sharpening technique using multi-scale learned dictionary}},
url = {https://doi.org/10.1016/j.isprsjprs.2018.10.009},
volume = {146},
year = {2018}
}
@article{Li2018g,
abstract = {Person re-identification plays an important role in many safety-critical applications. Existing works mainly focus on extracting patch-level features or learning distance metrics. However, the representation power of extracted features might be limited, due to the various viewing conditions of pedestrian images in complex real-world scenarios. To improve the representation power of features, we learn discriminative and robust representations via dictionary learning in this paper. First, we propose a Cross-view Dictionary Learning (CDL) model, which is a general solution to the multi-view learning problem. Inspired by the dictionary learning based domain adaptation, CDL learns a pair of dictionaries from two views. In particular, CDL adopts a projective learning strategy, which is more efficient than the l1 optimization in traditional dictionary learning. Second, we propose a Cross-view Multi-level Dictionary Learning (CMDL) approach based on CDL. CMDL contains dictionary learning models at different representation levels, including image-level, horizontal part-level, and patch-level. The proposed models take advantages of the view-consistency information, and adaptively learn pairs of dictionaries to generate robust and compact representations for pedestrian images. Third, we incorporate a discriminative regularization term to CMDL, and propose a CMDL-Dis approach which learns pairs of discriminative dictionaries in image-level and part-level. We devise efficient optimization algorithms to solve the proposed models. Finally, a fusion strategy is utilized to generate the similarity scores for test images. Experiments on the public VIPeR, CUHK Campus, iLIDS, GRID and PRID450S datasets show that our approach achieves the state-of-the-art performance.},
author = {Li, Sheng and Shao, Ming and Fu, Yun},
doi = {10.1109/TPAMI.2017.2764893},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08085134.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Dictionary learning,cross-view learning,multi-level representation,person re-identification},
number = {12},
pages = {2963--2977},
publisher = {IEEE},
title = {{Person re-identification by cross-view multi-level dictionary learning}},
volume = {40},
year = {2018}
}
@article{Shen2013,
author = {Shen, Rui and Cheng, Irene and Basu, Anup},
doi = {10.1109/TBME.2012.2211017},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2013-Cross-scale-coefficient-selection-f.pdf:pdf},
journal = {IEEE Transactions on Biomedical Engineering},
number = {4},
pages = {1069--1079},
publisher = {IEEE},
title = {{Cross-Scale Coefficient Selection for Volumetric}},
volume = {60},
year = {2013}
}
@article{Luengo2018,
abstract = {The electrocardiogram (ECG) was the first biomedical signal for which digital signal processing techniques were extensively applied. By its own nature, the ECG is typically a sparse signal, composed of regular activations (QRS complexes and other waveforms, such as the P and T waves) and periods of inactivity (corresponding to isoelectric intervals, such as the PQ or ST segments), plus noise and interferences. In this work, we describe an efficient method to construct an overcomplete and multi-scale dictionary for sparse ECG representation using waveforms recorded from real-world patients. Unlike most existing methods (which require multiple alternative iterations of the dictionary learning and sparse representation stages), the proposed approach learns the dictionary first, and then applies a fast sparse inference algorithm to model the signal using the constructed dictionary. As a result, our method is much more efficient from a computational point of view than other existing algorithms, thus becoming amenable to dealing with long recordings from multiple patients. Regarding the dictionary construction, we located first all the QRS complexes in the training database, then we computed a single average waveform per patient, and finally we selected the most representative waveforms (using a correlation-based approach) as the basic atoms that were resampled to construct the multi-scale dictionary. Simulations on real-world records from Physionet's PTB database show the good performance of the proposed approach.},
author = {Luengo, David and Meltzer, David and Trigano, Tom},
doi = {10.3390/app8122569},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/applsci-08-02569.pdf:pdf},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
keywords = {Electrocardiogram (ECG),Least Absolute Shrinkage and Selection Operator (L,Overcomplete multi-scale dictionary construction,Signal representation,Sparse inference},
number = {12},
pages = {1--18},
title = {{An efficient method to learn overcomplete multi-scale dictionaries of ECG signals}},
volume = {8},
year = {2018}
}
@article{Zhou2018,
abstract = {Cross-label suppression dictionary learning is an effective approach to preserve the label property for signal representation in face recognition. This paper presents a proposed improved dictionary learning algorithm, considering the tradeoffs between the operating time and the signal reconstruction residuals for the face recognition problem that combines an optimal loss function and the cross-label suppression supervised dictionary learning approach. Based on the relationship of the cost time of the dictionary learning algorithm and the residuals of the sparse representations, this paper attempts to select an optimal sparse coding dimension for the original signal to reduce the computational cost. Experiments on face recognition confirm that our proposed algorithm is able to achieve a desired classification results as well as obtain a considerably faster dictionary learning process.},
author = {Zhou, Tian and Yang, Sujuan and Wang, Lei and Yao, Jiming and Gui, Guan},
doi = {10.1109/ACCESS.2018.2868133},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08452894.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Cross-label suppression,compressive sensing,computational complexity,dictionary learning,face recognition},
pages = {48716--48725},
publisher = {IEEE},
title = {{Improved Cross-Label Suppression Dictionary Learning for Face Recognition}},
volume = {6},
year = {2018}
}
@article{Zhang2019f,
author = {Zhang, Wanhong and Gao, Juan and Yang, Yongfeng and Liang, Dong and Liu, Xin and Zheng, Hairong and Hu, Zhanli},
doi = {10.1002/mp.13804},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/mp.13804.pdf:pdf},
issn = {0094-2405},
journal = {Medical Physics},
keywords = {dictionary learning,image reconstruction,patch regularization,positron emission},
pages = {1--13},
title = {{Image reconstruction for positron emission tomography based on patch‐based regularization and dictionary learning}},
year = {2019}
}
@article{Iqbal2019,
author = {Iqbal, Asif and Seghouane, Abd-Krim},
doi = {10.1109/tip.2019.2922074},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08737866.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
number = {11},
pages = {5729--5739},
title = {{An {\$}\backslashalpha{\$} -Divergence-Based Approach for Robust Dictionary Learning}},
volume = {28},
year = {2019}
}
@article{Li2019b,
abstract = {{\textcopyright} 2019 Elsevier Ltd Analysis dictionary learning (ADL) has been successfully applied to a variety of learning systems. However, the ordinal locality of analysis dictionary has rarely been explored in constructing discriminative terms. In this paper, a discriminative low-rank analysis–synthesis dictionary learning (LR-ASDL) algorithm with the adaptively ordinal locality is proposed for object classification. Specifically, we first explicitly introduce the relations between the analysis atoms and profiles (i.e., row vectors of the coefficients matrix). That is, the similarity between two profiles depends on that between the corresponding analysis atoms. Moreover, an adaptively ordinal locality preserving(AOLP) term is constructed by simultaneously exploiting the profiles and analysis atoms, which can be learned in a supervised way. In this way, the neighborhood correlations between analysis atoms and the high-order ranking information of each analysis atom's neighbors can be simultaneously preserved in the learning process. Particularly, this helps to uncover the intrinsic underlying data factors and inherit the geometry structure information of training samples. Furthermore, the low-rank model is imposed on the synthesis atoms to further facilitate the learned dictionaries to be more discriminative. Extensive experimental results on eight databases demonstrate that the LR-ASDL algorithm clearly outperforms some analysis and synthesis dictionary learning algorithms using deep and hand-crafted features.},
author = {Li, Zhengming and Zhang, Zheng and Qin, Jie and Li, Sheng and Cai, Hongmin},
doi = {10.1016/j.neunet.2019.07.013},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0893608019302011-main.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {93--112},
publisher = {Elsevier Ltd},
title = {{Low-rank analysis–synthesis dictionary learning with adaptively ordinal locality}},
url = {https://doi.org/10.1016/j.neunet.2019.07.013},
volume = {119},
year = {2019}
}
@article{Lv2018,
abstract = {Dictionary learning provides an adaptive way to optimally represent a given dataset. In dictionary learning, the basis function is adapted according to the given data instead of being fixed in many analytical sparse transforms. The application of the dictionary learning techniques in seismic data processing has been popular in the past decade. However, most dictionary learning algorithms are directly taken from the image processing community and thus are not suitable for seismic data. Considering that the seismic data is spatially coherent, the dictionary should better be learned according to the coherency information in the seismic data. We found the dictionary learning performs better when the spatial correlation is stronger and thus we propose an approximately flattening operator to help learn the dictionary in an approximately flattened structure domain, where the strong spatial coherence helps construct a dictionary that follows better the structural pattern inof the seismic data. The presented dictionary learning in the approximately flattened structure domain (DLAF) thus has a stronger capability in separating signal and noise. We use both synthetic and field data examples to demonstrate the superb performance of the proposed method.},
author = {Lv, Hui and Bai, Min},
doi = {10.1016/j.jappgeo.2018.09.010},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0926985118303380-main.pdf:pdf},
issn = {09269851},
journal = {Journal of Applied Geophysics},
pages = {522--531},
publisher = {Elsevier B.V.},
title = {{Learning dictionary in the approximately flattened structure domain}},
url = {https://doi.org/10.1016/j.jappgeo.2018.09.010},
volume = {159},
year = {2018}
}
@article{Lin2018b,
abstract = {For sparse representation or sparse coding based image classification, the dictionary, which is required to faithfully and robustly represent query images, plays an important role on its success. Learning dictionaries from the training data for sparse coding has shown state-of-the-art results in image classification and face recognition. However, for face recognition, conventional dictionary learning methods cannot well learn a reliable and robust dictionary due to suffering from the small-sample-size problem. The other significant issue is that current dictionary learning do not completely cover the important components of signal representation (e.g., commonality, particularity, and disturbance), which limit their performance. In order to solve the above issues, in this paper, we propose a novel robust, discriminative and comprehensive dictionary learning (RDCDL) method, in which a robust dictionary is learned from comprehensive training sample diversities generated by extracting and generating facial variations. Especially, to completely represent the commonality, particularity and disturbance, class-shared, class-specific and disturbance dictionary atoms are learned to represent the data from different classes. Discriminative regularizations on the dictionary and the representation coefficients are used to exploit discriminative information, which effectively improves the classification capability of the dictionary. The proposed RDCDL method is extensively evaluated on benchmark face image databases, and it shows superior performance to many state-of-the-art dictionary learning methods for face recognition.},
author = {Lin, Guojun and Yang, Meng and Yang, Jian and Shen, Linlin and Xie, Weicheng},
doi = {10.1016/j.patcog.2018.03.021},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0031320318301109-main.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Dictionary learning,Face recognition,Sparse representation},
pages = {341--356},
publisher = {Elsevier Ltd},
title = {{Robust, discriminative and comprehensive dictionary learning for face recognition}},
url = {https://doi.org/10.1016/j.patcog.2018.03.021},
volume = {81},
year = {2018}
}
@article{Ma2018,
abstract = {Most hyperspectral anomaly detection methods directly utilize all the original spectra to recognize anomalies. However, the inherent characteristics of high spectral dimension and complex spectral correlation commonly make their detection performance unsatisfactory. Therefore, an effective feature extraction technique is necessary. To this end, this paper proposes a novel anomaly detection method via discriminative feature learning with multiple-dictionary sparse representation. Firstly, a new spectral feature selection framework based on sparse presentation is designed, which is closely guided by the anomaly detection task. Then, the representative spectra which can significantly enlarge anomaly's deviation from background are picked out by minimizing residues between background spectrum reconstruction error and anomaly spectrum recovery error. Finally, through comprehensively considering the virtues of different groups of representative features selected from multiple dictionaries, a global multiple-view detection strategy is presented to improve the detection accuracy. The proposed method is compared with ten state-of-the-art methods including LRX, SRD, CRD, LSMAD, RSAD, BACON, BACON-target, GRX, GKRX, and PCA-GRX on three real-world hyperspectral images. Corresponding to each competitor, it has the average detection performance improvement of about 9.9{\%}, 7.4{\%}, 24.2{\%}, 10.1{\%}, 26.2{\%}, 20.1{\%}, 5.1{\%}, 19.3{\%}, 10.7{\%}, and 2.0{\%} respectively. Extensive experiments demonstrate its superior performance in effectiveness and efficiency.},
author = {Ma, Dandan and Yuan, Yuan and Wang, Qi},
doi = {10.3390/rs10050745},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/remotesensing-10-00745(1).pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Anomaly detection,Clustering,Feature extraction,Hyperspectral image,Multiple dictionaries,Sparse representation},
number = {5},
title = {{Hyperspectral anomaly detection via discriminative feature learning with multiple-dictionary sparse representation}},
volume = {10},
year = {2018}
}
@article{Meher2019,
abstract = {Image fusion has been emerging as an important area of research. It has attracted many applications such as surveillance, photography, medical diagnosis, etc. Image fusion techniques are developed at three levels: pixel, feature and decision. Region based image fusion is one of the methods of feature level. It possesses certain advantages – less sensitive to noise, more robust and avoids misregistration. This paper presents a review of region based fusion approaches. A first hand classification of region based fusion methods is carried out. A comprehensive list of objective fusion evaluation metrics is highlighted to compare the existing methods. A detailed analysis is carried out and results are presented in tabular form. This may attract researchers to further explore the research in this direction.},
author = {Meher, Bikash and Agrawal, Sanjay and Panda, Rutuparna and Abraham, Ajith},
doi = {10.1016/j.inffus.2018.07.010},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/09-w-01-year2019-04-A survey on region based image fusion methods.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Image fusion,Region based fusion,Segmentation},
number = {December 2017},
pages = {119--132},
publisher = {Elsevier},
title = {{A survey on region based image fusion methods}},
url = {https://doi.org/10.1016/j.inffus.2018.07.010},
volume = {48},
year = {2019}
}
@article{Zhang2016,
abstract = {We present a novel fusion method based on a multi-task robust sparse representation (MRSR) model and spatial context information to address the fusion of multi-focus gray-level images with misregistration. First, we present a robust sparse representation (RSR) model by replacing the conventional least-squared reconstruction error by a sparse reconstruction error. We then propose a multi-task version of the RSR model, viz., the MRSR model. The latter is then applied to multi-focus image fusion by employing the detailed information regarding each image patch and its spatial neighbors to collaboratively determine both the focused and defocused regions in the input images. To achieve this, we formulate the problem of extracting details from multiple image patches as a joint multi-task sparsity pursuit based on the MRSR model. Experimental results demonstrate that the suggested algorithm is competitive with the current state-of-the-art and superior to some approaches that use traditional sparse representation methods when input images are misregistered.},
author = {Zhang, Qiang and Levine, Martin D.},
doi = {10.1109/TIP.2016.2524212},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/07398058.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {image patch misregistration,multi-focus image fusion,multi-task robust sparse representation,spatial context},
number = {5},
pages = {2045--2058},
publisher = {IEEE},
title = {{Robust Multi-Focus Image Fusion Using Multi-Task Sparse Representation and Spatial Context}},
volume = {25},
year = {2016}
}
@article{Zhang2019c,
abstract = {The impulsive components induced by bearing faults are key features for assessing gear-box bearing faults. However, because of heavy background noise and the interferences of other vibrations, it is difficult to extract these impulsive components caused by faults, particularly early faults, from the measured vibration signals. To capture the high-level structure of impulsive components embedded in measured vibration signals, a dictionary learning method called shift-invariant K-means singular value decomposition (SI-K-SVD) dictionary learning is used to detect the early faults of gear-box bearings. Although SI-K-SVD is more flexible and adaptable than existing methods, the improper selection of two SI-K-SVD-related parameters, namely, the number of iterations and the pattern lengths, has an adverse influence on fault detection performance. Therefore, the sparsity of the envelope spectrum (SES) and the kurtosis of the envelope spectrum (KES) are used to select these two key parameters, respectively. SI-K-SVD with the two selected optimal parameter values, referred to as optimal parameter SI-K-SVD (OP-SI-K-SVD), is proposed to detect gear-box bearing faults. The proposed method is verified by both simulations and an experiment. Compared to the state-of-the-art methods, namely, empirical model decomposition, wavelet transform and K-SVD, OP-SI-K-SVD has better performance in diagnosing the early faults of a gear-box bearing.},
author = {heng Zhang, Zhao and ming Ding, Jian and Wu, Chao and hui Lin, Jian},
doi = {10.1007/s11771-019-4052-4},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Zhang2019{\_}Article{\_}ImpulsiveComponentExtractionUs.pdf:pdf},
isbn = {1177101940524},
issn = {22275223},
journal = {Journal of Central South University},
keywords = {fault diagnosis,gear-box bearing,impulsive component extraction,shift-invariant K-means singular value decompositi},
number = {4},
pages = {824--838},
title = {{Impulsive component extraction using shift-invariant dictionary learning and its application to gear-box bearing early fault diagnosis}},
volume = {26},
year = {2019}
}
@article{Liu2018d,
abstract = {Learned dictionaries have been validated to perform better than predefined ones in many application areas. Focusing on synthetic aperture radar (SAR) images, a structure preserving dictionary learning (SPDL) algorithm, which can capture and preserve the local and distant structures of the datasets for SAR target configuration recognition is proposed in this paper. Due to the target aspect angle sensitivity characteristic of SAR images, two structure preserving factors are embedded into the proposed SPDL algorithm. One is constructed to preserve the local structure of the datasets, and the other one is established to preserve the distant structure of the datasets. Both the local and distant structures of the datasets are preserved using the learned dictionary to realize target configuration recognition. Experimental results on the moving and stationary target acquisition and recognition (MSTAR) database demonstrate that the proposed algorithm is capable of handling the situations with limited number of training samples and under noise conditions.},
author = {Liu, Ming and Chen, Shichao and Lu, Fugang and Wang, Jun},
doi = {10.1016/j.aeue.2017.11.001},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1434841117316023-main.pdf:pdf},
issn = {16180399},
journal = {AEU - International Journal of Electronics and Communications},
keywords = {Dictionary learning,Sparse representation,Synthetic aperture radar (SAR) images,Target configuration recognition},
number = {November 2017},
pages = {523--532},
publisher = {Elsevier},
title = {{SAR target configuration recognition via structure preserving dictionary learning}},
url = {https://doi.org/10.1016/j.aeue.2017.11.001},
volume = {83},
year = {2018}
}
@article{Dou2018,
abstract = {Monocular 3D face reconstruction from a single image has been an active research topic due to its wide applications. It has been demonstrated that the 3D face can be reconstructed efficiently using a PCA-based subspace model for facial shape representation and facial landmarks for model parameter estimation. However, due to the limited expressiveness of the subspace model and the inaccuracy of landmark detection, most existing methods are not robust to pose and illumination variation. To overcome this limitation, this work proposes a coupled-dictionary model for parametric facial shape representation and a two-stage framework for 3D face reconstruction from a single 2D image by using facial landmarks. Motivated by image super-resolution, the proposed coupled-model consists of two dictionaries for the sparse and the dense 3D facial shapes, respectively. In the first stage, the sparse 3D face is estimated from facial landmarks by using partial least-squares regression. In the second stage, the dense 3D face is reconstructed by 3D super-resolution on the estimated sparse 3D face. Comprehensive experimental evaluations demonstrate that the proposed coupled-dictionary model outperforms the PCA-based subspace model in 3D face modeling accuracy and that the proposed framework achieves much lower reconstruction error on facial images with pose and illumination variations compared to state-of-the-art algorithms. Moreover, qualitative analysis demonstrates that the proposed method is generalizable to different types of data, including facial images, portraits, and facial sketches.},
author = {Dou, Pengfei and Wu, Yuhang and Shah, Shishir K. and Kakadiaris, Ioannis A.},
doi = {10.1016/j.patcog.2018.03.002},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0031320318300918-main.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3D face modeling,3D face reconstruction,3D super-resolution,Dictionary learning,Sparse coding},
pages = {515--527},
publisher = {Elsevier Ltd},
title = {{Monocular 3D facial shape reconstruction from a single 2D image with coupled-dictionary learning and sparse coding}},
url = {https://doi.org/10.1016/j.patcog.2018.03.002},
volume = {81},
year = {2018}
}
@article{Zhang2019d,
author = {Zhang, Mingli and Desrosiers, Christian and Guo, Yuhong and Khundrakpam, Budhachandra and Al-Sharif, Noor and Kiar, Greg and Valdes-Sosa, Pedro and Poline, Jean-Baptiste and Evans, Alan},
doi = {10.1016/j.neuroimage.2019.116226},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1053811919308171-main(1).pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
pages = {116226},
publisher = {Elsevier Inc.},
title = {{Brain status modeling with non-negative projective dictionary learning}},
url = {https://doi.org/10.1016/j.neuroimage.2019.116226},
year = {2019}
}
@article{Zhang2019e,
author = {Zhang, Mingli and Desrosiers, Christian and Guo, Yuhong and Khundrakpam, Budhachandra and Al-Sharif, Noor and Kiar, Greg and Valdes-Sosa, Pedro and Poline, Jean-Baptiste and Evans, Alan},
doi = {10.1016/j.neuroimage.2019.116226},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1053811919308171-main.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
pages = {116226},
publisher = {Elsevier Inc.},
title = {{Brain status modeling with non-negative projective dictionary learning}},
url = {https://doi.org/10.1016/j.neuroimage.2019.116226},
year = {2019}
}
@article{Ikram2019,
abstract = {The application of compressed sensing (CS) to biomedical imaging is sensational since it permits a rationally accurate reconstruction of images by exploiting the image sparsity. The quality of CS reconstruction methods largely depends on the use of various sparsifying transforms, such as wavelets, curvelets or total variation (TV), to recover MR images. As per recently developed mathematical concepts of CS, the biomedical images with sparse representation can be recovered from randomly undersampled data, provided that an appropriate nonlinear recovery method is used. Due to high under-sampling, the reconstructed images have noise like artifacts because of aliasing. Reconstruction of images from CS involves two steps, one for dictionary learning and the other for sparse coding. In this novel framework, we choose Simultaneous code word optimization (SimCO) patch-based dictionary learning that updates the atoms simultaneously, whereas Focal underdetermined system solver (FOCUSS) is used for sparse representation because of a soft constraint on sparsity of an image. Combining SimCO and FOCUSS, we propose a new scheme called SiFo. Our proposed alternating reconstruction scheme learns the dictionary, uses it to eliminate aliasing and noise in one stage, and afterwards restores and fills in the k-space data in the second stage. Experiments were performed using different sampling schemes with noisy and noiseless cases of both phantom and real brain images. Based on various performance parameters, it has been shown that our designed technique outperforms the conventional techniques, like K-SVD with OMP, used in dictionary learning based MRI (DLMRI) reconstruction.},
author = {Ikram, Shahid and Shah, Jawad Ali and Zubair, Syed and Qureshi, Ijaz Mansoor and Bilal, Muhammad},
doi = {10.3390/s19081918},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Improved Reconstruction of MR Scanned Images by Using a Dictionary Learning Scheme.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {And dictionary learning based MRI (DLMRI),Compressed sensing (CS),Dictionary learning,Focal underdetermined system solver (FOCUSS),Magnetic resonance imaging (MRI),Simultaneous code word optimization (SimCO)},
number = {8},
pages = {1--17},
title = {{Improved reconstruction of MR scanned images by using a dictionary learning scheme}},
volume = {19},
year = {2019}
}
@article{Liu2018f,
abstract = {We study self-taught learning for hyperspectral image (HSI) classification with small labeled and unlabeled data sets. Supervised deep learning methods are currently state of the art for many machine learning problems, but these methods require large quantities of labeled data to be effective. Unfortunately, existing labeled HSI benchmarks are too small to train a deep supervised network. Alternatively, self-taught learning methods use sufficiently large quantities unlabeled data to improve the performance on a given image classification task. However, the unlabeled HSI data is also difficult to obtain. To overcome this limitation, we employ an online dictionary learning algorithm for sparse coding to self-taught learning, in which we extract features from much smaller unlabeled data sets. Furthermore, apart from the spectral information we also apply the spatial information to improve the performance of classification. Our results convinced that the proposed approach can extract discriminative features from small unlabeled and labeled data sets for classification. In addition, the results obtained by our approach are better than the results obtained by principal component analysis (PCA).},
author = {Liu, Fengshuang and Ma, Jiachen and Zhao, Rongqiang and Wang, Qiang},
doi = {10.1109/I2MTC.2018.8409676},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08088348.pdf:pdf},
isbn = {9781538622223},
journal = {I2MTC 2018 - 2018 IEEE International Instrumentation and Measurement Technology Conference: Discovering New Horizons in Instrumentation and Measurement, Proceedings},
keywords = {hyperspectral image classification,online dictionary learning,self-taught learning,sparse coding},
number = {3},
pages = {1--5},
title = {{Online dictionary self-taught learning for hyperspectral image classification}},
volume = {56},
year = {2018}
}
@article{Zhang2018f,
abstract = {Human action recognition is crucial to many practical applications, ranging from human-computer interaction to video surveillance. Most approaches either recognize the human action from a fixed view or require the knowledge of view angle, which is usually not available in practical applications. In this paper, we propose a novel end-To-end framework to jointly learn a view-invariance transfer dictionary and a view-invariant classifier. The result of the process is a dictionary that can project real-world 2D video into a view-invariant sparse representation, and a classifier to recognize actions with an arbitrary view. The main feature of our algorithm is the use of synthetic data to extract view-invariance between 3D and 2D videos during the pre-Training phase. This guarantees the availability of training data, and removes the hassle of obtaining real-world videos in specific viewing angles. Additionally, for better describing the actions in 3D videos, we introduce a new feature set called the 3D dense trajectories to effectively encode extracted trajectory information on 3D videos. Experimental results on the IXMAS, N-UCLA, i3DPost and UWA3DII data sets show improvements over existing algorithms.},
author = {Zhang, Jingtian and Shum, Hubert P.H. and Han, Jungong and Shao, Ling},
doi = {10.1109/TIP.2018.2836323},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08359373.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {3D dense trajectories,Action recognition,transfer dictionary learning,view-invariance},
number = {10},
pages = {4709--4723},
publisher = {IEEE},
title = {{Action Recognition from Arbitrary Views Using Transferable Dictionary Learning}},
volume = {27},
year = {2018}
}
@article{Seghouane2018,
abstract = {Algorithms for learning overcomplete dictionaries for sparse signal representation are mostly iterative minimization methods that alternate between a sparse coding stage and a dictionary update stage. For most however, the notion of consistency of the learned quantities has not been addressed. Based on the observation that the observed signals can be approximated as a sum of rank one matrices, a new adaptive dictionary learning algorithm is proposed in this paper. It is derived via sequential adaptive penalized rank one matrix approximation where the ℓ1-norm is introduced as a penalty promoting sparsity. The proposed algorithm uses a block coordinate descent approach to consistently estimate the unknowns and has the advantage of having simple closed form solutions for both the sparse coding and dictionary update stages. The consistency properties of both the estimated sparse code and dictionary atom are provided. The performance of the proposed algorithm compared to some state of the art algorithms is illustrated on both simulated data and a real functional magnetic resonance imaging (fMRI) data set from a finger tapping experiment.},
author = {Seghouane, Abd Krim and Iqbal, Asif},
doi = {10.1016/j.sigpro.2018.07.018},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0165168418302500-main.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Dictionary learning,Penalized rank one matrix approximation,Sequential learning,Sparsity},
pages = {300--310},
publisher = {Elsevier B.V.},
title = {{Consistent adaptive sequential dictionary learning}},
url = {https://doi.org/10.1016/j.sigpro.2018.07.018},
volume = {153},
year = {2018}
}
@article{Liu2013,
abstract = {Sparse representation (SR) has been widely used in many image processing applications including image fusion. As the contents vary significantly across different images, a highly redundant dictionary is always required in the sparse model, which reduces the algorithm stability and efficiency. This paper proposes a multi-focus image fusion method based on SR with adaptive sparse domain selection (SR-ASDS). Under SR-ASDS, numerous high-quality image patches are first classified into several categories according to their gradient information, and each category is applied into training a compact sub-dictionary. At the fusion process, a corresponding sub-dictionary is adaptively selected for a given pair of source image patches. Moreover, we present a general optimization framework for the merging rule design of the SR based image fusion. Numerous experiments on both clear images and the noisy ones demonstrate that the proposed method outperforms the fusion methods which use a single dictionary, in terms of several popular objective evaluation criteria.},
author = {Liu, Yu and Wang, Zengfu},
doi = {10.1109/ICIG.2013.123},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Multi-focus image fusion based .pdf:pdf},
isbn = {9780769550503},
journal = {Proceedings - 2013 7th International Conference on Image and Graphics, ICIG 2013},
pages = {591--596},
publisher = {IEEE},
title = {{Multi-focus image fusion based on sparse representation with adaptive sparse domain selection}},
year = {2013}
}
@article{Samareh2018,
abstract = {Effective monitoring of degenerative patient conditions is crucial for many clinical decision-making problems. Leveraging the nowadays data-rich environments in many clinical settings, in this paper, we propose a novel clinical data fusion framework that can build a contemporaneous health index (CHI) for degenerative disease monitoring to quantify the severity of deterioration process over time. Our framework specifically exploits the monotonic progression patterns of the target degenerative disease conditions such as the Alzheimer's disease (AD) and articulate these patterns with a systematic optimization formulation. Further, to address the patient heterogeneity, we integrate CHI with dictionary learning to build sets of overcomplete bases to represent the personalized models efficiently. Numerical performances on two real-world applications show the promising capability of the proposed DL-CHI model.},
author = {Samareh, Aven and Huang, Shuai},
doi = {10.1186/s13634-018-0538-8},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/document(2).pdf:pdf},
issn = {16876180},
journal = {Eurasip Journal on Advances in Signal Processing},
keywords = {Convex optimization,Dictionary learning,Patient monitoring,Personalized healthcare},
number = {1},
publisher = {EURASIP Journal on Advances in Signal Processing},
title = {{DL-CHI: a dictionary learning-based contemporaneous health index for degenerative disease monitoring}},
volume = {2018},
year = {2018}
}
@article{Zhang2018k,
abstract = {In this paper, we propose an analysis mechanism-based structured analysis discriminative dictionary learning analysis discriminative dictionary learning, framework. The ADDL seamlessly integrates ADDL, analysis representation, and analysis classifier training into a unified model. The applied analysis mechanism can make sure that the learned dictionaries, representations, and linear classifiers over different classes are independent and discriminating as much as possible. The dictionary is obtained by minimizing a reconstruction error and an analytical incoherence promoting term that encourages the subdictionaries associated with different classes to be independent. To obtain the representation coefficients, ADDL imposes a sparse {\$}l-{\{}2,1{\}}{\$} -norm constraint on the coding coefficients instead of using {\$}l-{\{}0{\}}{\$} or {\$}l-{\{}1{\}}{\$} norm, since the {\$}l-{\{}0{\}}{\$} - or {\$}l-{\{}1{\}}{\$} -norm constraint applied in most existing DL criteria makes the training phase time consuming. The code-extraction projection that bridges data with the sparse codes by extracting special features from the given samples is calculated via minimizing a sparse code approximation term. Then we compute a linear classifier based on the approximated sparse codes by an analysis mechanism to simultaneously consider the classification and representation powers. Thus, the classification approach of our model is very efficient, because it can avoid the extra time-consuming sparse reconstruction process with trained dictionary for each new test data as most existing DL algorithms. Simulations on real image databases demonstrate that our ADDL model can obtain superior performance over other state of the arts.},
author = {Zhang, Zhao and Jiang, Weiming and Qin, Jie and Zhang, Li and Li, Fanzhang and Zhang, Min and Yan, Shuicheng},
doi = {10.1109/TNNLS.2017.2740224},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/08038251.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Analysis multiclass classifier,analytical incoherence promotion,projective sparse representation (SR),structured analysis discriminative dictionary lear},
number = {8},
pages = {3798--3814},
publisher = {IEEE},
title = {{Jointly learning structured analysis discriminative dictionary and analysis multiclass classifier}},
volume = {29},
year = {2018}
}
@article{Duarte2005,
abstract = {Compressed sensing is an emerging field based on the revelation that a small collection of linear projections of a sparse signal contains enough information for reconstruction. In this paper we expand our theory for distributed compressed sensing (DCS) that enables new distributed coding algorithms for multi-signal ensembles that exploit both intra- and inter-signal correlation structures. The DCS theory rests on a new concept that we term the joint sparsity of a signal ensemble. We present a second new model for jointly sparse signals that allows for joint recovery of multiple signals from incoherent projections through simultaneous greedy pursuit algorithms. We also characterize theoretically and empirically the number of measurements per sensor required for accurate reconstruction. ?? 2005 IEEE.},
author = {Duarte, Marco F. and Sarvotham, Shriram and Baron, Dror and Wakin, Michael B. and Baraniuk, Richard G.},
doi = {10.1109/acssc.2005.1600024},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/01600024.pdf:pdf},
isbn = {1424401313},
issn = {10586393},
journal = {Conference Record - Asilomar Conference on Signals, Systems and Computers},
pages = {1537--1541},
publisher = {IEEE},
title = {{Distributed compressed sensing of jointly sparse signals}},
volume = {2005},
year = {2005}
}
@article{Saeedi2011,
abstract = {In this paper, a novel approach based on multiobjective particle swarm optimization (MOPSO) is presented for panchromatic (Pan) sharpening of a multispectral (MS) image. This new method could transfer spatial details of the pan image into a high-resolution version of the MS image, while color information from the low-resolution MS image is well preserved. The pan and MS images are locally different because of different resolutions, and therefore we cannot directly combine them in the spatial domain. For this reason, we generate two initial results, which are more appropriate for a weighted combination. First, the pan and the MS images are histogram matched. Then we use the shiftable contourlet transform (SCT) to decompose the histogram-matched pan and MS images. The SCT is a new shiftable and modified version of the contourlet transform. In this step, an algorithm based on the SCT is used to generate two initial results of the high-resolution MS images. Our objective is to produce two modified high-resolution MS images, in which one has high spatial similarity to the pan image and the other one has high radiometric quality in each band. Therefore, we have used two different fusion rules to integrate the high-frequency contourlet coefficients of the pan and MS images to generate two initial results of high-resolution MS image or the pan-sharpened (PS) image. Finally, we can find the optimal PS image by applying the MOPSO algorithm and using the two initial PS results. Specifically, the PS image is obtained via a weighted combination of the two initial results, in which the weights are locally estimated via a multiobjective particle swarm optimization algorithm to generate a PS image with high spatial and radiometric qualities. Based on experimental results obtained, the produced pan-sharpened image also has good spectral quality. The efficiency of the proposed method is tested by performing pan-sharpening of high-resolution (Quickbird and Wordview2) and medium-resolution (Landsat-7 ETM ) datasets. Extensive comparisons with the state-of-the-art pan-sharpening algorithms indicate that our new method provides improved subjective and objective results. {\textcopyright} 2011 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).},
author = {Saeedi, Jamal and Faez, Karim},
doi = {10.1016/j.isprsjprs.2011.01.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/Saeedi-2011-A-new-pan-sharpening-method-using-m.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Multiobjective particle swarm optimization,Pan-sharpening,Shiftable contourlet transform},
number = {3},
pages = {365--381},
publisher = {Elsevier B.V.},
title = {{A new pan-sharpening method using multiobjective particle swarm optimization and the shiftable contourlet transform}},
url = {http://dx.doi.org/10.1016/j.isprsjprs.2011.01.006},
volume = {66},
year = {2011}
}
@article{Singhal2019,
abstract = {Currently there are several well-known approaches to non-intrusive appliance load monitoring - rule based, stochastic finite state machines, neural networks, and sparse coding. Recently several studies have proposed a new approach based on multi-label classification. Different appliances are treated as separate classes, and the task is to identify the classes given the aggregate smart-meter reading. Prior studies in this area have used off-the-shelf algorithms like multi label {\{}K{\}} nearest neighbor and random {\{}K{\}} -label sets to address this problem. In this paper, we propose a deep learning-based technique. There are hardly any studies in deep learning based multi-label classification; two new deep learning techniques to solve the said problem are fundamental contributions of this paper. These are deep dictionary learning and deep transform learning. Thorough experimental results on benchmark datasets show marked improvement over existing studies.},
author = {Singhal, Vanika and Maggu, Jyoti and Majumdar, Angshul},
doi = {10.1109/TSG.2018.2815763},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-5-Simultaneous Detection of Multiple AppliancesFrom Smart-Meter Measurements via Multi-LabelConsistent .pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Deep learning,energy disaggregation,multi-label classification,non-intrusive load monitoring},
number = {3},
pages = {2969--2978},
publisher = {IEEE},
title = {{Simultaneous Detection of Multiple Appliances from Smart-Meter Measurements via Multi-Label Consistent Deep Dictionary Learning and Deep Transform Learning}},
volume = {10},
year = {2019}
}
@article{Liu2018a,
abstract = {Nonparametric Bayesian dictionary learning has shown a powerful potential in image restoration. However, it still lacks exploiting image structure to improve the performance. In this work, we propose a sparse Bayesian dictionary learning framework with structure prior called nonlocal structured beta process factor analysis (NLS-BPFA) which connects nonlocal self-similarity and sparse Bayesian dictionary learning. A nonlocal structured beta process is proposed to introduce the nonlocal self-similarity as a structure prior for image denoising and inpainting. Unlike most of the existing image denoising methods, our proposed method does not need to know noise variance in advance like an unsupervised learning. The experimental results demonstrate the effectiveness of our proposed model.},
author = {Liu, Zhou and Yu, Lei and Sun, Hong},
doi = {10.1016/j.jvcir.2018.02.011},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1047320318300439-main.pdf:pdf},
issn = {10959076},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Beta process,Dictionary learning,Image restoration,Nonlocal structure prior,Nonparametric Bayesian},
number = {December 2016},
pages = {159--169},
publisher = {Elsevier},
title = {{Image restoration via Bayesian dictionary learning with nonlocal structured beta process}},
url = {https://doi.org/10.1016/j.jvcir.2018.02.011},
volume = {52},
year = {2018}
}
@article{Du2016,
abstract = {Multi-modal medical image fusion is the process of merging multiple images from single or multiple imaging modalities to improve the imaging quality with preserving the specific features. Medical image fusion covers a broad number of hot topic areas, including image processing, computer vision, pattern recognition, machine learning and artificial intelligence. And medical image fusion has been widely used in clinical for physicians to comprehend the lesion by the fusion of different modalities medical images. In this review, methods in the field of medical image fusion are characterized by (1) image decomposition and image reconstruction, (2) image fusion rules, (3) image quality assessments, and (4) experiments on the benchmark dataset. In addition, this review provides a factual listing of scientific challenges faced in the field of multi-modal medical image fusion.},
author = {Du, Jiao and Li, Weisheng and Lu, Ke and Xiao, Bin},
doi = {10.1016/j.neucom.2015.07.160},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/00 An overview of multi-modal medical image fusion.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Image decomposition,Image fusion,Image fusion rules,Image quality assessment,Image reconstruction,Multi-modal},
pages = {3--20},
title = {{An overview of multi-modal medical image fusion}},
volume = {215},
year = {2016}
}
@article{Li2018f,
abstract = {Researches demonstrate that profiles (row vectors of coding coefficient matrix) can be used to select and update atoms. However, the profiles are seldom used to construct discriminative terms in dictionary learning. In this paper, we propose an interactively constrained discriminative dictionary learning (IC-DDL) algorithm for image classification. First, we give a Lemma of the relation between the profiles and atoms. That is, similar profiles can lead to the corresponding atoms which are also similar, and vice verse. Then, we construct a profile constrained term by using the profiles and Laplacian graph of the atoms. Third, we explore the atoms and the Laplacian graph of the profiles to construct an atom constrained term. By alternatively and interactively updating the profiles and atoms, the two proposed constrained terms not only can inherit the structure information of the training samples, but also preserve the structure information of the atoms and profiles simultaneously. Moreover, the atom constrained model also can minimize the incoherence of the atoms. Experiment results demonstrate that the IC-DDL algorithm can achieve better performance than some state-of-the-art dictionary learning algorithms on the six image databases.},
author = {Li, Zhengming and Zhang, Zheng and Fan, Zizhu and Wen, Jie},
doi = {10.1016/j.engappai.2018.04.006},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0952197618300885-main.pdf:pdf},
issn = {09521976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {Dictionary learning,Image classification,Sparse coding},
number = {August 2017},
pages = {241--252},
publisher = {Elsevier Ltd},
title = {{An interactively constrained discriminative dictionary learning algorithm for image classification}},
url = {https://doi.org/10.1016/j.engappai.2018.04.006},
volume = {72},
year = {2018}
}
@article{Liu2018h,
author = {Liu, Yu and Chen, Xun and Wang, Zengfu and Wang, Z Jane and Ward, Rabab K and Wang, Xuesong},
doi = {10.1016/j.inffus.2017.10.007},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S1566253517305936-main(2).pdf:pdf},
issn = {1566-2535},
journal = {Information Fusion},
keywords = {Convolutional neural network,Convolutional sparse representation,Deep learning,Image fusion,Stacked autoencoder},
number = {September 2017},
pages = {158--173},
publisher = {Elsevier},
title = {{Deep learning for pixel-level image fusion : Recent advances and future prospects}},
url = {https://doi.org/10.1016/j.inffus.2017.10.007},
volume = {42},
year = {2018}
}
@article{Kanoga2019,
abstract = {This paper addresses two issues toward practical use of wearable electroencephalogram (EEG) measurement devices. Ocular (eye movement and blink) artifacts often contaminate EEGs and deteriorate the performance of EEG-based brain–computer interfaces (BCIs). Although wearable consumer-grade EEG devices with single electrode allow users to operate BCIs conveniently in daily lives, it remains a challenging issue to attenuate ocular artifacts from single-channel measurements without spatial information. Existing ocular artifact reduction methods are, however, not simple enough for single-channel EEG data in the sense that they require an additional reference channel and/or pre-processing for artifact segment detection. Another issue is how to assess the performance of artifact reduction; the existing studies have used their own datasets that are not accessible from other researchers. Then, this paper makes two major contributions. (1) This paper proposes a novel ocular artifact reduction method, multi-scale dictionary learning (MSDL), which operates under single-channel measurements and without artifact segment detection. (2) We also develop a semi-simulation setting for quantitative evaluation with a publicly available EEG dataset. In particular, we employed BCI Competition IV Dataset 2a, on which the proposed method was compared with state-of-art methods. The proposed technique showed the best performance for recovering artifact-reduced waveforms from single-channel data compared to the other artifact reduction methods. The Matlab scripts for semi-simulation data generation and single-channel artifact reduction are available on GitHub.},
author = {Kanoga, Suguru and Kanemura, Atsunori and Asoh, Hideki},
doi = {10.1016/j.neucom.2019.02.060},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/2019-1-Multi-scaledictionarylearningforocularartifactreductionfromsingle-channelelectroencephalograms.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Adaptive filter,Dictionary learning,Electroencephalogram (EEG),Independent component analysis (ICA),Ocular artifact reduction,Single-channel signal},
pages = {240--250},
publisher = {Elsevier B.V.},
title = {{Multi-scale dictionary learning for ocular artifact reduction from single-channel electroencephalograms}},
url = {https://doi.org/10.1016/j.neucom.2019.02.060},
volume = {347},
year = {2019}
}
@article{Zhao2019c,
abstract = {Dictionary learning (DL) methods are widely used for pattern recognition in recent years. In most DL methods, the l 1 norm is employed to promote sparsity of the coding. However, the usage of the sparse coding based methods is limited since solving the l1 based sparse coding is very time-consuming. In this paper, a novel orthogonal collaborative dictionary learning (CDL) method is proposed for accurate and efficient face classification. In this method, several class-specific dictionaries and one common dictionary are learned jointly from the training data, where the class-specific dictionaries are used to model the appearance of the subjects and the common dictionary is used to model the facial variations. To learn these dictionaries, we introduce an orthogonality promoting term to encourage the facial variations to be independent of the appearance as much as possible, and introduce a scatter constraint term to remove the variations in the class-specific dictionaries. Since CDL can derive analytical solutions for both code learning and dictionary updating, it is much more efficient than many other DL methods in terms of training and classification. Experiments conducted on seven face databases show that CDL outperforms many state-of-the-art DL methods and coding methods in both accuracy and efficiency.},
author = {Zhao, Zhong and Feng, Guocan and Zhang, Lifang and Zhu, Jiehua and Shen, Qi},
doi = {10.1016/j.knosys.2018.09.014},
file = {:C$\backslash$:/E-DATA-GROUNP/github/baidu{\_}yun/Mendeley{\_}paper/1-s2.0-S0950705118304659-main.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Collaborative representation,Common dictionary,Dictionary learning,Efficient face recognition},
pages = {533--545},
publisher = {Elsevier B.V.},
title = {{Novel orthogonal based collaborative dictionary learning for efficient face recognition}},
url = {https://doi.org/10.1016/j.knosys.2018.09.014},
volume = {163},
year = {2019}
}
